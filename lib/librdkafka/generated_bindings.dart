// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

class LibRdKafka {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  LibRdKafka(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  LibRdKafka.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  int renameat(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
  ) {
    return _renameat(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _renameatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Pointer<ffi.Char>)>>('renameat');
  late final _renameat = _renameatPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>)>();

  int renamex_np(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _renamex_np(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _renamex_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.UnsignedInt)>>('renamex_np');
  late final _renamex_np = _renamex_npPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int renameatx_np(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
    int arg4,
  ) {
    return _renameatx_np(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _renameatx_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Pointer<ffi.Char>, ffi.UnsignedInt)>>('renameatx_np');
  late final _renameatx_np = _renameatx_npPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>, int)>();

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stdinp =
      _lookup<ffi.Pointer<FILE>>('__stdinp');

  ffi.Pointer<FILE> get __stdinp => ___stdinp.value;

  set __stdinp(ffi.Pointer<FILE> value) => ___stdinp.value = value;

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stdoutp =
      _lookup<ffi.Pointer<FILE>>('__stdoutp');

  ffi.Pointer<FILE> get __stdoutp => ___stdoutp.value;

  set __stdoutp(ffi.Pointer<FILE> value) => ___stdoutp.value = value;

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stderrp =
      _lookup<ffi.Pointer<FILE>>('__stderrp');

  ffi.Pointer<FILE> get __stderrp => ___stderrp.value;

  set __stderrp(ffi.Pointer<FILE> value) => ___stderrp.value = value;

  void clearerr(
    ffi.Pointer<FILE> arg0,
  ) {
    return _clearerr(
      arg0,
    );
  }

  late final _clearerrPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'clearerr');
  late final _clearerr =
      _clearerrPtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int fclose(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fclose(
      arg0,
    );
  }

  late final _fclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fclose');
  late final _fclose = _fclosePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int feof(
    ffi.Pointer<FILE> arg0,
  ) {
    return _feof(
      arg0,
    );
  }

  late final _feofPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('feof');
  late final _feof = _feofPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int ferror(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ferror(
      arg0,
    );
  }

  late final _ferrorPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'ferror');
  late final _ferror = _ferrorPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fflush(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fflush(
      arg0,
    );
  }

  late final _fflushPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fflush');
  late final _fflush = _fflushPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fgetc(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fgetc(
      arg0,
    );
  }

  late final _fgetcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('fgetc');
  late final _fgetc = _fgetcPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fgetpos(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<fpos_t> arg1,
  ) {
    return _fgetpos(
      arg0,
      arg1,
    );
  }

  late final _fgetposPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>>('fgetpos');
  late final _fgetpos = _fgetposPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>();

  ffi.Pointer<ffi.Char> fgets(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    ffi.Pointer<FILE> arg2,
  ) {
    return _fgets(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _fgetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<FILE>)>>('fgets');
  late final _fgets = _fgetsPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, int, ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> fopen(
    ffi.Pointer<ffi.Char> __filename,
    ffi.Pointer<ffi.Char> __mode,
  ) {
    return _fopen(
      __filename,
      __mode,
    );
  }

  late final _fopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('fopen');
  late final _fopen = _fopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fprintf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fprintf(
      arg0,
      arg1,
    );
  }

  late final _fprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('fprintf');
  late final _fprintf = _fprintfPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int fputc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _fputc(
      arg0,
      arg1,
    );
  }

  late final _fputcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'fputc');
  late final _fputc =
      _fputcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int fputs(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _fputs(
      arg0,
      arg1,
    );
  }

  late final _fputsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>>('fputs');
  late final _fputs = _fputsPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>();

  int fread(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
    int __nitems,
    ffi.Pointer<FILE> __stream,
  ) {
    return _fread(
      __ptr,
      __size,
      __nitems,
      __stream,
    );
  }

  late final _freadPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.Size,
              ffi.Pointer<FILE>)>>('fread');
  late final _fread = _freadPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> freopen(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    ffi.Pointer<FILE> arg2,
  ) {
    return _freopen(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _freopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>>('freopen');
  late final _freopen = _freopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>();

  int fscanf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fscanf(
      arg0,
      arg1,
    );
  }

  late final _fscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('fscanf');
  late final _fscanf = _fscanfPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int fseek(
    ffi.Pointer<FILE> arg0,
    int arg1,
    int arg2,
  ) {
    return _fseek(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _fseekPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Long, ffi.Int)>>('fseek');
  late final _fseek =
      _fseekPtr.asFunction<int Function(ffi.Pointer<FILE>, int, int)>();

  int fsetpos(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<fpos_t> arg1,
  ) {
    return _fsetpos(
      arg0,
      arg1,
    );
  }

  late final _fsetposPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>>('fsetpos');
  late final _fsetpos = _fsetposPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>();

  int ftell(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ftell(
      arg0,
    );
  }

  late final _ftellPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<FILE>)>>(
          'ftell');
  late final _ftell = _ftellPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fwrite(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
    int __nitems,
    ffi.Pointer<FILE> __stream,
  ) {
    return _fwrite(
      __ptr,
      __size,
      __nitems,
      __stream,
    );
  }

  late final _fwritePtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.Size,
              ffi.Pointer<FILE>)>>('fwrite');
  late final _fwrite = _fwritePtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<FILE>)>();

  int getc(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getc(
      arg0,
    );
  }

  late final _getcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('getc');
  late final _getc = _getcPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int getchar() {
    return _getchar();
  }

  late final _getcharPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('getchar');
  late final _getchar = _getcharPtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Char> gets(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _gets(
      arg0,
    );
  }

  late final _getsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('gets');
  late final _gets = _getsPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  void perror(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _perror(
      arg0,
    );
  }

  late final _perrorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>(
          'perror');
  late final _perror =
      _perrorPtr.asFunction<void Function(ffi.Pointer<ffi.Char>)>();

  int printf(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _printf(
      arg0,
    );
  }

  late final _printfPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'printf');
  late final _printf =
      _printfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int putc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putc(
      arg0,
      arg1,
    );
  }

  late final _putcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putc');
  late final _putc =
      _putcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int putchar(
    int arg0,
  ) {
    return _putchar(
      arg0,
    );
  }

  late final _putcharPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('putchar');
  late final _putchar = _putcharPtr.asFunction<int Function(int)>();

  int puts(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _puts(
      arg0,
    );
  }

  late final _putsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'puts');
  late final _puts = _putsPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int remove(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _remove(
      arg0,
    );
  }

  late final _removePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'remove');
  late final _remove =
      _removePtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int rename(
    ffi.Pointer<ffi.Char> __old,
    ffi.Pointer<ffi.Char> __new,
  ) {
    return _rename(
      __old,
      __new,
    );
  }

  late final _renamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('rename');
  late final _rename = _renamePtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  void rewind(
    ffi.Pointer<FILE> arg0,
  ) {
    return _rewind(
      arg0,
    );
  }

  late final _rewindPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'rewind');
  late final _rewind =
      _rewindPtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int scanf(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _scanf(
      arg0,
    );
  }

  late final _scanfPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'scanf');
  late final _scanf =
      _scanfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  void setbuf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _setbuf(
      arg0,
      arg1,
    );
  }

  late final _setbufPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('setbuf');
  late final _setbuf = _setbufPtr
      .asFunction<void Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int setvbuf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    int arg3,
  ) {
    return _setvbuf(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _setvbufPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Size)>>('setvbuf');
  late final _setvbuf = _setvbufPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, int, int)>();

  int sprintf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _sprintf(
      arg0,
      arg1,
    );
  }

  late final _sprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('sprintf');
  late final _sprintf = _sprintfPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int sscanf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _sscanf(
      arg0,
      arg1,
    );
  }

  late final _sscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('sscanf');
  late final _sscanf = _sscanfPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> tmpfile() {
    return _tmpfile();
  }

  late final _tmpfilePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<FILE> Function()>>('tmpfile');
  late final _tmpfile = _tmpfilePtr.asFunction<ffi.Pointer<FILE> Function()>();

  ffi.Pointer<ffi.Char> tmpnam(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _tmpnam(
      arg0,
    );
  }

  late final _tmpnamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('tmpnam');
  late final _tmpnam = _tmpnamPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  int ungetc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _ungetc(
      arg0,
      arg1,
    );
  }

  late final _ungetcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'ungetc');
  late final _ungetc =
      _ungetcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int vfprintf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vfprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vfprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>>('vfprintf');
  late final _vfprintf = _vfprintfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int vprintf(
    ffi.Pointer<ffi.Char> arg0,
    va_list arg1,
  ) {
    return _vprintf(
      arg0,
      arg1,
    );
  }

  late final _vprintfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>, va_list)>>(
      'vprintf');
  late final _vprintf =
      _vprintfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, va_list)>();

  int vsprintf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vsprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vsprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              va_list)>>('vsprintf');
  late final _vsprintf = _vsprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, va_list)>();

  ffi.Pointer<ffi.Char> ctermid(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _ctermid(
      arg0,
    );
  }

  late final _ctermidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('ctermid');
  late final _ctermid = _ctermidPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> fdopen(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fdopen(
      arg0,
      arg1,
    );
  }

  late final _fdopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Int, ffi.Pointer<ffi.Char>)>>('fdopen');
  late final _fdopen = _fdopenPtr
      .asFunction<ffi.Pointer<FILE> Function(int, ffi.Pointer<ffi.Char>)>();

  int fileno(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fileno(
      arg0,
    );
  }

  late final _filenoPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fileno');
  late final _fileno = _filenoPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int pclose(
    ffi.Pointer<FILE> arg0,
  ) {
    return _pclose(
      arg0,
    );
  }

  late final _pclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'pclose');
  late final _pclose = _pclosePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> popen(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _popen(
      arg0,
      arg1,
    );
  }

  late final _popenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('popen');
  late final _popen = _popenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int __srget(
    ffi.Pointer<FILE> arg0,
  ) {
    return ___srget(
      arg0,
    );
  }

  late final ___srgetPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          '__srget');
  late final ___srget =
      ___srgetPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int __svfscanf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return ___svfscanf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___svfscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>,
              va_list)>>('__svfscanf');
  late final ___svfscanf = ___svfscanfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int __swbuf(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return ___swbuf(
      arg0,
      arg1,
    );
  }

  late final ___swbufPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          '__swbuf');
  late final ___swbuf =
      ___swbufPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  void flockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _flockfile(
      arg0,
    );
  }

  late final _flockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'flockfile');
  late final _flockfile =
      _flockfilePtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int ftrylockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ftrylockfile(
      arg0,
    );
  }

  late final _ftrylockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'ftrylockfile');
  late final _ftrylockfile =
      _ftrylockfilePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  void funlockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _funlockfile(
      arg0,
    );
  }

  late final _funlockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'funlockfile');
  late final _funlockfile =
      _funlockfilePtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int getc_unlocked(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getc_unlocked(
      arg0,
    );
  }

  late final _getc_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'getc_unlocked');
  late final _getc_unlocked =
      _getc_unlockedPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int getchar_unlocked() {
    return _getchar_unlocked();
  }

  late final _getchar_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('getchar_unlocked');
  late final _getchar_unlocked =
      _getchar_unlockedPtr.asFunction<int Function()>();

  int putc_unlocked(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putc_unlocked(
      arg0,
      arg1,
    );
  }

  late final _putc_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putc_unlocked');
  late final _putc_unlocked =
      _putc_unlockedPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int putchar_unlocked(
    int arg0,
  ) {
    return _putchar_unlocked(
      arg0,
    );
  }

  late final _putchar_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'putchar_unlocked');
  late final _putchar_unlocked =
      _putchar_unlockedPtr.asFunction<int Function(int)>();

  int getw(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getw(
      arg0,
    );
  }

  late final _getwPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('getw');
  late final _getw = _getwPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int putw(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putw(
      arg0,
      arg1,
    );
  }

  late final _putwPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putw');
  late final _putw =
      _putwPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  ffi.Pointer<ffi.Char> tempnam(
    ffi.Pointer<ffi.Char> __dir,
    ffi.Pointer<ffi.Char> __prefix,
  ) {
    return _tempnam(
      __dir,
      __prefix,
    );
  }

  late final _tempnamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('tempnam');
  late final _tempnam = _tempnamPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fseeko(
    ffi.Pointer<FILE> __stream,
    int __offset,
    int __whence,
  ) {
    return _fseeko(
      __stream,
      __offset,
      __whence,
    );
  }

  late final _fseekoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, off_t, ffi.Int)>>('fseeko');
  late final _fseeko =
      _fseekoPtr.asFunction<int Function(ffi.Pointer<FILE>, int, int)>();

  int ftello(
    ffi.Pointer<FILE> __stream,
  ) {
    return _ftello(
      __stream,
    );
  }

  late final _ftelloPtr =
      _lookup<ffi.NativeFunction<off_t Function(ffi.Pointer<FILE>)>>('ftello');
  late final _ftello = _ftelloPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int snprintf(
    ffi.Pointer<ffi.Char> __str,
    int __size,
    ffi.Pointer<ffi.Char> __format,
  ) {
    return _snprintf(
      __str,
      __size,
      __format,
    );
  }

  late final _snprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('snprintf');
  late final _snprintf = _snprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>)>();

  int vfscanf(
    ffi.Pointer<FILE> __stream,
    ffi.Pointer<ffi.Char> __format,
    va_list arg2,
  ) {
    return _vfscanf(
      __stream,
      __format,
      arg2,
    );
  }

  late final _vfscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>>('vfscanf');
  late final _vfscanf = _vfscanfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int vscanf(
    ffi.Pointer<ffi.Char> __format,
    va_list arg1,
  ) {
    return _vscanf(
      __format,
      arg1,
    );
  }

  late final _vscanfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>, va_list)>>(
      'vscanf');
  late final _vscanf =
      _vscanfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, va_list)>();

  int vsnprintf(
    ffi.Pointer<ffi.Char> __str,
    int __size,
    ffi.Pointer<ffi.Char> __format,
    va_list arg3,
  ) {
    return _vsnprintf(
      __str,
      __size,
      __format,
      arg3,
    );
  }

  late final _vsnprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('vsnprintf');
  late final _vsnprintf = _vsnprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>, va_list)>();

  int vsscanf(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Char> __format,
    va_list arg2,
  ) {
    return _vsscanf(
      __str,
      __format,
      arg2,
    );
  }

  late final _vsscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              va_list)>>('vsscanf');
  late final _vsscanf = _vsscanfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, va_list)>();

  int dprintf(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _dprintf(
      arg0,
      arg1,
    );
  }

  late final _dprintfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>)>>(
      'dprintf');
  late final _dprintf =
      _dprintfPtr.asFunction<int Function(int, ffi.Pointer<ffi.Char>)>();

  int vdprintf(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vdprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vdprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, ffi.Pointer<ffi.Char>, va_list)>>('vdprintf');
  late final _vdprintf = _vdprintfPtr
      .asFunction<int Function(int, ffi.Pointer<ffi.Char>, va_list)>();

  int getdelim(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __linep,
    ffi.Pointer<ffi.Size> __linecapp,
    int __delimiter,
    ffi.Pointer<FILE> __stream,
  ) {
    return _getdelim(
      __linep,
      __linecapp,
      __delimiter,
      __stream,
    );
  }

  late final _getdelimPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>, ffi.Int, ffi.Pointer<FILE>)>>('getdelim');
  late final _getdelim = _getdelimPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>,
          int, ffi.Pointer<FILE>)>();

  int getline(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __linep,
    ffi.Pointer<ffi.Size> __linecapp,
    ffi.Pointer<FILE> __stream,
  ) {
    return _getline(
      __linep,
      __linecapp,
      __stream,
    );
  }

  late final _getlinePtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>, ffi.Pointer<FILE>)>>('getline');
  late final _getline = _getlinePtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>,
          ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> fmemopen(
    ffi.Pointer<ffi.Void> __buf,
    int __size,
    ffi.Pointer<ffi.Char> __mode,
  ) {
    return _fmemopen(
      __buf,
      __size,
      __mode,
    );
  }

  late final _fmemopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Void>, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('fmemopen');
  late final _fmemopen = _fmemopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> open_memstream(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __bufp,
    ffi.Pointer<ffi.Size> __sizep,
  ) {
    return _open_memstream(
      __bufp,
      __sizep,
    );
  }

  late final _open_memstreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>)>>('open_memstream');
  late final _open_memstream = _open_memstreamPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>)>();

  late final ffi.Pointer<ffi.Int> _sys_nerr = _lookup<ffi.Int>('sys_nerr');

  int get sys_nerr => _sys_nerr.value;

  late final ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> _sys_errlist =
      _lookup<ffi.Pointer<ffi.Pointer<ffi.Char>>>('sys_errlist');

  ffi.Pointer<ffi.Pointer<ffi.Char>> get sys_errlist => _sys_errlist.value;

  set sys_errlist(ffi.Pointer<ffi.Pointer<ffi.Char>> value) =>
      _sys_errlist.value = value;

  int asprintf(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _asprintf(
      arg0,
      arg1,
    );
  }

  late final _asprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Char>)>>('asprintf');
  late final _asprintf = _asprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> ctermid_r(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _ctermid_r(
      arg0,
    );
  }

  late final _ctermid_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('ctermid_r');
  late final _ctermid_r = _ctermid_rPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> fgetln(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Size> arg1,
  ) {
    return _fgetln(
      arg0,
      arg1,
    );
  }

  late final _fgetlnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Size>)>>('fgetln');
  late final _fgetln = _fgetlnPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<FILE>, ffi.Pointer<ffi.Size>)>();

  ffi.Pointer<ffi.Char> fmtcheck(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fmtcheck(
      arg0,
      arg1,
    );
  }

  late final _fmtcheckPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('fmtcheck');
  late final _fmtcheck = _fmtcheckPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fpurge(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fpurge(
      arg0,
    );
  }

  late final _fpurgePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fpurge');
  late final _fpurge = _fpurgePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  void setbuffer(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _setbuffer(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _setbufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, ffi.Int)>>('setbuffer');
  late final _setbuffer = _setbufferPtr.asFunction<
      void Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, int)>();

  int setlinebuf(
    ffi.Pointer<FILE> arg0,
  ) {
    return _setlinebuf(
      arg0,
    );
  }

  late final _setlinebufPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'setlinebuf');
  late final _setlinebuf =
      _setlinebufPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int vasprintf(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vasprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vasprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Char>, va_list)>>('vasprintf');
  late final _vasprintf = _vasprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Char>,
          va_list)>();

  ffi.Pointer<FILE> funopen(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>
        arg1,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>
        arg2,
    ffi.Pointer<
            ffi.NativeFunction<
                fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>
        arg3,
    ffi.Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
        arg4,
  ) {
    return _funopen(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _funopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>)>>)>>('funopen');
  late final _funopen = _funopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<
                  fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>)>();

  int __sprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
  ) {
    return ___sprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final ___sprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('__sprintf_chk');
  late final ___sprintf_chk = ___sprintf_chkPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, int, ffi.Pointer<ffi.Char>)>();

  int __snprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    int arg3,
    ffi.Pointer<ffi.Char> arg4,
  ) {
    return ___snprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final ___snprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('__snprintf_chk');
  late final ___snprintf_chk = ___snprintf_chkPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, int, int, ffi.Pointer<ffi.Char>)>();

  int __vsprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
    va_list arg4,
  ) {
    return ___vsprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final ___vsprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('__vsprintf_chk');
  late final ___vsprintf_chk = ___vsprintf_chkPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, int, ffi.Pointer<ffi.Char>, va_list)>();

  int __vsnprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    int arg3,
    ffi.Pointer<ffi.Char> arg4,
    va_list arg5,
  ) {
    return ___vsnprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final ___vsnprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('__vsnprintf_chk');
  late final ___vsnprintf_chk = ___vsnprintf_chkPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, int, int, ffi.Pointer<ffi.Char>,
          va_list)>();

  int imaxabs(
    int j,
  ) {
    return _imaxabs(
      j,
    );
  }

  late final _imaxabsPtr =
      _lookup<ffi.NativeFunction<intmax_t Function(intmax_t)>>('imaxabs');
  late final _imaxabs = _imaxabsPtr.asFunction<int Function(int)>();

  imaxdiv_t imaxdiv(
    int __numer,
    int __denom,
  ) {
    return _imaxdiv(
      __numer,
      __denom,
    );
  }

  late final _imaxdivPtr =
      _lookup<ffi.NativeFunction<imaxdiv_t Function(intmax_t, intmax_t)>>(
          'imaxdiv');
  late final _imaxdiv = _imaxdivPtr.asFunction<imaxdiv_t Function(int, int)>();

  int strtoimax(
    ffi.Pointer<ffi.Char> __nptr,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoimax(
      __nptr,
      __endptr,
      __base,
    );
  }

  late final _strtoimaxPtr = _lookup<
      ffi.NativeFunction<
          intmax_t Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoimax');
  late final _strtoimax = _strtoimaxPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int strtoumax(
    ffi.Pointer<ffi.Char> __nptr,
    ffi.Pointer<ffi.Pointer<ffi.Char>> __endptr,
    int __base,
  ) {
    return _strtoumax(
      __nptr,
      __endptr,
      __base,
    );
  }

  late final _strtoumaxPtr = _lookup<
      ffi.NativeFunction<
          uintmax_t Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Int)>>('strtoumax');
  late final _strtoumax = _strtoumaxPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  int wcstoimax(
    ffi.Pointer<ffi.WChar> __nptr,
    ffi.Pointer<ffi.Pointer<ffi.WChar>> __endptr,
    int __base,
  ) {
    return _wcstoimax(
      __nptr,
      __endptr,
      __base,
    );
  }

  late final _wcstoimaxPtr = _lookup<
      ffi.NativeFunction<
          intmax_t Function(ffi.Pointer<ffi.WChar>,
              ffi.Pointer<ffi.Pointer<ffi.WChar>>, ffi.Int)>>('wcstoimax');
  late final _wcstoimax = _wcstoimaxPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Pointer<ffi.WChar>>, int)>();

  int wcstoumax(
    ffi.Pointer<ffi.WChar> __nptr,
    ffi.Pointer<ffi.Pointer<ffi.WChar>> __endptr,
    int __base,
  ) {
    return _wcstoumax(
      __nptr,
      __endptr,
      __base,
    );
  }

  late final _wcstoumaxPtr = _lookup<
      ffi.NativeFunction<
          uintmax_t Function(ffi.Pointer<ffi.WChar>,
              ffi.Pointer<ffi.Pointer<ffi.WChar>>, ffi.Int)>>('wcstoumax');
  late final _wcstoumax = _wcstoumaxPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.WChar>, ffi.Pointer<ffi.Pointer<ffi.WChar>>, int)>();

  int __darwin_check_fd_set_overflow(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return ___darwin_check_fd_set_overflow(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___darwin_check_fd_set_overflowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Void>,
              ffi.Int)>>('__darwin_check_fd_set_overflow');
  late final ___darwin_check_fd_set_overflow =
      ___darwin_check_fd_set_overflowPtr
          .asFunction<int Function(int, ffi.Pointer<ffi.Void>, int)>();

  int accept(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
    ffi.Pointer<socklen_t> arg2,
  ) {
    return _accept(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _acceptPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<sockaddr>,
              ffi.Pointer<socklen_t>)>>('accept');
  late final _accept = _acceptPtr.asFunction<
      int Function(int, ffi.Pointer<sockaddr>, ffi.Pointer<socklen_t>)>();

  int bind(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
    int arg2,
  ) {
    return _bind(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _bindPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<sockaddr>, socklen_t)>>('bind');
  late final _bind =
      _bindPtr.asFunction<int Function(int, ffi.Pointer<sockaddr>, int)>();

  int connect(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
    int arg2,
  ) {
    return _connect(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _connectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, ffi.Pointer<sockaddr>, socklen_t)>>('connect');
  late final _connect =
      _connectPtr.asFunction<int Function(int, ffi.Pointer<sockaddr>, int)>();

  int getpeername(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
    ffi.Pointer<socklen_t> arg2,
  ) {
    return _getpeername(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _getpeernamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<sockaddr>,
              ffi.Pointer<socklen_t>)>>('getpeername');
  late final _getpeername = _getpeernamePtr.asFunction<
      int Function(int, ffi.Pointer<sockaddr>, ffi.Pointer<socklen_t>)>();

  int getsockname(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
    ffi.Pointer<socklen_t> arg2,
  ) {
    return _getsockname(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _getsocknamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<sockaddr>,
              ffi.Pointer<socklen_t>)>>('getsockname');
  late final _getsockname = _getsocknamePtr.asFunction<
      int Function(int, ffi.Pointer<sockaddr>, ffi.Pointer<socklen_t>)>();

  int getsockopt(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Void> arg3,
    ffi.Pointer<socklen_t> arg4,
  ) {
    return _getsockopt(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _getsockoptPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>,
              ffi.Pointer<socklen_t>)>>('getsockopt');
  late final _getsockopt = _getsockoptPtr.asFunction<
      int Function(
          int, int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<socklen_t>)>();

  int listen(
    int arg0,
    int arg1,
  ) {
    return _listen(
      arg0,
      arg1,
    );
  }

  late final _listenPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int)>>('listen');
  late final _listen = _listenPtr.asFunction<int Function(int, int)>();

  int recv(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
    int arg3,
  ) {
    return _recv(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _recvPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(
              ffi.Int, ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int)>>('recv');
  late final _recv =
      _recvPtr.asFunction<int Function(int, ffi.Pointer<ffi.Void>, int, int)>();

  int recvfrom(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
    int arg3,
    ffi.Pointer<sockaddr> arg4,
    ffi.Pointer<socklen_t> arg5,
  ) {
    return _recvfrom(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final _recvfromPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Int, ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int,
              ffi.Pointer<sockaddr>, ffi.Pointer<socklen_t>)>>('recvfrom');
  late final _recvfrom = _recvfromPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<sockaddr>,
          ffi.Pointer<socklen_t>)>();

  int recvmsg(
    int arg0,
    ffi.Pointer<msghdr> arg1,
    int arg2,
  ) {
    return _recvmsg(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _recvmsgPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Int, ffi.Pointer<msghdr>, ffi.Int)>>('recvmsg');
  late final _recvmsg =
      _recvmsgPtr.asFunction<int Function(int, ffi.Pointer<msghdr>, int)>();

  int send(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
    int arg3,
  ) {
    return _send(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _sendPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(
              ffi.Int, ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int)>>('send');
  late final _send =
      _sendPtr.asFunction<int Function(int, ffi.Pointer<ffi.Void>, int, int)>();

  int sendmsg(
    int arg0,
    ffi.Pointer<msghdr> arg1,
    int arg2,
  ) {
    return _sendmsg(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _sendmsgPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Int, ffi.Pointer<msghdr>, ffi.Int)>>('sendmsg');
  late final _sendmsg =
      _sendmsgPtr.asFunction<int Function(int, ffi.Pointer<msghdr>, int)>();

  int sendto(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
    int arg3,
    ffi.Pointer<sockaddr> arg4,
    int arg5,
  ) {
    return _sendto(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final _sendtoPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Int, ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int,
              ffi.Pointer<sockaddr>, socklen_t)>>('sendto');
  late final _sendto = _sendtoPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<sockaddr>, int)>();

  int setsockopt(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return _setsockopt(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _setsockoptPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Void>,
              socklen_t)>>('setsockopt');
  late final _setsockopt = _setsockoptPtr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Void>, int)>();

  int shutdown(
    int arg0,
    int arg1,
  ) {
    return _shutdown(
      arg0,
      arg1,
    );
  }

  late final _shutdownPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int)>>(
          'shutdown');
  late final _shutdown = _shutdownPtr.asFunction<int Function(int, int)>();

  int sockatmark(
    int arg0,
  ) {
    return _sockatmark(
      arg0,
    );
  }

  late final _sockatmarkPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('sockatmark');
  late final _sockatmark = _sockatmarkPtr.asFunction<int Function(int)>();

  int socket(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return _socket(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _socketPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Int, ffi.Int)>>(
          'socket');
  late final _socket = _socketPtr.asFunction<int Function(int, int, int)>();

  int socketpair(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Int> arg3,
  ) {
    return _socketpair(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _socketpairPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, ffi.Int, ffi.Int, ffi.Pointer<ffi.Int>)>>('socketpair');
  late final _socketpair = _socketpairPtr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Int>)>();

  int sendfile(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<off_t> arg3,
    ffi.Pointer<sf_hdtr> arg4,
    int arg5,
  ) {
    return _sendfile(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final _sendfilePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Int, off_t, ffi.Pointer<off_t>,
              ffi.Pointer<sf_hdtr>, ffi.Int)>>('sendfile');
  late final _sendfile = _sendfilePtr.asFunction<
      int Function(
          int, int, int, ffi.Pointer<off_t>, ffi.Pointer<sf_hdtr>, int)>();

  void pfctlinput(
    int arg0,
    ffi.Pointer<sockaddr> arg1,
  ) {
    return _pfctlinput(
      arg0,
      arg1,
    );
  }

  late final _pfctlinputPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int, ffi.Pointer<sockaddr>)>>('pfctlinput');
  late final _pfctlinput =
      _pfctlinputPtr.asFunction<void Function(int, ffi.Pointer<sockaddr>)>();

  int connectx(
    int arg0,
    ffi.Pointer<sa_endpoints_t> arg1,
    int arg2,
    int arg3,
    ffi.Pointer<iovec> arg4,
    int arg5,
    ffi.Pointer<ffi.Size> arg6,
    ffi.Pointer<sae_connid_t> arg7,
  ) {
    return _connectx(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final _connectxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int,
              ffi.Pointer<sa_endpoints_t>,
              sae_associd_t,
              ffi.UnsignedInt,
              ffi.Pointer<iovec>,
              ffi.UnsignedInt,
              ffi.Pointer<ffi.Size>,
              ffi.Pointer<sae_connid_t>)>>('connectx');
  late final _connectx = _connectxPtr.asFunction<
      int Function(
          int,
          ffi.Pointer<sa_endpoints_t>,
          int,
          int,
          ffi.Pointer<iovec>,
          int,
          ffi.Pointer<ffi.Size>,
          ffi.Pointer<sae_connid_t>)>();

  int disconnectx(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return _disconnectx(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _disconnectxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, sae_associd_t, sae_connid_t)>>('disconnectx');
  late final _disconnectx =
      _disconnectxPtr.asFunction<int Function(int, int, int)>();

  /// @brief Returns the librdkafka version as integer.
  ///
  /// @returns Version integer.
  ///
  /// @sa See RD_KAFKA_VERSION for how to parse the integer format.
  /// @sa Use rd_kafka_version_str() to retreive the version as a string.
  int rd_kafka_version() {
    return _rd_kafka_version();
  }

  late final _rd_kafka_versionPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('rd_kafka_version');
  late final _rd_kafka_version =
      _rd_kafka_versionPtr.asFunction<int Function()>();

  /// @brief Returns the librdkafka version as string.
  ///
  /// @returns Version string
  ffi.Pointer<ffi.Char> rd_kafka_version_str() {
    return _rd_kafka_version_str();
  }

  late final _rd_kafka_version_strPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'rd_kafka_version_str');
  late final _rd_kafka_version_str =
      _rd_kafka_version_strPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// @brief Retrieve supported debug contexts for use with the \c \"debug\"
  /// configuration property. (runtime)
  ///
  /// @returns Comma-separated list of available debugging contexts.
  ffi.Pointer<ffi.Char> rd_kafka_get_debug_contexts() {
    return _rd_kafka_get_debug_contexts();
  }

  late final _rd_kafka_get_debug_contextsPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'rd_kafka_get_debug_contexts');
  late final _rd_kafka_get_debug_contexts = _rd_kafka_get_debug_contextsPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// @brief Returns the full list of error codes.
  void rd_kafka_get_err_descs(
    ffi.Pointer<ffi.Pointer<rd_kafka_err_desc>> errdescs,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_get_err_descs(
      errdescs,
      cntp,
    );
  }

  late final _rd_kafka_get_err_descsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_err_desc>>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_get_err_descs');
  late final _rd_kafka_get_err_descs = _rd_kafka_get_err_descsPtr.asFunction<
      void Function(ffi.Pointer<ffi.Pointer<rd_kafka_err_desc>>,
          ffi.Pointer<ffi.Size>)>();

  /// @brief Returns a human readable representation of a kafka error.
  ///
  /// @param err Error code to translate
  ffi.Pointer<ffi.Char> rd_kafka_err2str(
    int err,
  ) {
    return _rd_kafka_err2str(
      err,
    );
  }

  late final _rd_kafka_err2strPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_err2str');
  late final _rd_kafka_err2str =
      _rd_kafka_err2strPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @brief Returns the error code name (enum name).
  ///
  /// @param err Error code to translate
  ffi.Pointer<ffi.Char> rd_kafka_err2name(
    int err,
  ) {
    return _rd_kafka_err2name(
      err,
    );
  }

  late final _rd_kafka_err2namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_err2name');
  late final _rd_kafka_err2name =
      _rd_kafka_err2namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @brief Returns the last error code generated by a legacy API call
  /// in the current thread.
  ///
  /// The legacy APIs are the ones using errno to propagate error value, namely:
  /// - rd_kafka_topic_new()
  /// - rd_kafka_consume_start()
  /// - rd_kafka_consume_stop()
  /// - rd_kafka_consume()
  /// - rd_kafka_consume_batch()
  /// - rd_kafka_consume_callback()
  /// - rd_kafka_consume_queue()
  /// - rd_kafka_produce()
  ///
  /// The main use for this function is to avoid converting system \p errno
  /// values to rd_kafka_resp_err_t codes for legacy APIs.
  ///
  /// @remark The last error is stored per-thread, if multiple rd_kafka_t handles
  /// are used in the same application thread the developer needs to
  /// make sure rd_kafka_last_error() is called immediately after
  /// a failed API call.
  ///
  /// @remark errno propagation from librdkafka is not safe on Windows
  /// and should not be used, use rd_kafka_last_error() instead.
  int rd_kafka_last_error() {
    return _rd_kafka_last_error();
  }

  late final _rd_kafka_last_errorPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('rd_kafka_last_error');
  late final _rd_kafka_last_error =
      _rd_kafka_last_errorPtr.asFunction<int Function()>();

  /// @brief Converts the system errno value \p errnox to a rd_kafka_resp_err_t
  /// error code upon failure from the following functions:
  /// - rd_kafka_topic_new()
  /// - rd_kafka_consume_start()
  /// - rd_kafka_consume_stop()
  /// - rd_kafka_consume()
  /// - rd_kafka_consume_batch()
  /// - rd_kafka_consume_callback()
  /// - rd_kafka_consume_queue()
  /// - rd_kafka_produce()
  ///
  /// @param errnox  System errno value to convert
  ///
  /// @returns Appropriate error code for \p errnox
  ///
  /// @remark A better alternative is to call rd_kafka_last_error() immediately
  /// after any of the above functions return -1 or NULL.
  ///
  /// @deprecated Use rd_kafka_last_error() to retrieve the last error code
  /// set by the legacy librdkafka APIs.
  ///
  /// @sa rd_kafka_last_error()
  int rd_kafka_errno2err(
    int errnox,
  ) {
    return _rd_kafka_errno2err(
      errnox,
    );
  }

  late final _rd_kafka_errno2errPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int)>>(
          'rd_kafka_errno2err');
  late final _rd_kafka_errno2err =
      _rd_kafka_errno2errPtr.asFunction<int Function(int)>();

  /// @brief Returns the thread-local system errno
  ///
  /// On most platforms this is the same as \p errno but in case of different
  /// runtimes between library and application (e.g., Windows static DLLs)
  /// this provides a means for exposing the errno librdkafka uses.
  ///
  /// @remark The value is local to the current calling thread.
  ///
  /// @deprecated Use rd_kafka_last_error() to retrieve the last error code
  /// set by the legacy librdkafka APIs.
  int rd_kafka_errno() {
    return _rd_kafka_errno();
  }

  late final _rd_kafka_errnoPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('rd_kafka_errno');
  late final _rd_kafka_errno = _rd_kafka_errnoPtr.asFunction<int Function()>();

  /// @brief Returns the first fatal error set on this client instance,
  /// or RD_KAFKA_RESP_ERR_NO_ERROR if no fatal error has occurred.
  ///
  /// This function is to be used with the Idempotent Producer and \c error_cb
  /// to detect fatal errors.
  ///
  /// Generally all errors raised by \c error_cb are to be considered
  /// informational and temporary, the client will try to recover from all
  /// errors in a graceful fashion (by retrying, etc).
  ///
  /// However, some errors should logically be considered fatal to retain
  /// consistency; in particular a set of errors that may occur when using the
  /// Idempotent Producer and the in-order or exactly-once producer guarantees
  /// can't be satisfied.
  ///
  /// @param rk Client instance.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written to if there is a fatal error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if no fatal error has been raised, else
  /// any other error code.
  int rd_kafka_fatal_error(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_fatal_error(
      rk,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_fatal_errorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_fatal_error');
  late final _rd_kafka_fatal_error = _rd_kafka_fatal_errorPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Trigger a fatal error for testing purposes.
  ///
  /// Since there is no practical way to trigger real fatal errors in the
  /// idempotent producer, this method allows an application to trigger
  /// fabricated fatal errors in tests to check its error handling code.
  ///
  /// @param rk Client instance.
  /// @param err The underlying error code.
  /// @param reason A human readable error reason.
  /// Will be prefixed with "test_fatal_error: " to differentiate
  /// from real fatal errors.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if a fatal error was triggered, or
  /// RD_KAFKA_RESP_ERR__PREV_IN_PROGRESS if a previous fatal error
  /// has already been triggered.
  int rd_kafka_test_fatal_error(
    ffi.Pointer<rd_kafka_t> rk,
    int err,
    ffi.Pointer<ffi.Char> reason,
  ) {
    return _rd_kafka_test_fatal_error(
      rk,
      err,
      reason,
    );
  }

  late final _rd_kafka_test_fatal_errorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_t>, ffi.Int32,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_test_fatal_error');
  late final _rd_kafka_test_fatal_error =
      _rd_kafka_test_fatal_errorPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>, int, ffi.Pointer<ffi.Char>)>();

  /// @returns the error code for \p error or RD_KAFKA_RESP_ERR_NO_ERROR if
  /// \p error is NULL.
  int rd_kafka_error_code(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_code(
      error,
    );
  }

  late final _rd_kafka_error_codePtr = _lookup<
          ffi
          .NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_error_t>)>>(
      'rd_kafka_error_code');
  late final _rd_kafka_error_code = _rd_kafka_error_codePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @returns the error code name for \p error, e.g, "ERR_UNKNOWN_MEMBER_ID",
  /// or an empty string if \p error is NULL.
  ///
  /// @remark The lifetime of the returned pointer is the same as the error object.
  ///
  /// @sa rd_kafka_err2name()
  ffi.Pointer<ffi.Char> rd_kafka_error_name(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_name(
      error,
    );
  }

  late final _rd_kafka_error_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_error_t>)>>('rd_kafka_error_name');
  late final _rd_kafka_error_name = _rd_kafka_error_namePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @returns a human readable error string for \p error,
  /// or an empty string if \p error is NULL.
  ///
  /// @remark The lifetime of the returned pointer is the same as the error object.
  ffi.Pointer<ffi.Char> rd_kafka_error_string(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_string(
      error,
    );
  }

  late final _rd_kafka_error_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_error_t>)>>('rd_kafka_error_string');
  late final _rd_kafka_error_string = _rd_kafka_error_stringPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @returns 1 if the error is a fatal error, indicating that the client
  /// instance is no longer usable, else 0 (also if \p error is NULL).
  int rd_kafka_error_is_fatal(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_is_fatal(
      error,
    );
  }

  late final _rd_kafka_error_is_fatalPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_error_t>)>>(
      'rd_kafka_error_is_fatal');
  late final _rd_kafka_error_is_fatal = _rd_kafka_error_is_fatalPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @returns 1 if the operation may be retried,
  /// else 0 (also if \p error is NULL).
  int rd_kafka_error_is_retriable(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_is_retriable(
      error,
    );
  }

  late final _rd_kafka_error_is_retriablePtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_error_t>)>>(
      'rd_kafka_error_is_retriable');
  late final _rd_kafka_error_is_retriable = _rd_kafka_error_is_retriablePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @returns 1 if the error is an abortable transaction error in which case
  /// the application must call rd_kafka_abort_transaction() and
  /// start a new transaction with rd_kafka_begin_transaction() if it
  /// wishes to proceed with transactions.
  /// Else returns 0 (also if \p error is NULL).
  ///
  /// @remark The return value of this method is only valid for errors returned
  /// by the transactional API.
  int rd_kafka_error_txn_requires_abort(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_txn_requires_abort(
      error,
    );
  }

  late final _rd_kafka_error_txn_requires_abortPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_error_t>)>>(
      'rd_kafka_error_txn_requires_abort');
  late final _rd_kafka_error_txn_requires_abort =
      _rd_kafka_error_txn_requires_abortPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @brief Free and destroy an error object.
  ///
  /// @remark As a conveniance it is permitted to pass a NULL \p error.
  void rd_kafka_error_destroy(
    ffi.Pointer<rd_kafka_error_t> error,
  ) {
    return _rd_kafka_error_destroy(
      error,
    );
  }

  late final _rd_kafka_error_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_error_t>)>>(
      'rd_kafka_error_destroy');
  late final _rd_kafka_error_destroy = _rd_kafka_error_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_error_t>)>();

  /// @brief Create a new error object with error \p code and optional
  /// human readable error string in \p fmt.
  ///
  /// This method is mainly to be used for mocking errors in application test code.
  ///
  /// The returned object must be destroyed with rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_error_new(
    int code,
    ffi.Pointer<ffi.Char> fmt,
  ) {
    return _rd_kafka_error_new(
      code,
      fmt,
    );
  }

  late final _rd_kafka_error_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Int32, ffi.Pointer<ffi.Char>)>>('rd_kafka_error_new');
  late final _rd_kafka_error_new = _rd_kafka_error_newPtr.asFunction<
      ffi.Pointer<rd_kafka_error_t> Function(int, ffi.Pointer<ffi.Char>)>();

  /// @brief Destroy a rd_kafka_topic_partition_t.
  /// @remark This must not be called for elements in a topic partition list.
  void rd_kafka_topic_partition_destroy(
    ffi.Pointer<rd_kafka_topic_partition_t> rktpar,
  ) {
    return _rd_kafka_topic_partition_destroy(
      rktpar,
    );
  }

  late final _rd_kafka_topic_partition_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_topic_partition_t>)>>(
      'rd_kafka_topic_partition_destroy');
  late final _rd_kafka_topic_partition_destroy =
      _rd_kafka_topic_partition_destroyPtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_topic_partition_t>)>();

  /// @brief Sets the offset leader epoch (use -1 to clear).
  ///
  /// @param rktpar Partition object.
  /// @param leader_epoch Offset leader epoch, use -1 to reset.
  ///
  /// @remark See KIP-320 for more information.
  void rd_kafka_topic_partition_set_leader_epoch(
    ffi.Pointer<rd_kafka_topic_partition_t> rktpar,
    int leader_epoch,
  ) {
    return _rd_kafka_topic_partition_set_leader_epoch(
      rktpar,
      leader_epoch,
    );
  }

  late final _rd_kafka_topic_partition_set_leader_epochPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_topic_partition_t>,
              ffi.Int32)>>('rd_kafka_topic_partition_set_leader_epoch');
  late final _rd_kafka_topic_partition_set_leader_epoch =
      _rd_kafka_topic_partition_set_leader_epochPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_topic_partition_t>, int)>();

  /// @returns the offset leader epoch, if relevant and known,
  /// else -1.
  ///
  /// @param rktpar Partition object.
  ///
  /// @remark See KIP-320 for more information.
  int rd_kafka_topic_partition_get_leader_epoch(
    ffi.Pointer<rd_kafka_topic_partition_t> rktpar,
  ) {
    return _rd_kafka_topic_partition_get_leader_epoch(
      rktpar,
    );
  }

  late final _rd_kafka_topic_partition_get_leader_epochPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_topic_partition_t>)>>(
      'rd_kafka_topic_partition_get_leader_epoch');
  late final _rd_kafka_topic_partition_get_leader_epoch =
      _rd_kafka_topic_partition_get_leader_epochPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_topic_partition_t>)>();

  /// @brief Create a new list/vector Topic+Partition container.
  ///
  /// @param size  Initial allocated size used when the expected number of
  /// elements is known or can be estimated.
  /// Avoids reallocation and possibly relocation of the
  /// elems array.
  ///
  /// @returns A newly allocated Topic+Partition list.
  ///
  /// @remark Use rd_kafka_topic_partition_list_destroy() to free all resources
  /// in use by a list and the list itself.
  /// @sa     rd_kafka_topic_partition_list_add()
  ffi.Pointer<rd_kafka_topic_partition_list_t>
      rd_kafka_topic_partition_list_new(
    int size,
  ) {
    return _rd_kafka_topic_partition_list_new(
      size,
    );
  }

  late final _rd_kafka_topic_partition_list_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Int)>>('rd_kafka_topic_partition_list_new');
  late final _rd_kafka_topic_partition_list_new =
      _rd_kafka_topic_partition_list_newPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(int)>();

  /// @brief Free all resources used by the list and the list itself.
  void rd_kafka_topic_partition_list_destroy(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rkparlist,
  ) {
    return _rd_kafka_topic_partition_list_destroy(
      rkparlist,
    );
  }

  late final _rd_kafka_topic_partition_list_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_topic_partition_list_destroy');
  late final _rd_kafka_topic_partition_list_destroy =
      _rd_kafka_topic_partition_list_destroyPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Add topic+partition to list
  ///
  /// @param rktparlist List to extend
  /// @param topic      Topic name (copied)
  /// @param partition  Partition id
  ///
  /// @returns The object which can be used to fill in additionals fields.
  ffi.Pointer<rd_kafka_topic_partition_t> rd_kafka_topic_partition_list_add(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<ffi.Char> topic,
    int partition,
  ) {
    return _rd_kafka_topic_partition_list_add(
      rktparlist,
      topic,
      partition,
    );
  }

  late final _rd_kafka_topic_partition_list_addPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('rd_kafka_topic_partition_list_add');
  late final _rd_kafka_topic_partition_list_add =
      _rd_kafka_topic_partition_list_addPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              int)>();

  /// @brief Add range of partitions from \p start to \p stop inclusive.
  ///
  /// @param rktparlist List to extend
  /// @param topic      Topic name (copied)
  /// @param start      Start partition of range
  /// @param stop       Last partition of range (inclusive)
  void rd_kafka_topic_partition_list_add_range(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<ffi.Char> topic,
    int start,
    int stop,
  ) {
    return _rd_kafka_topic_partition_list_add_range(
      rktparlist,
      topic,
      start,
      stop,
    );
  }

  late final _rd_kafka_topic_partition_list_add_rangePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Int32)>>('rd_kafka_topic_partition_list_add_range');
  late final _rd_kafka_topic_partition_list_add_range =
      _rd_kafka_topic_partition_list_add_rangePtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>, int, int)>();

  /// @brief Delete partition from list.
  ///
  /// @param rktparlist List to modify
  /// @param topic      Topic name to match
  /// @param partition  Partition to match
  ///
  /// @returns 1 if partition was found (and removed), else 0.
  ///
  /// @remark Any held indices to elems[] are unusable after this call returns 1.
  int rd_kafka_topic_partition_list_del(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<ffi.Char> topic,
    int partition,
  ) {
    return _rd_kafka_topic_partition_list_del(
      rktparlist,
      topic,
      partition,
    );
  }

  late final _rd_kafka_topic_partition_list_delPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('rd_kafka_topic_partition_list_del');
  late final _rd_kafka_topic_partition_list_del =
      _rd_kafka_topic_partition_list_delPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Delete partition from list by elems[] index.
  ///
  /// @returns 1 if partition was found (and removed), else 0.
  ///
  /// @sa rd_kafka_topic_partition_list_del()
  int rd_kafka_topic_partition_list_del_by_idx(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    int idx,
  ) {
    return _rd_kafka_topic_partition_list_del_by_idx(
      rktparlist,
      idx,
    );
  }

  late final _rd_kafka_topic_partition_list_del_by_idxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Int)>>('rd_kafka_topic_partition_list_del_by_idx');
  late final _rd_kafka_topic_partition_list_del_by_idx =
      _rd_kafka_topic_partition_list_del_by_idxPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_partition_list_t>, int)>();

  /// @brief Make a copy of an existing list.
  ///
  /// @param src   The existing list to copy.
  ///
  /// @returns A new list fully populated to be identical to \p src
  ffi.Pointer<rd_kafka_topic_partition_list_t>
      rd_kafka_topic_partition_list_copy(
    ffi.Pointer<rd_kafka_topic_partition_list_t> src,
  ) {
    return _rd_kafka_topic_partition_list_copy(
      src,
    );
  }

  late final _rd_kafka_topic_partition_list_copyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_topic_partition_list_copy');
  late final _rd_kafka_topic_partition_list_copy =
      _rd_kafka_topic_partition_list_copyPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Set offset to \p offset for \p topic and \p partition
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or
  /// RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION if \p partition was not found
  /// in the list.
  int rd_kafka_topic_partition_list_set_offset(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<ffi.Char> topic,
    int partition,
    int offset,
  ) {
    return _rd_kafka_topic_partition_list_set_offset(
      rktparlist,
      topic,
      partition,
      offset,
    );
  }

  late final _rd_kafka_topic_partition_list_set_offsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Int64)>>('rd_kafka_topic_partition_list_set_offset');
  late final _rd_kafka_topic_partition_list_set_offset =
      _rd_kafka_topic_partition_list_set_offsetPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>, int, int)>();

  /// @brief Find element by \p topic and \p partition.
  ///
  /// @returns a pointer to the first matching element, or NULL if not found.
  ffi.Pointer<rd_kafka_topic_partition_t> rd_kafka_topic_partition_list_find(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<ffi.Char> topic,
    int partition,
  ) {
    return _rd_kafka_topic_partition_list_find(
      rktparlist,
      topic,
      partition,
    );
  }

  late final _rd_kafka_topic_partition_list_findPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('rd_kafka_topic_partition_list_find');
  late final _rd_kafka_topic_partition_list_find =
      _rd_kafka_topic_partition_list_findPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<ffi.Char>,
              int)>();

  /// @brief Sort list using comparator \p cmp.
  ///
  /// If \p cmp is NULL the default comparator will be used that
  /// sorts by ascending topic name and partition.
  ///
  /// \p cmp_opaque is provided as the \p cmp_opaque argument to \p cmp.
  void rd_kafka_topic_partition_list_sort(
    ffi.Pointer<rd_kafka_topic_partition_list_t> rktparlist,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Void> a,
                    ffi.Pointer<ffi.Void> b, ffi.Pointer<ffi.Void> cmp_opaque)>>
        cmp,
    ffi.Pointer<ffi.Void> cmp_opaque,
  ) {
    return _rd_kafka_topic_partition_list_sort(
      rktparlist,
      cmp,
      cmp_opaque,
    );
  }

  late final _rd_kafka_topic_partition_list_sortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Void> a,
                          ffi.Pointer<ffi.Void> b,
                          ffi.Pointer<ffi.Void> cmp_opaque)>>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_topic_partition_list_sort');
  late final _rd_kafka_topic_partition_list_sort =
      _rd_kafka_topic_partition_list_sortPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Void> a,
                          ffi.Pointer<ffi.Void> b,
                          ffi.Pointer<ffi.Void> cmp_opaque)>>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Create a new headers list.
  ///
  /// @param initial_count Preallocate space for this number of headers.
  /// Any number of headers may be added, updated and
  /// removed regardless of the initial count.
  ffi.Pointer<rd_kafka_headers_t> rd_kafka_headers_new(
    int initial_count,
  ) {
    return _rd_kafka_headers_new(
      initial_count,
    );
  }

  late final _rd_kafka_headers_newPtr = _lookup<
          ffi
          .NativeFunction<ffi.Pointer<rd_kafka_headers_t> Function(ffi.Size)>>(
      'rd_kafka_headers_new');
  late final _rd_kafka_headers_new = _rd_kafka_headers_newPtr
      .asFunction<ffi.Pointer<rd_kafka_headers_t> Function(int)>();

  /// @brief Destroy the headers list. The object and any returned value pointers
  /// are not usable after this call.
  void rd_kafka_headers_destroy(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
  ) {
    return _rd_kafka_headers_destroy(
      hdrs,
    );
  }

  late final _rd_kafka_headers_destroyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_headers_t>)>>(
      'rd_kafka_headers_destroy');
  late final _rd_kafka_headers_destroy = _rd_kafka_headers_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_headers_t>)>();

  /// @brief Make a copy of headers list \p src.
  ffi.Pointer<rd_kafka_headers_t> rd_kafka_headers_copy(
    ffi.Pointer<rd_kafka_headers_t> src,
  ) {
    return _rd_kafka_headers_copy(
      src,
    );
  }

  late final _rd_kafka_headers_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_headers_t> Function(
              ffi.Pointer<rd_kafka_headers_t>)>>('rd_kafka_headers_copy');
  late final _rd_kafka_headers_copy = _rd_kafka_headers_copyPtr.asFunction<
      ffi.Pointer<rd_kafka_headers_t> Function(
          ffi.Pointer<rd_kafka_headers_t>)>();

  /// @brief Add header with name \p name and value \p val (copied) of size
  /// \p size (not including null-terminator).
  ///
  /// @param hdrs       Headers list.
  /// @param name       Header name.
  /// @param name_size  Header name size (not including the null-terminator).
  /// If -1 the \p name length is automatically acquired using
  /// strlen().
  /// @param value      Pointer to header value, or NULL (set size to 0 or -1).
  /// @param value_size Size of header value. If -1 the \p value is assumed to be a
  /// null-terminated string and the length is automatically
  /// acquired using strlen().
  ///
  /// @returns RD_KAFKA_RESP_ERR__READ_ONLY if the headers are read-only,
  /// else RD_KAFKA_RESP_ERR_NO_ERROR.
  int rd_kafka_header_add(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
    ffi.Pointer<ffi.Char> name,
    int name_size,
    ffi.Pointer<ffi.Void> value,
    int value_size,
  ) {
    return _rd_kafka_header_add(
      hdrs,
      name,
      name_size,
      value,
      value_size,
    );
  }

  late final _rd_kafka_header_addPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_headers_t>,
              ffi.Pointer<ffi.Char>,
              ssize_t,
              ffi.Pointer<ffi.Void>,
              ssize_t)>>('rd_kafka_header_add');
  late final _rd_kafka_header_add = _rd_kafka_header_addPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_headers_t>, ffi.Pointer<ffi.Char>, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// @brief Remove all headers for the given key (if any).
  ///
  /// @returns RD_KAFKA_RESP_ERR__READ_ONLY if the headers are read-only,
  /// RD_KAFKA_RESP_ERR__NOENT if no matching headers were found,
  /// else RD_KAFKA_RESP_ERR_NO_ERROR if headers were removed.
  int rd_kafka_header_remove(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _rd_kafka_header_remove(
      hdrs,
      name,
    );
  }

  late final _rd_kafka_header_removePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_headers_t>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_header_remove');
  late final _rd_kafka_header_remove = _rd_kafka_header_removePtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_headers_t>, ffi.Pointer<ffi.Char>)>();

  /// @brief Find last header in list \p hdrs matching \p name.
  ///
  /// @param hdrs   Headers list.
  /// @param name   Header to find (last match).
  /// @param valuep (out) Set to a (null-terminated) const pointer to the value
  /// (may be NULL).
  /// @param sizep  (out) Set to the value's size (not including null-terminator).
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if an entry was found, else
  /// RD_KAFKA_RESP_ERR__NOENT.
  ///
  /// @remark The returned pointer in \p valuep includes a trailing null-terminator
  /// that is not accounted for in \p sizep.
  /// @remark The returned pointer is only valid as long as the headers list and
  /// the header item is valid.
  int rd_kafka_header_get_last(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Pointer<ffi.Void>> valuep,
    ffi.Pointer<ffi.Size> sizep,
  ) {
    return _rd_kafka_header_get_last(
      hdrs,
      name,
      valuep,
      sizep,
    );
  }

  late final _rd_kafka_header_get_lastPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_headers_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_header_get_last');
  late final _rd_kafka_header_get_last =
      _rd_kafka_header_get_lastPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_headers_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Size>)>();

  /// @brief Iterator for headers matching \p name.
  ///
  /// Same semantics as rd_kafka_header_get_last()
  ///
  /// @param hdrs   Headers to iterate.
  /// @param idx    Iterator index, start at 0 and increment by one for each call
  /// as long as RD_KAFKA_RESP_ERR_NO_ERROR is returned.
  /// @param name   Header name to match.
  /// @param valuep (out) Set to a (null-terminated) const pointer to the value
  /// (may be NULL).
  /// @param sizep  (out) Set to the value's size (not including null-terminator).
  int rd_kafka_header_get(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
    int idx,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Pointer<ffi.Void>> valuep,
    ffi.Pointer<ffi.Size> sizep,
  ) {
    return _rd_kafka_header_get(
      hdrs,
      idx,
      name,
      valuep,
      sizep,
    );
  }

  late final _rd_kafka_header_getPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_headers_t>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_header_get');
  late final _rd_kafka_header_get = _rd_kafka_header_getPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_headers_t>, int, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Size>)>();

  /// @brief Iterator for all headers.
  ///
  /// Same semantics as rd_kafka_header_get()
  ///
  /// @sa rd_kafka_header_get()
  int rd_kafka_header_get_all(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
    int idx,
    ffi.Pointer<ffi.Pointer<ffi.Char>> namep,
    ffi.Pointer<ffi.Pointer<ffi.Void>> valuep,
    ffi.Pointer<ffi.Size> sizep,
  ) {
    return _rd_kafka_header_get_all(
      hdrs,
      idx,
      namep,
      valuep,
      sizep,
    );
  }

  late final _rd_kafka_header_get_allPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_headers_t>,
              ffi.Size,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_header_get_all');
  late final _rd_kafka_header_get_all = _rd_kafka_header_get_allPtr.asFunction<
      int Function(
          ffi.Pointer<rd_kafka_headers_t>,
          int,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Void>>,
          ffi.Pointer<ffi.Size>)>();

  /// @brief Frees resources for \p rkmessage and hands ownership back to rdkafka.
  void rd_kafka_message_destroy(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_destroy(
      rkmessage,
    );
  }

  late final _rd_kafka_message_destroyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_destroy');
  late final _rd_kafka_message_destroy = _rd_kafka_message_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Returns the error string for an errored rd_kafka_message_t or NULL if
  /// there was no error.
  ///
  /// @remark This function MUST NOT be used with the producer.
  ffi.Pointer<ffi.Char> rd_kafka_message_errstr(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_errstr(
      rkmessage,
    );
  }

  late final _rd_kafka_message_errstrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_message_t>)>>('rd_kafka_message_errstr');
  late final _rd_kafka_message_errstr = _rd_kafka_message_errstrPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Returns the error string for an errored produced rd_kafka_message_t or
  /// NULL if there was no error.
  ///
  /// @remark This function MUST used with the producer.
  ffi.Pointer<ffi.Char> rd_kafka_message_produce_errstr(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_produce_errstr(
      rkmessage,
    );
  }

  late final _rd_kafka_message_produce_errstrPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_produce_errstr');
  late final _rd_kafka_message_produce_errstr =
      _rd_kafka_message_produce_errstrPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Returns the message timestamp for a consumed message.
  ///
  /// The timestamp is the number of milliseconds since the epoch (UTC).
  ///
  /// \p tstype (if not NULL) is updated to indicate the type of timestamp.
  ///
  /// @returns message timestamp, or -1 if not available.
  ///
  /// @remark Message timestamps require broker version 0.10.0 or later.
  int rd_kafka_message_timestamp(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
    ffi.Pointer<ffi.Int32> tstype,
  ) {
    return _rd_kafka_message_timestamp(
      rkmessage,
      tstype,
    );
  }

  late final _rd_kafka_message_timestampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<rd_kafka_message_t>,
              ffi.Pointer<ffi.Int32>)>>('rd_kafka_message_timestamp');
  late final _rd_kafka_message_timestamp =
      _rd_kafka_message_timestampPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_message_t>, ffi.Pointer<ffi.Int32>)>();

  /// @brief Returns the latency for a produced message measured from
  /// the produce() call.
  ///
  /// @returns the latency in microseconds, or -1 if not available.
  int rd_kafka_message_latency(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_latency(
      rkmessage,
    );
  }

  late final _rd_kafka_message_latencyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int64 Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_latency');
  late final _rd_kafka_message_latency = _rd_kafka_message_latencyPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Returns the broker id of the broker the message was produced to
  /// or fetched from.
  ///
  /// @returns a broker id if known, else -1.
  int rd_kafka_message_broker_id(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_broker_id(
      rkmessage,
    );
  }

  late final _rd_kafka_message_broker_idPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_broker_id');
  late final _rd_kafka_message_broker_id = _rd_kafka_message_broker_idPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Get the message header list.
  ///
  /// The returned pointer in \p *hdrsp is associated with the \p rkmessage and
  /// must not be used after destruction of the message object or the header
  /// list is replaced with rd_kafka_message_set_headers().
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if headers were returned,
  /// RD_KAFKA_RESP_ERR__NOENT if the message has no headers,
  /// or another error code if the headers could not be parsed.
  ///
  /// @remark Headers require broker version 0.11.0.0 or later.
  ///
  /// @remark As an optimization the raw protocol headers are parsed on
  /// the first call to this function.
  int rd_kafka_message_headers(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
    ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>> hdrsp,
  ) {
    return _rd_kafka_message_headers(
      rkmessage,
      hdrsp,
    );
  }

  late final _rd_kafka_message_headersPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_message_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>>)>>(
      'rd_kafka_message_headers');
  late final _rd_kafka_message_headers =
      _rd_kafka_message_headersPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_message_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>>)>();

  /// @brief Get the message header list and detach the list from the message
  /// making the application the owner of the headers.
  /// The application must eventually destroy the headers using
  /// rd_kafka_headers_destroy().
  /// The message's headers will be set to NULL.
  ///
  /// Otherwise same semantics as rd_kafka_message_headers()
  ///
  /// @sa rd_kafka_message_headers
  int rd_kafka_message_detach_headers(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
    ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>> hdrsp,
  ) {
    return _rd_kafka_message_detach_headers(
      rkmessage,
      hdrsp,
    );
  }

  late final _rd_kafka_message_detach_headersPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_message_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>>)>>(
      'rd_kafka_message_detach_headers');
  late final _rd_kafka_message_detach_headers =
      _rd_kafka_message_detach_headersPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_message_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_headers_t>>)>();

  /// @brief Replace the message's current headers with a new list.
  ///
  /// @param rkmessage The message to set headers.
  /// @param hdrs New header list. The message object assumes ownership of
  /// the list, the list will be destroyed automatically with
  /// the message object.
  /// The new headers list may be updated until the message object
  /// is passed or returned to librdkafka.
  ///
  /// @remark The existing headers object, if any, will be destroyed.
  void rd_kafka_message_set_headers(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
    ffi.Pointer<rd_kafka_headers_t> hdrs,
  ) {
    return _rd_kafka_message_set_headers(
      rkmessage,
      hdrs,
    );
  }

  late final _rd_kafka_message_set_headersPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_message_t>,
                  ffi.Pointer<rd_kafka_headers_t>)>>(
      'rd_kafka_message_set_headers');
  late final _rd_kafka_message_set_headers =
      _rd_kafka_message_set_headersPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_message_t>,
              ffi.Pointer<rd_kafka_headers_t>)>();

  /// @brief Returns the number of header key/value pairs
  ///
  /// @param hdrs   Headers to count
  int rd_kafka_header_cnt(
    ffi.Pointer<rd_kafka_headers_t> hdrs,
  ) {
    return _rd_kafka_header_cnt(
      hdrs,
    );
  }

  late final _rd_kafka_header_cntPtr = _lookup<
          ffi
          .NativeFunction<ffi.Size Function(ffi.Pointer<rd_kafka_headers_t>)>>(
      'rd_kafka_header_cnt');
  late final _rd_kafka_header_cnt = _rd_kafka_header_cntPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_headers_t>)>();

  /// @brief Returns the message's persistence status in the topic log.
  ///
  /// @remark The message status is not available in on_acknowledgement
  /// interceptors.
  int rd_kafka_message_status(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_status(
      rkmessage,
    );
  }

  late final _rd_kafka_message_statusPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_status');
  late final _rd_kafka_message_status = _rd_kafka_message_statusPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @returns the message's partition leader epoch at the time the message was
  /// fetched and if known, else -1.
  ///
  /// @remark This API must only be used on consumed messages without error.
  /// @remark Requires broker version >= 2.10 (KIP-320).
  int rd_kafka_message_leader_epoch(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_message_leader_epoch(
      rkmessage,
    );
  }

  late final _rd_kafka_message_leader_epochPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_message_leader_epoch');
  late final _rd_kafka_message_leader_epoch = _rd_kafka_message_leader_epochPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Computes base64 encoding for the given uuid string.
  /// @param uuid UUID for which base64 encoding is required.
  ///
  /// @return base64 encoded string for the given UUID or NULL in case of some
  /// issue with the conversion or the conversion is not supported.
  ffi.Pointer<ffi.Char> rd_kafka_Uuid_base64str(
    ffi.Pointer<rd_kafka_Uuid_t> uuid,
  ) {
    return _rd_kafka_Uuid_base64str(
      uuid,
    );
  }

  late final _rd_kafka_Uuid_base64strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_Uuid_t>)>>('rd_kafka_Uuid_base64str');
  late final _rd_kafka_Uuid_base64str = _rd_kafka_Uuid_base64strPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_Uuid_t>)>();

  /// @brief Gets least significant 64 bits for the given UUID.
  ///
  /// @param uuid UUID
  ///
  /// @return least significant 64 bits for the given UUID.
  int rd_kafka_Uuid_least_significant_bits(
    ffi.Pointer<rd_kafka_Uuid_t> uuid,
  ) {
    return _rd_kafka_Uuid_least_significant_bits(
      uuid,
    );
  }

  late final _rd_kafka_Uuid_least_significant_bitsPtr = _lookup<
          ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<rd_kafka_Uuid_t>)>>(
      'rd_kafka_Uuid_least_significant_bits');
  late final _rd_kafka_Uuid_least_significant_bits =
      _rd_kafka_Uuid_least_significant_bitsPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_Uuid_t>)>();

  /// @brief Gets most significant 64 bits for the given UUID.
  ///
  /// @param uuid UUID
  ///
  /// @return most significant 64 bits for the given UUID.
  int rd_kafka_Uuid_most_significant_bits(
    ffi.Pointer<rd_kafka_Uuid_t> uuid,
  ) {
    return _rd_kafka_Uuid_most_significant_bits(
      uuid,
    );
  }

  late final _rd_kafka_Uuid_most_significant_bitsPtr = _lookup<
          ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<rd_kafka_Uuid_t>)>>(
      'rd_kafka_Uuid_most_significant_bits');
  late final _rd_kafka_Uuid_most_significant_bits =
      _rd_kafka_Uuid_most_significant_bitsPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_Uuid_t>)>();

  /// @brief Creates a new UUID.
  ///
  /// @param most_significant_bits most significant 64 bits of the 128 bits UUID.
  /// @param least_significant_bits least significant 64 bits of the 128 bits UUID.
  ///
  /// @return A newly allocated UUID.
  /// @remark Must be freed after use using rd_kafka_Uuid_destroy()
  ffi.Pointer<rd_kafka_Uuid_t> rd_kafka_Uuid_new(
    int most_significant_bits,
    int least_significant_bits,
  ) {
    return _rd_kafka_Uuid_new(
      most_significant_bits,
      least_significant_bits,
    );
  }

  late final _rd_kafka_Uuid_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_Uuid_t> Function(
              ffi.Int64, ffi.Int64)>>('rd_kafka_Uuid_new');
  late final _rd_kafka_Uuid_new = _rd_kafka_Uuid_newPtr
      .asFunction<ffi.Pointer<rd_kafka_Uuid_t> Function(int, int)>();

  /// @brief Copies the given UUID.
  ///
  /// @param uuid UUID to be copied.
  ///
  /// @return A newly allocated copy of the provided UUID.
  /// @remark Must be freed after use using rd_kafka_Uuid_destroy()
  ffi.Pointer<rd_kafka_Uuid_t> rd_kafka_Uuid_copy(
    ffi.Pointer<rd_kafka_Uuid_t> uuid,
  ) {
    return _rd_kafka_Uuid_copy(
      uuid,
    );
  }

  late final _rd_kafka_Uuid_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_Uuid_t> Function(
              ffi.Pointer<rd_kafka_Uuid_t>)>>('rd_kafka_Uuid_copy');
  late final _rd_kafka_Uuid_copy = _rd_kafka_Uuid_copyPtr.asFunction<
      ffi.Pointer<rd_kafka_Uuid_t> Function(ffi.Pointer<rd_kafka_Uuid_t>)>();

  /// @brief Destroy the provided uuid.
  ///
  /// @param uuid UUID
  void rd_kafka_Uuid_destroy(
    ffi.Pointer<rd_kafka_Uuid_t> uuid,
  ) {
    return _rd_kafka_Uuid_destroy(
      uuid,
    );
  }

  late final _rd_kafka_Uuid_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_Uuid_t>)>>(
      'rd_kafka_Uuid_destroy');
  late final _rd_kafka_Uuid_destroy = _rd_kafka_Uuid_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_Uuid_t>)>();

  /// @brief Create configuration object.
  ///
  /// When providing your own configuration to the \c rd_kafka_*_new_*() calls
  /// the rd_kafka_conf_t objects needs to be created with this function
  /// which will set up the defaults.
  /// I.e.:
  /// @code
  /// rd_kafka_conf_t *myconf;
  /// rd_kafka_conf_res_t res;
  ///
  /// myconf = rd_kafka_conf_new();
  /// res = rd_kafka_conf_set(myconf, "socket.timeout.ms", "600",
  /// errstr, sizeof(errstr));
  /// if (res != RD_KAFKA_CONF_OK)
  /// die("%s\n", errstr);
  ///
  /// rk = rd_kafka_new(..., myconf);
  /// @endcode
  ///
  /// Please see CONFIGURATION.md for the default settings or use
  /// rd_kafka_conf_properties_show() to provide the information at runtime.
  ///
  /// The properties are identical to the Apache Kafka configuration properties
  /// whenever possible.
  ///
  /// @remark A successful call to rd_kafka_new() will assume ownership of
  /// the conf object and rd_kafka_conf_destroy() must not be called.
  ///
  /// @returns A new rd_kafka_conf_t object with defaults set.
  ///
  /// @sa rd_kafka_new(), rd_kafka_conf_set(), rd_kafka_conf_destroy()
  ffi.Pointer<rd_kafka_conf_t> rd_kafka_conf_new() {
    return _rd_kafka_conf_new();
  }

  late final _rd_kafka_conf_newPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<rd_kafka_conf_t> Function()>>(
          'rd_kafka_conf_new');
  late final _rd_kafka_conf_new = _rd_kafka_conf_newPtr
      .asFunction<ffi.Pointer<rd_kafka_conf_t> Function()>();

  /// @brief Destroys a conf object.
  void rd_kafka_conf_destroy(
    ffi.Pointer<rd_kafka_conf_t> conf,
  ) {
    return _rd_kafka_conf_destroy(
      conf,
    );
  }

  late final _rd_kafka_conf_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_conf_t>)>>(
      'rd_kafka_conf_destroy');
  late final _rd_kafka_conf_destroy = _rd_kafka_conf_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_conf_t>)>();

  /// @brief Creates a copy/duplicate of configuration object \p conf
  ///
  /// @remark Interceptors are NOT copied to the new configuration object.
  /// @sa rd_kafka_interceptor_f_on_conf_dup
  ffi.Pointer<rd_kafka_conf_t> rd_kafka_conf_dup(
    ffi.Pointer<rd_kafka_conf_t> conf,
  ) {
    return _rd_kafka_conf_dup(
      conf,
    );
  }

  late final _rd_kafka_conf_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_conf_t> Function(
              ffi.Pointer<rd_kafka_conf_t>)>>('rd_kafka_conf_dup');
  late final _rd_kafka_conf_dup = _rd_kafka_conf_dupPtr.asFunction<
      ffi.Pointer<rd_kafka_conf_t> Function(ffi.Pointer<rd_kafka_conf_t>)>();

  /// @brief Same as rd_kafka_conf_dup() but with an array of property name
  /// prefixes to filter out (ignore) when copying.
  ffi.Pointer<rd_kafka_conf_t> rd_kafka_conf_dup_filter(
    ffi.Pointer<rd_kafka_conf_t> conf,
    int filter_cnt,
    ffi.Pointer<ffi.Pointer<ffi.Char>> filter,
  ) {
    return _rd_kafka_conf_dup_filter(
      conf,
      filter_cnt,
      filter,
    );
  }

  late final _rd_kafka_conf_dup_filterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_conf_t> Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Size,
              ffi.Pointer<ffi.Pointer<ffi.Char>>)>>('rd_kafka_conf_dup_filter');
  late final _rd_kafka_conf_dup_filter =
      _rd_kafka_conf_dup_filterPtr.asFunction<
          ffi.Pointer<rd_kafka_conf_t> Function(ffi.Pointer<rd_kafka_conf_t>,
              int, ffi.Pointer<ffi.Pointer<ffi.Char>>)>();

  /// @returns the configuration object used by an rd_kafka_t instance.
  /// For use with rd_kafka_conf_get(), et.al., to extract configuration
  /// properties from a running client.
  ///
  /// @remark the returned object is read-only and its lifetime is the same
  /// as the rd_kafka_t object.
  ffi.Pointer<rd_kafka_conf_t> rd_kafka_conf(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_conf(
      rk,
    );
  }

  late final _rd_kafka_confPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_conf_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_conf');
  late final _rd_kafka_conf = _rd_kafka_confPtr.asFunction<
      ffi.Pointer<rd_kafka_conf_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Sets a configuration property.
  ///
  /// \p conf must have been previously created with rd_kafka_conf_new().
  ///
  /// Fallthrough:
  /// Topic-level configuration properties may be set using this interface
  /// in which case they are applied on the \c default_topic_conf.
  /// If no \c default_topic_conf has been set one will be created.
  /// Any subsequent rd_kafka_conf_set_default_topic_conf() calls will
  /// replace the current default topic configuration.
  ///
  /// @returns \c rd_kafka_conf_res_t to indicate success or failure.
  /// In case of failure \p errstr is updated to contain a human readable
  /// error string.
  ///
  /// @remark Setting properties or values that were disabled at build time due to
  /// missing dependencies will return RD_KAFKA_CONF_INVALID.
  int rd_kafka_conf_set(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> value,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_conf_set(
      conf,
      name,
      value,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_conf_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_conf_set');
  late final _rd_kafka_conf_set = _rd_kafka_conf_setPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Enable event sourcing.
  /// \p events is a bitmask of \c RD_KAFKA_EVENT_* of events to enable
  /// for consumption by `rd_kafka_queue_poll()`.
  void rd_kafka_conf_set_events(
    ffi.Pointer<rd_kafka_conf_t> conf,
    int events,
  ) {
    return _rd_kafka_conf_set_events(
      conf,
      events,
    );
  }

  late final _rd_kafka_conf_set_eventsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_conf_t>,
              ffi.Int)>>('rd_kafka_conf_set_events');
  late final _rd_kafka_conf_set_events = _rd_kafka_conf_set_eventsPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_conf_t>, int)>();

  /// @brief Generic event callback to be used with the event API to trigger
  /// callbacks for \c rd_kafka_event_t objects from a background
  /// thread serving the background queue.
  ///
  /// How to use:
  /// 1. First set the event callback on the configuration object with this
  /// function, followed by creating an rd_kafka_t instance
  /// with rd_kafka_new().
  /// 2. Get the instance's background queue with rd_kafka_queue_get_background()
  /// and pass it as the reply/response queue to an API that takes an
  /// event queue, such as rd_kafka_CreateTopics().
  /// 3. As the response event is ready and enqueued on the background queue the
  /// event callback will be triggered from the background thread.
  /// 4. Prior to destroying the client instance, loose your reference to the
  /// background queue by calling rd_kafka_queue_destroy().
  ///
  /// The application must destroy the \c rkev passed to \p event cb using
  /// rd_kafka_event_destroy().
  ///
  /// The \p event_cb \c opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark This callback is a specialized alternative to the poll-based
  /// event API described in the Event interface section.
  ///
  /// @remark The \p event_cb will be called spontaneously from a background
  /// thread completely managed by librdkafka.
  /// Take care to perform proper locking of application objects.
  ///
  /// @warning The application MUST NOT call rd_kafka_destroy() from the
  /// event callback.
  ///
  /// @sa rd_kafka_queue_get_background
  void rd_kafka_conf_set_background_event_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<rd_kafka_event_t> rkev,
                    ffi.Pointer<ffi.Void> opaque)>>
        event_cb,
  ) {
    return _rd_kafka_conf_set_background_event_cb(
      conf,
      event_cb,
    );
  }

  late final _rd_kafka_conf_set_background_event_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<rd_kafka_event_t> rkev,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_background_event_cb');
  late final _rd_kafka_conf_set_background_event_cb =
      _rd_kafka_conf_set_background_event_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<rd_kafka_event_t> rkev,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @deprecated See rd_kafka_conf_set_dr_msg_cb()
  void rd_kafka_conf_set_dr_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Void> payload,
                    ffi.Size len,
                    ffi.Int32 err,
                    ffi.Pointer<ffi.Void> opaque,
                    ffi.Pointer<ffi.Void> msg_opaque)>>
        dr_cb,
  ) {
    return _rd_kafka_conf_set_dr_cb(
      conf,
      dr_cb,
    );
  }

  late final _rd_kafka_conf_set_dr_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<ffi.Void> payload,
                              ffi.Size len,
                              ffi.Int32 err,
                              ffi.Pointer<ffi.Void> opaque,
                              ffi.Pointer<ffi.Void> msg_opaque)>>)>>(
      'rd_kafka_conf_set_dr_cb');
  late final _rd_kafka_conf_set_dr_cb = _rd_kafka_conf_set_dr_cbPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_conf_t>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Void Function(
                      ffi.Pointer<rd_kafka_t> rk,
                      ffi.Pointer<ffi.Void> payload,
                      ffi.Size len,
                      ffi.Int32 err,
                      ffi.Pointer<ffi.Void> opaque,
                      ffi.Pointer<ffi.Void> msg_opaque)>>)>();

  /// @brief \b Producer: Set delivery report callback in provided \p conf object.
  ///
  /// The delivery report callback will be called once for each message
  /// accepted by rd_kafka_produce() (et.al) with \p err set to indicate
  /// the result of the produce request.
  ///
  /// The callback is called when a message is succesfully produced or
  /// if librdkafka encountered a permanent failure.
  /// Delivery errors occur when the retry count is exceeded, when the
  /// message.timeout.ms timeout is exceeded or there is a permanent error
  /// like RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_OR_PART.
  ///
  /// An application must call rd_kafka_poll() at regular intervals to
  /// serve queued delivery report callbacks.
  ///
  /// The broker-assigned offset can be retrieved with \c rkmessage->offset
  /// and the timestamp can be retrieved using rd_kafka_message_timestamp().
  ///
  /// The \p dr_msg_cb \c opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  /// The per-message msg_opaque value is available in
  /// \c rd_kafka_message_t._private.
  ///
  /// @remark The Idempotent Producer may return invalid timestamp
  /// (RD_KAFKA_TIMESTAMP_NOT_AVAILABLE), and
  /// and offset (RD_KAFKA_OFFSET_INVALID) for retried messages
  /// that were previously successfully delivered but not properly
  /// acknowledged.
  void rd_kafka_conf_set_dr_msg_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<rd_kafka_message_t> rkmessage,
                    ffi.Pointer<ffi.Void> opaque)>>
        dr_msg_cb,
  ) {
    return _rd_kafka_conf_set_dr_msg_cb(
      conf,
      dr_msg_cb,
    );
  }

  late final _rd_kafka_conf_set_dr_msg_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<rd_kafka_message_t> rkmessage,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_dr_msg_cb');
  late final _rd_kafka_conf_set_dr_msg_cb =
      _rd_kafka_conf_set_dr_msg_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief \b Consumer: Set consume callback for use with
  /// rd_kafka_consumer_poll()
  ///
  /// The \p consume_cb \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  void rd_kafka_conf_set_consume_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_message_t> rkmessage,
                    ffi.Pointer<ffi.Void> opaque)>>
        consume_cb,
  ) {
    return _rd_kafka_conf_set_consume_cb(
      conf,
      consume_cb,
    );
  }

  late final _rd_kafka_conf_set_consume_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_message_t> rkmessage,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_consume_cb');
  late final _rd_kafka_conf_set_consume_cb =
      _rd_kafka_conf_set_consume_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief \b Consumer: Set rebalance callback for use with
  /// coordinated consumer group balancing.
  ///
  /// The \p err field is set to either RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS
  /// or RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS and 'partitions'
  /// contains the full partition set that was either assigned or revoked.
  ///
  /// Registering a \p rebalance_cb turns off librdkafka's automatic
  /// partition assignment/revocation and instead delegates that responsibility
  /// to the application's \p rebalance_cb.
  ///
  /// The rebalance callback is responsible for updating librdkafka's
  /// assignment set based on the two events: RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS
  /// and RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS but should also be able to handle
  /// arbitrary rebalancing failures where \p err is neither of those.
  /// @remark In this latter case (arbitrary error), the application must
  /// call rd_kafka_assign(rk, NULL) to synchronize state.
  ///
  /// For eager/non-cooperative `partition.assignment.strategy` assignors,
  /// such as `range` and `roundrobin`, the application must use
  /// rd_kafka_assign() to set or clear the entire assignment.
  /// For the cooperative assignors, such as `cooperative-sticky`, the application
  /// must use rd_kafka_incremental_assign() for
  /// RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS and rd_kafka_incremental_unassign()
  /// for RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS.
  ///
  /// Without a rebalance callback this is done automatically by librdkafka
  /// but registering a rebalance callback gives the application flexibility
  /// in performing other operations along with the assigning/revocation,
  /// such as fetching offsets from an alternate location (on assign)
  /// or manually committing offsets (on revoke).
  ///
  /// rebalance_cb is always triggered exactly once when a rebalance completes
  /// with a new assignment, even if that assignment is empty. If an
  /// eager/non-cooperative assignor is configured, there will eventually be
  /// exactly one corresponding call to rebalance_cb to revoke these partitions
  /// (even if empty), whether this is due to a group rebalance or lost
  /// partitions. In the cooperative case, rebalance_cb will never be called if
  /// the set of partitions being revoked is empty (whether or not lost).
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark The \p partitions list is destroyed by librdkafka on return
  /// return from the rebalance_cb and must not be freed or
  /// saved by the application.
  ///
  /// @remark Be careful when modifying the \p partitions list.
  /// Changing this list should only be done to change the initial
  /// offsets for each partition.
  /// But a function like `rd_kafka_position()` might have unexpected
  /// effects for instance when a consumer gets assigned a partition
  /// it used to consume at an earlier rebalance. In this case, the
  /// list of partitions will be updated with the old offset for that
  /// partition. In this case, it is generally better to pass a copy
  /// of the list (see `rd_kafka_topic_partition_list_copy()`).
  /// The result of `rd_kafka_position()` is typically outdated in
  /// RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS.
  ///
  /// @sa rd_kafka_assign()
  /// @sa rd_kafka_incremental_assign()
  /// @sa rd_kafka_incremental_unassign()
  /// @sa rd_kafka_assignment_lost()
  /// @sa rd_kafka_rebalance_protocol()
  ///
  /// The following example shows the application's responsibilities:
  /// @code
  /// static void rebalance_cb (rd_kafka_t *rk, rd_kafka_resp_err_t err,
  /// rd_kafka_topic_partition_list_t *partitions,
  /// void *opaque) {
  ///
  /// switch (err)
  /// {
  /// case RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS:
  /// // application may load offets from arbitrary external
  /// // storage here and update \p partitions
  /// if (!strcmp(rd_kafka_rebalance_protocol(rk), "COOPERATIVE"))
  /// rd_kafka_incremental_assign(rk, partitions);
  /// else // EAGER
  /// rd_kafka_assign(rk, partitions);
  /// break;
  ///
  /// case RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS:
  /// if (manual_commits) // Optional explicit manual commit
  /// rd_kafka_commit(rk, partitions, 0); // sync commit
  ///
  /// if (!strcmp(rd_kafka_rebalance_protocol(rk), "COOPERATIVE"))
  /// rd_kafka_incremental_unassign(rk, partitions);
  /// else // EAGER
  /// rd_kafka_assign(rk, NULL);
  /// break;
  ///
  /// default:
  /// handle_unlikely_error(err);
  /// rd_kafka_assign(rk, NULL); // sync state
  /// break;
  /// }
  /// }
  /// @endcode
  ///
  /// @remark The above example lacks error handling for assign calls, see
  /// the examples/ directory.
  void rd_kafka_conf_set_rebalance_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Int32 err,
                    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
                    ffi.Pointer<ffi.Void> opaque)>>
        rebalance_cb,
  ) {
    return _rd_kafka_conf_set_rebalance_cb(
      conf,
      rebalance_cb,
    );
  }

  late final _rd_kafka_conf_set_rebalance_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Int32 err,
                              ffi.Pointer<rd_kafka_topic_partition_list_t>
                                  partitions,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_rebalance_cb');
  late final _rd_kafka_conf_set_rebalance_cb =
      _rd_kafka_conf_set_rebalance_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Int32 err,
                          ffi.Pointer<rd_kafka_topic_partition_list_t>
                              partitions,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief \b Consumer: Set offset commit callback for use with consumer groups.
  ///
  /// The results of automatic or manual offset commits will be scheduled
  /// for this callback and is served by rd_kafka_consumer_poll().
  ///
  /// If no partitions had valid offsets to commit this callback will be called
  /// with \p err == RD_KAFKA_RESP_ERR__NO_OFFSET which is not to be considered
  /// an error.
  ///
  /// The \p offsets list contains per-partition information:
  /// - \c offset: committed offset (attempted)
  /// - \c err:    commit error
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  void rd_kafka_conf_set_offset_commit_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Int32 err,
                    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
                    ffi.Pointer<ffi.Void> opaque)>>
        offset_commit_cb,
  ) {
    return _rd_kafka_conf_set_offset_commit_cb(
      conf,
      offset_commit_cb,
    );
  }

  late final _rd_kafka_conf_set_offset_commit_cbPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Void Function(
                      ffi.Pointer<rd_kafka_conf_t>,
                      ffi.Pointer<
                          ffi.NativeFunction<
                              ffi.Void Function(
                                  ffi.Pointer<rd_kafka_t> rk,
                                  ffi.Int32 err,
                                  ffi.Pointer<rd_kafka_topic_partition_list_t>
                                      offsets,
                                  ffi.Pointer<ffi.Void> opaque)>>)>>(
          'rd_kafka_conf_set_offset_commit_cb');
  late final _rd_kafka_conf_set_offset_commit_cb =
      _rd_kafka_conf_set_offset_commit_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Int32 err,
                          ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set error callback in provided conf object.
  ///
  /// The error callback is used by librdkafka to signal warnings and errors
  /// back to the application.
  ///
  /// These errors should generally be considered informational and non-permanent,
  /// the client will try to recover automatically from all type of errors.
  /// Given that the client and cluster configuration is correct the
  /// application should treat these as temporary errors.
  ///
  /// \p error_cb will be triggered with \c err set to RD_KAFKA_RESP_ERR__FATAL
  /// if a fatal error has been raised; in this case use rd_kafka_fatal_error() to
  /// retrieve the fatal error code and error string, and then begin terminating
  /// the client instance.
  ///
  /// If no \p error_cb is registered, or RD_KAFKA_EVENT_ERROR has not been set
  /// with rd_kafka_conf_set_events, then the errors will be logged instead.
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  void rd_kafka_conf_set_error_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Int err,
                    ffi.Pointer<ffi.Char> reason,
                    ffi.Pointer<ffi.Void> opaque)>>
        error_cb,
  ) {
    return _rd_kafka_conf_set_error_cb(
      conf,
      error_cb,
    );
  }

  late final _rd_kafka_conf_set_error_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Int err,
                              ffi.Pointer<ffi.Char> reason,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_error_cb');
  late final _rd_kafka_conf_set_error_cb =
      _rd_kafka_conf_set_error_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Int err,
                          ffi.Pointer<ffi.Char> reason,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set throttle callback.
  ///
  /// The throttle callback is used to forward broker throttle times to the
  /// application for Produce and Fetch (consume) requests.
  ///
  /// Callbacks are triggered whenever a non-zero throttle time is returned by
  /// the broker, or when the throttle time drops back to zero.
  ///
  /// An application must call rd_kafka_poll() or rd_kafka_consumer_poll() at
  /// regular intervals to serve queued callbacks.
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark Requires broker version 0.9.0 or later.
  void rd_kafka_conf_set_throttle_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Char> broker_name,
                    ffi.Int32 broker_id,
                    ffi.Int throttle_time_ms,
                    ffi.Pointer<ffi.Void> opaque)>>
        throttle_cb,
  ) {
    return _rd_kafka_conf_set_throttle_cb(
      conf,
      throttle_cb,
    );
  }

  late final _rd_kafka_conf_set_throttle_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<ffi.Char> broker_name,
                              ffi.Int32 broker_id,
                              ffi.Int throttle_time_ms,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_throttle_cb');
  late final _rd_kafka_conf_set_throttle_cb =
      _rd_kafka_conf_set_throttle_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Char> broker_name,
                          ffi.Int32 broker_id,
                          ffi.Int throttle_time_ms,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set logger callback.
  ///
  /// The default is to print to stderr, but a syslog logger is also available,
  /// see rd_kafka_log_print and rd_kafka_log_syslog for the builtin alternatives.
  /// Alternatively the application may provide its own logger callback.
  /// Or pass \p func as NULL to disable logging.
  ///
  /// This is the configuration alternative to the deprecated rd_kafka_set_logger()
  ///
  /// @remark The log_cb will be called spontaneously from librdkafka's internal
  /// threads unless logs have been forwarded to a poll queue through
  /// \c rd_kafka_set_log_queue().
  /// An application MUST NOT call any librdkafka APIs or do any prolonged
  /// work in a non-forwarded \c log_cb.
  void rd_kafka_conf_set_log_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_t> rk, ffi.Int level,
                    ffi.Pointer<ffi.Char> fac, ffi.Pointer<ffi.Char> buf)>>
        log_cb,
  ) {
    return _rd_kafka_conf_set_log_cb(
      conf,
      log_cb,
    );
  }

  late final _rd_kafka_conf_set_log_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Int level,
                              ffi.Pointer<ffi.Char> fac,
                              ffi.Pointer<ffi.Char> buf)>>)>>(
      'rd_kafka_conf_set_log_cb');
  late final _rd_kafka_conf_set_log_cb =
      _rd_kafka_conf_set_log_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Int level,
                          ffi.Pointer<ffi.Char> fac,
                          ffi.Pointer<ffi.Char> buf)>>)>();

  /// @brief Set statistics callback in provided conf object.
  ///
  /// The statistics callback is triggered from rd_kafka_poll() every
  /// \c statistics.interval.ms (needs to be configured separately).
  /// Function arguments:
  /// - \p rk - Kafka handle
  /// - \p json - String containing the statistics data in JSON format
  /// - \p json_len - Length of \p json string.
  /// - \p opaque - Application-provided opaque as set by
  /// rd_kafka_conf_set_opaque().
  ///
  /// For more information on the format of \p json, see
  /// https://github.com/confluentinc/librdkafka/wiki/Statistics
  ///
  /// If the application wishes to hold on to the \p json pointer and free
  /// it at a later time it must return 1 from the \p stats_cb.
  /// If the application returns 0 from the \p stats_cb then librdkafka
  /// will immediately free the \p json pointer.
  ///
  /// See STATISTICS.md for a full definition of the JSON object.
  void rd_kafka_conf_set_stats_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Char> json,
                    ffi.Size json_len,
                    ffi.Pointer<ffi.Void> opaque)>>
        stats_cb,
  ) {
    return _rd_kafka_conf_set_stats_cb(
      conf,
      stats_cb,
    );
  }

  late final _rd_kafka_conf_set_stats_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<ffi.Char> json,
                              ffi.Size json_len,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_stats_cb');
  late final _rd_kafka_conf_set_stats_cb =
      _rd_kafka_conf_set_stats_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Char> json,
                          ffi.Size json_len,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set SASL/OAUTHBEARER token refresh callback in provided conf object.
  ///
  /// @param conf the configuration to mutate.
  /// @param oauthbearer_token_refresh_cb the callback to set; callback function
  /// arguments:<br>
  /// \p rk - Kafka handle<br>
  /// \p oauthbearer_config - Value of configuration property
  /// sasl.oauthbearer.config.
  /// \p opaque - Application-provided opaque set via
  /// rd_kafka_conf_set_opaque()
  ///
  /// The SASL/OAUTHBEARER token refresh callback is triggered via rd_kafka_poll()
  /// whenever OAUTHBEARER is the SASL mechanism and a token needs to be retrieved,
  /// typically based on the configuration defined in \c sasl.oauthbearer.config.
  ///
  /// The callback should invoke rd_kafka_oauthbearer_set_token()
  /// or rd_kafka_oauthbearer_set_token_failure() to indicate success
  /// or failure, respectively.
  ///
  /// The refresh operation is eventable and may be received via
  /// rd_kafka_queue_poll() with an event type of
  /// \c RD_KAFKA_EVENT_OAUTHBEARER_TOKEN_REFRESH.
  ///
  /// Note that before any SASL/OAUTHBEARER broker connection can succeed the
  /// application must call rd_kafka_oauthbearer_set_token() once -- either
  /// directly or, more typically, by invoking either rd_kafka_poll(),
  /// rd_kafka_consumer_poll(), rd_kafka_queue_poll(), etc, in order to cause
  /// retrieval of an initial token to occur.
  ///
  /// Alternatively, the application can enable the SASL queue by calling
  /// rd_kafka_conf_enable_sasl_queue() on the configuration object prior to
  /// creating the client instance, get the SASL queue with
  /// rd_kafka_queue_get_sasl(), and either serve the queue manually by calling
  /// rd_kafka_queue_poll(), or redirecting the queue to the background thread to
  /// have the queue served automatically. For the latter case the SASL queue
  /// must be forwarded to the background queue with rd_kafka_queue_forward().
  /// A convenience function is available to automatically forward the SASL queue
  /// to librdkafka's background thread, see
  /// rd_kafka_sasl_background_callbacks_enable().
  ///
  /// An unsecured JWT refresh handler is provided by librdkafka for development
  /// and testing purposes, it is enabled by setting
  /// the \c enable.sasl.oauthbearer.unsecure.jwt property to true and is
  /// mutually exclusive to using a refresh callback.
  ///
  /// @sa rd_kafka_sasl_background_callbacks_enable()
  /// @sa rd_kafka_queue_get_sasl()
  void rd_kafka_conf_set_oauthbearer_token_refresh_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Char> oauthbearer_config,
                    ffi.Pointer<ffi.Void> opaque)>>
        oauthbearer_token_refresh_cb,
  ) {
    return _rd_kafka_conf_set_oauthbearer_token_refresh_cb(
      conf,
      oauthbearer_token_refresh_cb,
    );
  }

  late final _rd_kafka_conf_set_oauthbearer_token_refresh_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<ffi.Char> oauthbearer_config,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_oauthbearer_token_refresh_cb');
  late final _rd_kafka_conf_set_oauthbearer_token_refresh_cb =
      _rd_kafka_conf_set_oauthbearer_token_refresh_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Char> oauthbearer_config,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Enable/disable creation of a queue specific to SASL events
  /// and callbacks.
  ///
  /// For SASL mechanisms that trigger callbacks (currently OAUTHBEARER) this
  /// configuration API allows an application to get a dedicated
  /// queue for the SASL events/callbacks. After enabling the queue with this API
  /// the application can retrieve the queue by calling
  /// rd_kafka_queue_get_sasl() on the client instance.
  /// This queue may then be served directly by the application
  /// (with rd_kafka_queue_poll(), et.al)  or forwarded to another queue, such as
  /// the background queue.
  ///
  /// A convenience function is available to automatically forward the SASL queue
  /// to librdkafka's background thread, see
  /// rd_kafka_sasl_background_callbacks_enable().
  ///
  /// By default (\p enable = 0) the main queue (as served by rd_kafka_poll(),
  /// et.al.) is used for SASL callbacks.
  ///
  /// @remark The SASL queue is currently only used by the SASL OAUTHBEARER
  /// mechanism's token_refresh_cb().
  ///
  /// @sa rd_kafka_queue_get_sasl()
  /// @sa rd_kafka_sasl_background_callbacks_enable()
  void rd_kafka_conf_enable_sasl_queue(
    ffi.Pointer<rd_kafka_conf_t> conf,
    int enable,
  ) {
    return _rd_kafka_conf_enable_sasl_queue(
      conf,
      enable,
    );
  }

  late final _rd_kafka_conf_enable_sasl_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_conf_t>,
              ffi.Int)>>('rd_kafka_conf_enable_sasl_queue');
  late final _rd_kafka_conf_enable_sasl_queue =
      _rd_kafka_conf_enable_sasl_queuePtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_conf_t>, int)>();

  /// @brief Set socket callback.
  ///
  /// The socket callback is responsible for opening a socket
  /// according to the supplied \p domain, \p type and \p protocol.
  /// The socket shall be created with \c CLOEXEC set in a racefree fashion, if
  /// possible.
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// Default:
  /// - on linux: racefree CLOEXEC
  /// - others  : non-racefree CLOEXEC
  ///
  /// @remark The callback will be called from an internal librdkafka thread.
  void rd_kafka_conf_set_socket_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Int domain, ffi.Int type, ffi.Int protocol,
                    ffi.Pointer<ffi.Void> opaque)>>
        socket_cb,
  ) {
    return _rd_kafka_conf_set_socket_cb(
      conf,
      socket_cb,
    );
  }

  late final _rd_kafka_conf_set_socket_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Int domain,
                              ffi.Int type,
                              ffi.Int protocol,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_socket_cb');
  late final _rd_kafka_conf_set_socket_cb =
      _rd_kafka_conf_set_socket_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Int domain, ffi.Int type,
                          ffi.Int protocol, ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set connect callback.
  ///
  /// The connect callback is responsible for connecting socket \p sockfd
  /// to peer address \p addr.
  /// The \p id field contains the broker identifier.
  ///
  /// \p connect_cb shall return 0 on success (socket connected) or an error
  /// number (errno) on error.
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark The callback will be called from an internal librdkafka thread.
  void rd_kafka_conf_set_connect_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Int sockfd,
                    ffi.Pointer<sockaddr> addr,
                    ffi.Int addrlen,
                    ffi.Pointer<ffi.Char> id,
                    ffi.Pointer<ffi.Void> opaque)>>
        connect_cb,
  ) {
    return _rd_kafka_conf_set_connect_cb(
      conf,
      connect_cb,
    );
  }

  late final _rd_kafka_conf_set_connect_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Int sockfd,
                              ffi.Pointer<sockaddr> addr,
                              ffi.Int addrlen,
                              ffi.Pointer<ffi.Char> id,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_connect_cb');
  late final _rd_kafka_conf_set_connect_cb =
      _rd_kafka_conf_set_connect_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Int sockfd,
                          ffi.Pointer<sockaddr> addr,
                          ffi.Int addrlen,
                          ffi.Pointer<ffi.Char> id,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set close socket callback.
  ///
  /// Close a socket (optionally opened with socket_cb()).
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark The callback will be called from an internal librdkafka thread.
  void rd_kafka_conf_set_closesocket_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Int sockfd, ffi.Pointer<ffi.Void> opaque)>>
        closesocket_cb,
  ) {
    return _rd_kafka_conf_set_closesocket_cb(
      conf,
      closesocket_cb,
    );
  }

  late final _rd_kafka_conf_set_closesocket_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(ffi.Int sockfd,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_closesocket_cb');
  late final _rd_kafka_conf_set_closesocket_cb =
      _rd_kafka_conf_set_closesocket_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Int sockfd, ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set open callback.
  ///
  /// The open callback is responsible for opening the file specified by
  /// pathname, flags and mode.
  /// The file shall be opened with \c CLOEXEC set in a racefree fashion, if
  /// possible.
  ///
  /// Default:
  /// - on linux: racefree CLOEXEC
  /// - others  : non-racefree CLOEXEC
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @remark The callback will be called from an internal librdkafka thread.
  void rd_kafka_conf_set_open_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<ffi.Char> pathname, ffi.Int flags,
                    mode_t mode, ffi.Pointer<ffi.Void> opaque)>>
        open_cb,
  ) {
    return _rd_kafka_conf_set_open_cb(
      conf,
      open_cb,
    );
  }

  late final _rd_kafka_conf_set_open_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Pointer<ffi.Char> pathname,
                              ffi.Int flags,
                              mode_t mode,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_open_cb');
  late final _rd_kafka_conf_set_open_cb =
      _rd_kafka_conf_set_open_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Char> pathname,
                          ffi.Int flags,
                          mode_t mode,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set address resolution callback.
  ///
  /// The callback is responsible for resolving the hostname \p node and the
  /// service \p service into a list of socket addresses as \c getaddrinfo(3)
  /// would. The \p hints and \p res parameters function as they do for
  /// \c getaddrinfo(3). The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// If the callback is invoked with a NULL \p node, \p service, and \p hints, the
  /// callback should instead free the addrinfo struct specified in \p res. In this
  /// case the callback must succeed; the return value will not be checked by the
  /// caller.
  ///
  /// The callback's return value is interpreted as the return value of \p
  /// \c getaddrinfo(3).
  ///
  /// @remark The callback will be called from an internal librdkafka thread.
  void rd_kafka_conf_set_resolve_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<ffi.Char> node,
                    ffi.Pointer<ffi.Char> service,
                    ffi.Pointer<addrinfo> hints,
                    ffi.Pointer<ffi.Pointer<addrinfo>> res,
                    ffi.Pointer<ffi.Void> opaque)>>
        resolve_cb,
  ) {
    return _rd_kafka_conf_set_resolve_cb(
      conf,
      resolve_cb,
    );
  }

  late final _rd_kafka_conf_set_resolve_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Pointer<ffi.Char> node,
                              ffi.Pointer<ffi.Char> service,
                              ffi.Pointer<addrinfo> hints,
                              ffi.Pointer<ffi.Pointer<addrinfo>> res,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_resolve_cb');
  late final _rd_kafka_conf_set_resolve_cb =
      _rd_kafka_conf_set_resolve_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<ffi.Char> node,
                          ffi.Pointer<ffi.Char> service,
                          ffi.Pointer<addrinfo> hints,
                          ffi.Pointer<ffi.Pointer<addrinfo>> res,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Sets the verification callback of the broker certificate
  ///
  /// The verification callback is triggered from internal librdkafka threads
  /// upon connecting to a broker. On each connection attempt the callback
  /// will be called for each certificate in the broker's certificate chain,
  /// starting at the root certification, as long as the application callback
  /// returns 1 (valid certificate).
  /// \c broker_name and \c broker_id correspond to the broker the connection
  /// is being made to.
  /// The \c x509_error argument indicates if OpenSSL's verification of
  /// the certificate succeed (0) or failed (an OpenSSL error code).
  /// The application may set the SSL context error code by returning 0
  /// from the verify callback and providing a non-zero SSL context error code
  /// in \c x509_error.
  /// If the verify callback sets \c x509_error to 0, returns 1, and the
  /// original \c x509_error was non-zero, the error on the SSL context will
  /// be cleared.
  /// \c x509_error is always a valid pointer to an int.
  ///
  /// \c depth is the depth of the current certificate in the chain, starting
  /// at the root certificate.
  ///
  /// The certificate itself is passed in binary DER format in \c buf of
  /// size \c size.
  ///
  /// The callback must return 1 if verification succeeds, or
  /// 0 if verification fails and then write a human-readable error message
  /// to \c errstr (limited to \c errstr_size bytes, including nul-term).
  ///
  /// The callback's \p opaque argument is the opaque set with
  /// rd_kafka_conf_set_opaque().
  ///
  /// @returns RD_KAFKA_CONF_OK if SSL is supported in this build, else
  /// RD_KAFKA_CONF_INVALID.
  ///
  /// @warning This callback will be called from internal librdkafka threads.
  ///
  /// @remark See <openssl/x509_vfy.h> in the OpenSSL source distribution
  /// for a list of \p x509_error codes.
  int rd_kafka_conf_set_ssl_cert_verify_cb(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Char> broker_name,
                    ffi.Int32 broker_id,
                    ffi.Pointer<ffi.Int> x509_error,
                    ffi.Int depth,
                    ffi.Pointer<ffi.Char> buf,
                    ffi.Size size,
                    ffi.Pointer<ffi.Char> errstr,
                    ffi.Size errstr_size,
                    ffi.Pointer<ffi.Void> opaque)>>
        ssl_cert_verify_cb,
  ) {
    return _rd_kafka_conf_set_ssl_cert_verify_cb(
      conf,
      ssl_cert_verify_cb,
    );
  }

  late final _rd_kafka_conf_set_ssl_cert_verify_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Pointer<ffi.Char> broker_name,
                              ffi.Int32 broker_id,
                              ffi.Pointer<ffi.Int> x509_error,
                              ffi.Int depth,
                              ffi.Pointer<ffi.Char> buf,
                              ffi.Size size,
                              ffi.Pointer<ffi.Char> errstr,
                              ffi.Size errstr_size,
                              ffi.Pointer<ffi.Void> opaque)>>)>>(
      'rd_kafka_conf_set_ssl_cert_verify_cb');
  late final _rd_kafka_conf_set_ssl_cert_verify_cb =
      _rd_kafka_conf_set_ssl_cert_verify_cbPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Char> broker_name,
                          ffi.Int32 broker_id,
                          ffi.Pointer<ffi.Int> x509_error,
                          ffi.Int depth,
                          ffi.Pointer<ffi.Char> buf,
                          ffi.Size size,
                          ffi.Pointer<ffi.Char> errstr,
                          ffi.Size errstr_size,
                          ffi.Pointer<ffi.Void> opaque)>>)>();

  /// @brief Set certificate/key \p cert_type from the \p cert_enc encoded
  /// memory at \p buffer of \p size bytes.
  ///
  /// @param conf Configuration object.
  /// @param cert_type Certificate or key type to configure.
  /// @param cert_enc  Buffer \p encoding type.
  /// @param buffer Memory pointer to encoded certificate or key.
  /// The memory is not referenced after this function returns.
  /// @param size Size of memory at \p buffer.
  /// @param errstr Memory were a human-readable error string will be written
  /// on failure.
  /// @param errstr_size Size of \p errstr, including space for nul-terminator.
  ///
  /// @returns RD_KAFKA_CONF_OK on success or RD_KAFKA_CONF_INVALID if the
  /// memory in \p buffer is of incorrect encoding, or if librdkafka
  /// was not built with SSL support.
  ///
  /// @remark Calling this method multiple times with the same \p cert_type
  /// will replace the previous value.
  ///
  /// @remark Calling this method with \p buffer set to NULL will clear the
  /// configuration for \p cert_type.
  ///
  /// @remark The private key may require a password, which must be specified
  /// with the `ssl.key.password` configuration property prior to
  /// calling this function.
  ///
  /// @remark Private and public keys in PEM format may also be set with the
  /// `ssl.key.pem` and `ssl.certificate.pem` configuration properties.
  ///
  /// @remark CA certificate in PEM format may also be set with the
  /// `ssl.ca.pem` configuration property.
  ///
  /// @remark When librdkafka is linked to OpenSSL 3.0 and the certificate is
  /// encoded using an obsolete cipher, it might be necessary to set up
  /// an OpenSSL configuration file to load the "legacy" provider and
  /// set the OPENSSL_CONF environment variable.
  /// See
  /// https://github.com/openssl/openssl/blob/master/README-PROVIDERS.md for more
  /// information.
  int rd_kafka_conf_set_ssl_cert(
    ffi.Pointer<rd_kafka_conf_t> conf,
    int cert_type,
    int cert_enc,
    ffi.Pointer<ffi.Void> buffer,
    int size,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_conf_set_ssl_cert(
      conf,
      cert_type,
      cert_enc,
      buffer,
      size,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_conf_set_ssl_certPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_conf_set_ssl_cert');
  late final _rd_kafka_conf_set_ssl_cert =
      _rd_kafka_conf_set_ssl_certPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_conf_t>, int, int,
              ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Set callback_data for OpenSSL engine.
  ///
  /// @param conf Configuration object.
  /// @param callback_data passed to engine callbacks,
  /// e.g. \c ENGINE_load_ssl_client_cert.
  ///
  /// @remark The \c ssl.engine.location configuration must be set for this
  /// to have affect.
  ///
  /// @remark The memory pointed to by \p value must remain valid for the
  /// lifetime of the configuration object and any Kafka clients that
  /// use it.
  void rd_kafka_conf_set_engine_callback_data(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Void> callback_data,
  ) {
    return _rd_kafka_conf_set_engine_callback_data(
      conf,
      callback_data,
    );
  }

  late final _rd_kafka_conf_set_engine_callback_dataPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_conf_set_engine_callback_data');
  late final _rd_kafka_conf_set_engine_callback_data =
      _rd_kafka_conf_set_engine_callback_dataPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Void>)>();

  /// @brief Sets the application's opaque pointer that will be passed to callbacks
  ///
  /// @sa rd_kafka_opaque()
  void rd_kafka_conf_set_opaque(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Void> opaque,
  ) {
    return _rd_kafka_conf_set_opaque(
      conf,
      opaque,
    );
  }

  late final _rd_kafka_conf_set_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_conf_set_opaque');
  late final _rd_kafka_conf_set_opaque =
      _rd_kafka_conf_set_opaquePtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Void>)>();

  /// @brief Retrieves the opaque pointer previously set
  /// with rd_kafka_conf_set_opaque()
  ffi.Pointer<ffi.Void> rd_kafka_opaque(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_opaque(
      rk,
    );
  }

  late final _rd_kafka_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_opaque');
  late final _rd_kafka_opaque = _rd_kafka_opaquePtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Sets the default topic configuration to use for automatically
  /// subscribed topics (e.g., through pattern-matched topics).
  /// The topic config object is not usable after this call.
  ///
  /// @warning Any topic configuration settings that have been set on the
  /// global rd_kafka_conf_t object will be overwritten by this call
  /// since the implicitly created default topic config object is
  /// replaced by the user-supplied one.
  ///
  /// @deprecated Set default topic level configuration on the
  /// global rd_kafka_conf_t object instead.
  void rd_kafka_conf_set_default_topic_conf(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<rd_kafka_topic_conf_t> tconf,
  ) {
    return _rd_kafka_conf_set_default_topic_conf(
      conf,
      tconf,
    );
  }

  late final _rd_kafka_conf_set_default_topic_confPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<rd_kafka_topic_conf_t>)>>(
      'rd_kafka_conf_set_default_topic_conf');
  late final _rd_kafka_conf_set_default_topic_conf =
      _rd_kafka_conf_set_default_topic_confPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<rd_kafka_topic_conf_t>)>();

  /// @brief Gets the default topic configuration as previously set with
  /// rd_kafka_conf_set_default_topic_conf() or that was implicitly created
  /// by configuring a topic-level property on the global \p conf object.
  ///
  /// @returns the \p conf's default topic configuration (if any), or NULL.
  ///
  /// @warning The returned topic configuration object is owned by the \p conf
  /// object. It may be modified but not destroyed and its lifetime is
  /// the same as the \p conf object or the next call to
  /// rd_kafka_conf_set_default_topic_conf().
  ffi.Pointer<rd_kafka_topic_conf_t> rd_kafka_conf_get_default_topic_conf(
    ffi.Pointer<rd_kafka_conf_t> conf,
  ) {
    return _rd_kafka_conf_get_default_topic_conf(
      conf,
    );
  }

  late final _rd_kafka_conf_get_default_topic_confPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_conf_t> Function(
                  ffi.Pointer<rd_kafka_conf_t>)>>(
      'rd_kafka_conf_get_default_topic_conf');
  late final _rd_kafka_conf_get_default_topic_conf =
      _rd_kafka_conf_get_default_topic_confPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_conf_t> Function(
              ffi.Pointer<rd_kafka_conf_t>)>();

  /// @brief Retrieve configuration value for property \p name.
  ///
  /// If \p dest is non-NULL the value will be written to \p dest with at
  /// most \p dest_size.
  ///
  /// \p *dest_size is updated to the full length of the value, thus if
  /// \p *dest_size initially is smaller than the full length the application
  /// may reallocate \p dest to fit the returned \p *dest_size and try again.
  ///
  /// If \p dest is NULL only the full length of the value is returned.
  ///
  /// Fallthrough:
  /// Topic-level configuration properties from the \c default_topic_conf
  /// may be retrieved using this interface.
  ///
  /// @returns \p RD_KAFKA_CONF_OK if the property name matched, else
  /// \p RD_KAFKA_CONF_UNKNOWN.
  int rd_kafka_conf_get(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> dest,
    ffi.Pointer<ffi.Size> dest_size,
  ) {
    return _rd_kafka_conf_get(
      conf,
      name,
      dest,
      dest_size,
    );
  }

  late final _rd_kafka_conf_getPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_conf_get');
  late final _rd_kafka_conf_get = _rd_kafka_conf_getPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Size>)>();

  /// @brief Retrieve topic configuration value for property \p name.
  ///
  /// @sa rd_kafka_conf_get()
  int rd_kafka_topic_conf_get(
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> dest,
    ffi.Pointer<ffi.Size> dest_size,
  ) {
    return _rd_kafka_topic_conf_get(
      conf,
      name,
      dest,
      dest_size,
    );
  }

  late final _rd_kafka_topic_conf_getPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_topic_conf_get');
  late final _rd_kafka_topic_conf_get = _rd_kafka_topic_conf_getPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_topic_conf_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Size>)>();

  /// @brief Dump the configuration properties and values of \p conf to an array
  /// with \"key\", \"value\" pairs.
  ///
  /// The number of entries in the array is returned in \p *cntp.
  ///
  /// The dump must be freed with `rd_kafka_conf_dump_free()`.
  ffi.Pointer<ffi.Pointer<ffi.Char>> rd_kafka_conf_dump(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_conf_dump(
      conf,
      cntp,
    );
  }

  late final _rd_kafka_conf_dumpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<ffi.Char>> Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_conf_dump');
  late final _rd_kafka_conf_dump = _rd_kafka_conf_dumpPtr.asFunction<
      ffi.Pointer<ffi.Pointer<ffi.Char>> Function(
          ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Size>)>();

  /// @brief Dump the topic configuration properties and values of \p conf
  /// to an array with \"key\", \"value\" pairs.
  ///
  /// The number of entries in the array is returned in \p *cntp.
  ///
  /// The dump must be freed with `rd_kafka_conf_dump_free()`.
  ffi.Pointer<ffi.Pointer<ffi.Char>> rd_kafka_topic_conf_dump(
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_topic_conf_dump(
      conf,
      cntp,
    );
  }

  late final _rd_kafka_topic_conf_dumpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<ffi.Char>> Function(
              ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_topic_conf_dump');
  late final _rd_kafka_topic_conf_dump =
      _rd_kafka_topic_conf_dumpPtr.asFunction<
          ffi.Pointer<ffi.Pointer<ffi.Char>> Function(
              ffi.Pointer<rd_kafka_topic_conf_t>, ffi.Pointer<ffi.Size>)>();

  /// @brief Frees a configuration dump returned from `rd_kafka_conf_dump()` or
  /// `rd_kafka_topic_conf_dump().
  void rd_kafka_conf_dump_free(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arr,
    int cnt,
  ) {
    return _rd_kafka_conf_dump_free(
      arr,
      cnt,
    );
  }

  late final _rd_kafka_conf_dump_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Size)>>('rd_kafka_conf_dump_free');
  late final _rd_kafka_conf_dump_free = _rd_kafka_conf_dump_freePtr
      .asFunction<void Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  /// @brief Prints a table to \p fp of all supported configuration properties,
  /// their default values as well as a description.
  ///
  /// @remark All properties and properties and values are shown, even those
  /// that have been disabled at build time due to missing dependencies.
  void rd_kafka_conf_properties_show(
    ffi.Pointer<FILE> fp,
  ) {
    return _rd_kafka_conf_properties_show(
      fp,
    );
  }

  late final _rd_kafka_conf_properties_showPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'rd_kafka_conf_properties_show');
  late final _rd_kafka_conf_properties_show = _rd_kafka_conf_properties_showPtr
      .asFunction<void Function(ffi.Pointer<FILE>)>();

  /// @brief Create topic configuration object
  ///
  /// @sa Same semantics as for rd_kafka_conf_new().
  ffi.Pointer<rd_kafka_topic_conf_t> rd_kafka_topic_conf_new() {
    return _rd_kafka_topic_conf_new();
  }

  late final _rd_kafka_topic_conf_newPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<rd_kafka_topic_conf_t> Function()>>(
      'rd_kafka_topic_conf_new');
  late final _rd_kafka_topic_conf_new = _rd_kafka_topic_conf_newPtr
      .asFunction<ffi.Pointer<rd_kafka_topic_conf_t> Function()>();

  /// @brief Creates a copy/duplicate of topic configuration object \p conf.
  ffi.Pointer<rd_kafka_topic_conf_t> rd_kafka_topic_conf_dup(
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
  ) {
    return _rd_kafka_topic_conf_dup(
      conf,
    );
  }

  late final _rd_kafka_topic_conf_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_conf_t> Function(
              ffi.Pointer<rd_kafka_topic_conf_t>)>>('rd_kafka_topic_conf_dup');
  late final _rd_kafka_topic_conf_dup = _rd_kafka_topic_conf_dupPtr.asFunction<
      ffi.Pointer<rd_kafka_topic_conf_t> Function(
          ffi.Pointer<rd_kafka_topic_conf_t>)>();

  /// @brief Creates a copy/duplicate of \p rk 's default topic configuration
  /// object.
  ffi.Pointer<rd_kafka_topic_conf_t> rd_kafka_default_topic_conf_dup(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_default_topic_conf_dup(
      rk,
    );
  }

  late final _rd_kafka_default_topic_conf_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_conf_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_default_topic_conf_dup');
  late final _rd_kafka_default_topic_conf_dup =
      _rd_kafka_default_topic_conf_dupPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_conf_t> Function(
              ffi.Pointer<rd_kafka_t>)>();

  /// @brief Destroys a topic conf object.
  void rd_kafka_topic_conf_destroy(
    ffi.Pointer<rd_kafka_topic_conf_t> topic_conf,
  ) {
    return _rd_kafka_topic_conf_destroy(
      topic_conf,
    );
  }

  late final _rd_kafka_topic_conf_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_topic_conf_t>)>>(
      'rd_kafka_topic_conf_destroy');
  late final _rd_kafka_topic_conf_destroy = _rd_kafka_topic_conf_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_topic_conf_t>)>();

  /// @brief Sets a single rd_kafka_topic_conf_t value by property name.
  ///
  /// \p topic_conf should have been previously set up
  /// with `rd_kafka_topic_conf_new()`.
  ///
  /// @returns rd_kafka_conf_res_t to indicate success or failure.
  int rd_kafka_topic_conf_set(
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> value,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_topic_conf_set(
      conf,
      name,
      value,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_topic_conf_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_topic_conf_set');
  late final _rd_kafka_topic_conf_set = _rd_kafka_topic_conf_setPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_topic_conf_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Sets the application's opaque pointer that will be passed to all topic
  /// callbacks as the \c rkt_opaque argument.
  ///
  /// @sa rd_kafka_topic_opaque()
  void rd_kafka_topic_conf_set_opaque(
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
    ffi.Pointer<ffi.Void> rkt_opaque,
  ) {
    return _rd_kafka_topic_conf_set_opaque(
      conf,
      rkt_opaque,
    );
  }

  late final _rd_kafka_topic_conf_set_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_topic_conf_set_opaque');
  late final _rd_kafka_topic_conf_set_opaque =
      _rd_kafka_topic_conf_set_opaquePtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_topic_conf_t>, ffi.Pointer<ffi.Void>)>();

  /// @brief \b Producer: Set partitioner callback in provided topic conf object.
  ///
  /// The partitioner may be called in any thread at any time,
  /// it may be called multiple times for the same message/key.
  ///
  /// The callback's \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The callback's \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// Partitioner function constraints:
  /// - MUST NOT call any rd_kafka_*() functions except:
  /// rd_kafka_topic_partition_available()
  /// - MUST NOT block or execute for prolonged periods of time.
  /// - MUST return a value between 0 and partition_cnt-1, or the
  /// special \c RD_KAFKA_PARTITION_UA value if partitioning
  /// could not be performed.
  void rd_kafka_topic_conf_set_partitioner_cb(
    ffi.Pointer<rd_kafka_topic_conf_t> topic_conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int32 Function(
                    ffi.Pointer<rd_kafka_topic_t> rkt,
                    ffi.Pointer<ffi.Void> keydata,
                    ffi.Size keylen,
                    ffi.Int32 partition_cnt,
                    ffi.Pointer<ffi.Void> rkt_opaque,
                    ffi.Pointer<ffi.Void> msg_opaque)>>
        partitioner,
  ) {
    return _rd_kafka_topic_conf_set_partitioner_cb(
      topic_conf,
      partitioner,
    );
  }

  late final _rd_kafka_topic_conf_set_partitioner_cbPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_topic_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int32 Function(
                              ffi.Pointer<rd_kafka_topic_t> rkt,
                              ffi.Pointer<ffi.Void> keydata,
                              ffi.Size keylen,
                              ffi.Int32 partition_cnt,
                              ffi.Pointer<ffi.Void> rkt_opaque,
                              ffi.Pointer<ffi.Void> msg_opaque)>>)>>(
      'rd_kafka_topic_conf_set_partitioner_cb');
  late final _rd_kafka_topic_conf_set_partitioner_cb =
      _rd_kafka_topic_conf_set_partitioner_cbPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(
                          ffi.Pointer<rd_kafka_topic_t> rkt,
                          ffi.Pointer<ffi.Void> keydata,
                          ffi.Size keylen,
                          ffi.Int32 partition_cnt,
                          ffi.Pointer<ffi.Void> rkt_opaque,
                          ffi.Pointer<ffi.Void> msg_opaque)>>)>();

  /// @brief \b Producer: Set message queueing order comparator callback.
  ///
  /// The callback may be called in any thread at any time,
  /// it may be called multiple times for the same message.
  ///
  /// Ordering comparator function constraints:
  /// - MUST be stable sort (same input gives same output).
  /// - MUST NOT call any rd_kafka_*() functions.
  /// - MUST NOT block or execute for prolonged periods of time.
  ///
  /// The comparator shall compare the two messages and return:
  /// - < 0 if message \p a should be inserted before message \p b.
  /// - >=0 if message \p a should be inserted after message \p b.
  ///
  /// @remark Insert sorting will be used to enqueue the message in the
  /// correct queue position, this comes at a cost of O(n).
  ///
  /// @remark If `queuing.strategy=fifo` new messages are enqueued to the
  /// tail of the queue regardless of msg_order_cmp, but retried messages
  /// are still affected by msg_order_cmp.
  ///
  /// @warning THIS IS AN EXPERIMENTAL API, SUBJECT TO CHANGE OR REMOVAL,
  /// DO NOT USE IN PRODUCTION.
  void rd_kafka_topic_conf_set_msg_order_cmp(
    ffi.Pointer<rd_kafka_topic_conf_t> topic_conf,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(ffi.Pointer<rd_kafka_message_t> a,
                    ffi.Pointer<rd_kafka_message_t> b)>>
        msg_order_cmp,
  ) {
    return _rd_kafka_topic_conf_set_msg_order_cmp(
      topic_conf,
      msg_order_cmp,
    );
  }

  late final _rd_kafka_topic_conf_set_msg_order_cmpPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_topic_conf_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Int Function(ffi.Pointer<rd_kafka_message_t> a,
                              ffi.Pointer<rd_kafka_message_t> b)>>)>>(
      'rd_kafka_topic_conf_set_msg_order_cmp');
  late final _rd_kafka_topic_conf_set_msg_order_cmp =
      _rd_kafka_topic_conf_set_msg_order_cmpPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_topic_conf_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<rd_kafka_message_t> a,
                          ffi.Pointer<rd_kafka_message_t> b)>>)>();

  /// @brief Check if partition is available (has a leader broker).
  ///
  /// @returns 1 if the partition is available, else 0.
  ///
  /// @warning This function must only be called from inside a partitioner function
  int rd_kafka_topic_partition_available(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
  ) {
    return _rd_kafka_topic_partition_available(
      rkt,
      partition,
    );
  }

  late final _rd_kafka_topic_partition_availablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32)>>('rd_kafka_topic_partition_available');
  late final _rd_kafka_topic_partition_available =
      _rd_kafka_topic_partition_availablePtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_topic_t>, int)>();

  /// @brief Random partitioner.
  ///
  /// Will try not to return unavailable partitions.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a random partition between 0 and \p partition_cnt - 1.
  int rd_kafka_msg_partitioner_random(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_random(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_randomPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_msg_partitioner_random');
  late final _rd_kafka_msg_partitioner_random =
      _rd_kafka_msg_partitioner_randomPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Consistent partitioner.
  ///
  /// Uses consistent hashing to map identical keys onto identical partitions.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a \"random\" partition between 0 and \p partition_cnt - 1 based on
  /// the CRC value of the key
  int rd_kafka_msg_partitioner_consistent(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_consistent(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_consistentPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_msg_partitioner_consistent');
  late final _rd_kafka_msg_partitioner_consistent =
      _rd_kafka_msg_partitioner_consistentPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Consistent-Random partitioner.
  ///
  /// This is the default partitioner.
  /// Uses consistent hashing to map identical keys onto identical partitions, and
  /// messages without keys will be assigned via the random partitioner.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a \"random\" partition between 0 and \p partition_cnt - 1 based on
  /// the CRC value of the key (if provided)
  int rd_kafka_msg_partitioner_consistent_random(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_consistent_random(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_consistent_randomPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_topic_t>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Size,
                  ffi.Int32,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_msg_partitioner_consistent_random');
  late final _rd_kafka_msg_partitioner_consistent_random =
      _rd_kafka_msg_partitioner_consistent_randomPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Murmur2 partitioner (Java compatible).
  ///
  /// Uses consistent hashing to map identical keys onto identical partitions
  /// using Java-compatible Murmur2 hashing.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a partition between 0 and \p partition_cnt - 1.
  int rd_kafka_msg_partitioner_murmur2(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_murmur2(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_murmur2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_msg_partitioner_murmur2');
  late final _rd_kafka_msg_partitioner_murmur2 =
      _rd_kafka_msg_partitioner_murmur2Ptr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Consistent-Random Murmur2 partitioner (Java compatible).
  ///
  /// Uses consistent hashing to map identical keys onto identical partitions
  /// using Java-compatible Murmur2 hashing.
  /// Messages without keys will be assigned via the random partitioner.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a partition between 0 and \p partition_cnt - 1.
  int rd_kafka_msg_partitioner_murmur2_random(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_murmur2_random(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_murmur2_randomPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_topic_t>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Size,
                  ffi.Int32,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_msg_partitioner_murmur2_random');
  late final _rd_kafka_msg_partitioner_murmur2_random =
      _rd_kafka_msg_partitioner_murmur2_randomPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief FNV-1a partitioner.
  ///
  /// Uses consistent hashing to map identical keys onto identical partitions
  /// using FNV-1a hashing.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a partition between 0 and \p partition_cnt - 1.
  int rd_kafka_msg_partitioner_fnv1a(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_fnv1a(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_fnv1aPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_msg_partitioner_fnv1a');
  late final _rd_kafka_msg_partitioner_fnv1a =
      _rd_kafka_msg_partitioner_fnv1aPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Consistent-Random FNV-1a partitioner.
  ///
  /// Uses consistent hashing to map identical keys onto identical partitions
  /// using FNV-1a hashing.
  /// Messages without keys will be assigned via the random partitioner.
  ///
  /// The \p rkt_opaque argument is the opaque set by
  /// rd_kafka_topic_conf_set_opaque().
  /// The \p msg_opaque argument is the per-message opaque
  /// passed to produce().
  ///
  /// @returns a partition between 0 and \p partition_cnt - 1.
  int rd_kafka_msg_partitioner_fnv1a_random(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    int partition_cnt,
    ffi.Pointer<ffi.Void> rkt_opaque,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_msg_partitioner_fnv1a_random(
      rkt,
      key,
      keylen,
      partition_cnt,
      rkt_opaque,
      msg_opaque,
    );
  }

  late final _rd_kafka_msg_partitioner_fnv1a_randomPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_msg_partitioner_fnv1a_random');
  late final _rd_kafka_msg_partitioner_fnv1a_random =
      _rd_kafka_msg_partitioner_fnv1a_randomPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Pointer<ffi.Void>,
              int, int, ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  /// @brief Creates a new Kafka handle and starts its operation according to the
  /// specified \p type (\p RD_KAFKA_CONSUMER or \p RD_KAFKA_PRODUCER).
  ///
  /// \p conf is an optional struct created with `rd_kafka_conf_new()` that will
  /// be used instead of the default configuration.
  /// The \p conf object is freed by this function on success and must not be used
  /// or destroyed by the application subsequently.
  /// See `rd_kafka_conf_set()` et.al for more information.
  ///
  /// \p errstr must be a pointer to memory of at least size \p errstr_size where
  /// `rd_kafka_new()` may write a human readable error message in case the
  /// creation of a new handle fails. In which case the function returns NULL.
  ///
  /// @remark \b RD_KAFKA_CONSUMER: When a new \p RD_KAFKA_CONSUMER
  /// rd_kafka_t handle is created it may either operate in the
  /// legacy simple consumer mode using the rd_kafka_consume_start()
  /// interface, or the High-level KafkaConsumer API.
  /// @remark An application must only use one of these groups of APIs on a given
  /// rd_kafka_t RD_KAFKA_CONSUMER handle.
  ///
  ///
  /// @returns The Kafka handle on success or NULL on error (see \p errstr)
  ///
  /// @sa To destroy the Kafka handle, use rd_kafka_destroy().
  ffi.Pointer<rd_kafka_t> rd_kafka_new(
    int type,
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_new(
      type,
      conf,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_t> Function(
              ffi.Int32,
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_new');
  late final _rd_kafka_new = _rd_kafka_newPtr.asFunction<
      ffi.Pointer<rd_kafka_t> Function(
          int, ffi.Pointer<rd_kafka_conf_t>, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Destroy Kafka handle.
  ///
  /// @remark This is a blocking operation.
  /// @remark rd_kafka_consumer_close() will be called from this function
  /// if the instance type is RD_KAFKA_CONSUMER, a \c group.id was
  /// configured, and the rd_kafka_consumer_close() was not
  /// explicitly called by the application. This in turn may
  /// trigger consumer callbacks, such as rebalance_cb.
  /// Use rd_kafka_destroy_flags() with
  /// RD_KAFKA_DESTROY_F_NO_CONSUMER_CLOSE to avoid this behaviour.
  ///
  /// @sa rd_kafka_destroy_flags()
  void rd_kafka_destroy(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_destroy(
      rk,
    );
  }

  late final _rd_kafka_destroyPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_destroy');
  late final _rd_kafka_destroy =
      _rd_kafka_destroyPtr.asFunction<void Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Destroy Kafka handle according to specified destroy flags
  void rd_kafka_destroy_flags(
    ffi.Pointer<rd_kafka_t> rk,
    int flags,
  ) {
    return _rd_kafka_destroy_flags(
      rk,
      flags,
    );
  }

  late final _rd_kafka_destroy_flagsPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_t>, ffi.Int)>>(
      'rd_kafka_destroy_flags');
  late final _rd_kafka_destroy_flags = _rd_kafka_destroy_flagsPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Returns Kafka handle name.
  ffi.Pointer<ffi.Char> rd_kafka_name(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_name(
      rk,
    );
  }

  late final _rd_kafka_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_name');
  late final _rd_kafka_name = _rd_kafka_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Returns Kafka handle type.
  int rd_kafka_type(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_type(
      rk,
    );
  }

  late final _rd_kafka_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_type');
  late final _rd_kafka_type =
      _rd_kafka_typePtr.asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Returns this client's broker-assigned group member id.
  ///
  /// @remark This currently requires the high-level KafkaConsumer
  ///
  /// @returns An allocated string containing the current broker-assigned group
  /// member id, or NULL if not available.
  /// The application must free the string with \p free() or
  /// rd_kafka_mem_free()
  ffi.Pointer<ffi.Char> rd_kafka_memberid(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_memberid(
      rk,
    );
  }

  late final _rd_kafka_memberidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_memberid');
  late final _rd_kafka_memberid = _rd_kafka_memberidPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Returns the ClusterId as reported in broker metadata.
  ///
  /// @param rk         Client instance.
  /// @param timeout_ms If there is no cached value from metadata retrieval
  /// then this specifies the maximum amount of time
  /// (in milliseconds) the call will block waiting
  /// for metadata to be retrieved.
  /// Use 0 for non-blocking calls.
  ///
  /// @remark Requires broker version >=0.10.0 and api.version.request=true.
  ///
  /// @remark The application must free the returned pointer
  /// using rd_kafka_mem_free().
  ///
  /// @returns a newly allocated string containing the ClusterId, or NULL
  /// if no ClusterId could be retrieved in the allotted timespan.
  ffi.Pointer<ffi.Char> rd_kafka_clusterid(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_clusterid(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_clusteridPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_clusterid');
  late final _rd_kafka_clusterid = _rd_kafka_clusteridPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Returns the current ControllerId as reported in broker metadata.
  ///
  /// @param rk         Client instance.
  /// @param timeout_ms If there is no cached value from metadata retrieval
  /// then this specifies the maximum amount of time
  /// (in milliseconds) the call will block waiting
  /// for metadata to be retrieved.
  /// Use 0 for non-blocking calls.
  ///
  /// @remark Requires broker version >=0.10.0 and api.version.request=true.
  ///
  /// @returns the controller broker id (>= 0), or -1 if no ControllerId could be
  /// retrieved in the allotted timespan.
  int rd_kafka_controllerid(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_controllerid(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_controlleridPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_controllerid');
  late final _rd_kafka_controllerid = _rd_kafka_controlleridPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Creates a new topic handle for topic named \p topic.
  ///
  /// \p conf is an optional configuration for the topic created with
  /// `rd_kafka_topic_conf_new()` that will be used instead of the default
  /// topic configuration.
  /// The \p conf object is freed by this function and must not be used or
  /// destroyed by the application subsequently.
  /// See `rd_kafka_topic_conf_set()` et.al for more information.
  ///
  /// Topic handles are refcounted internally and calling rd_kafka_topic_new()
  /// again with the same topic name will return the previous topic handle
  /// without updating the original handle's configuration.
  /// Applications must eventually call rd_kafka_topic_destroy() for each
  /// succesfull call to rd_kafka_topic_new() to clear up resources.
  ///
  /// @returns the new topic handle or NULL on error (use rd_kafka_errno2err()
  /// to convert system \p errno to an rd_kafka_resp_err_t error code.
  ///
  /// @sa rd_kafka_topic_destroy()
  ffi.Pointer<rd_kafka_topic_t> rd_kafka_topic_new(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> topic,
    ffi.Pointer<rd_kafka_topic_conf_t> conf,
  ) {
    return _rd_kafka_topic_new(
      rk,
      topic,
      conf,
    );
  }

  late final _rd_kafka_topic_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_topic_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_topic_conf_t>)>>('rd_kafka_topic_new');
  late final _rd_kafka_topic_new = _rd_kafka_topic_newPtr.asFunction<
      ffi.Pointer<rd_kafka_topic_t> Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Char>, ffi.Pointer<rd_kafka_topic_conf_t>)>();

  /// @brief Loose application's topic handle refcount as previously created
  /// with `rd_kafka_topic_new()`.
  ///
  /// @remark Since topic objects are refcounted (both internally and for the app)
  /// the topic object might not actually be destroyed by this call,
  /// but the application must consider the object destroyed.
  void rd_kafka_topic_destroy(
    ffi.Pointer<rd_kafka_topic_t> rkt,
  ) {
    return _rd_kafka_topic_destroy(
      rkt,
    );
  }

  late final _rd_kafka_topic_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_topic_t>)>>(
      'rd_kafka_topic_destroy');
  late final _rd_kafka_topic_destroy = _rd_kafka_topic_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_topic_t>)>();

  /// @brief Returns the topic name.
  ffi.Pointer<ffi.Char> rd_kafka_topic_name(
    ffi.Pointer<rd_kafka_topic_t> rkt,
  ) {
    return _rd_kafka_topic_name(
      rkt,
    );
  }

  late final _rd_kafka_topic_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_topic_t>)>>('rd_kafka_topic_name');
  late final _rd_kafka_topic_name = _rd_kafka_topic_namePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_topic_t>)>();

  /// @brief Get the \p rkt_opaque pointer that was set in the topic configuration
  /// with rd_kafka_topic_conf_set_opaque().
  ffi.Pointer<ffi.Void> rd_kafka_topic_opaque(
    ffi.Pointer<rd_kafka_topic_t> rkt,
  ) {
    return _rd_kafka_topic_opaque(
      rkt,
    );
  }

  late final _rd_kafka_topic_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<rd_kafka_topic_t>)>>('rd_kafka_topic_opaque');
  late final _rd_kafka_topic_opaque = _rd_kafka_topic_opaquePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_topic_t>)>();

  /// @brief Polls the provided kafka handle for events.
  ///
  /// Events will cause application-provided callbacks to be called.
  ///
  /// The \p timeout_ms argument specifies the maximum amount of time
  /// (in milliseconds) that the call will block waiting for events.
  /// For non-blocking calls, provide 0 as \p timeout_ms.
  /// To wait indefinitely for an event, provide -1.
  ///
  /// @remark  An application should make sure to call poll() at regular
  /// intervals to serve any queued callbacks waiting to be called.
  /// @remark  If your producer doesn't have any callback set (in particular
  /// via rd_kafka_conf_set_dr_msg_cb or rd_kafka_conf_set_error_cb)
  /// you might choose not to call poll(), though this is not
  /// recommended.
  ///
  /// Events:
  /// - delivery report callbacks (if dr_cb/dr_msg_cb is configured) [producer]
  /// - error callbacks (rd_kafka_conf_set_error_cb()) [all]
  /// - stats callbacks (rd_kafka_conf_set_stats_cb()) [all]
  /// - throttle callbacks (rd_kafka_conf_set_throttle_cb()) [all]
  /// - OAUTHBEARER token refresh callbacks
  /// (rd_kafka_conf_set_oauthbearer_token_refresh_cb()) [all]
  ///
  /// @returns the number of events served.
  int rd_kafka_poll(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_poll(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_pollPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_poll');
  late final _rd_kafka_poll = _rd_kafka_pollPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Cancels the current callback dispatcher (rd_kafka_poll(),
  /// rd_kafka_consume_callback(), etc).
  ///
  /// A callback may use this to force an immediate return to the calling
  /// code (caller of e.g. rd_kafka_poll()) without processing any further
  /// events.
  ///
  /// @remark This function MUST ONLY be called from within a librdkafka callback.
  void rd_kafka_yield(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_yield(
      rk,
    );
  }

  late final _rd_kafka_yieldPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_yield');
  late final _rd_kafka_yield =
      _rd_kafka_yieldPtr.asFunction<void Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Pause producing or consumption for the provided list of partitions.
  ///
  /// Success or error is returned per-partition \p err in the \p partitions list.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR
  int rd_kafka_pause_partitions(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_pause_partitions(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_pause_partitionsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_pause_partitions');
  late final _rd_kafka_pause_partitions =
      _rd_kafka_pause_partitionsPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Resume producing consumption for the provided list of partitions.
  ///
  /// Success or error is returned per-partition \p err in the \p partitions list.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR
  int rd_kafka_resume_partitions(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_resume_partitions(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_resume_partitionsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_resume_partitions');
  late final _rd_kafka_resume_partitions =
      _rd_kafka_resume_partitionsPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Query broker for low (oldest/beginning) and high (newest/end) offsets
  /// for partition.
  ///
  /// Offsets are returned in \p *low and \p *high respectively.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on failure.
  int rd_kafka_query_watermark_offsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> topic,
    int partition,
    ffi.Pointer<ffi.Int64> low,
    ffi.Pointer<ffi.Int64> high,
    int timeout_ms,
  ) {
    return _rd_kafka_query_watermark_offsets(
      rk,
      topic,
      partition,
      low,
      high,
      timeout_ms,
    );
  }

  late final _rd_kafka_query_watermark_offsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Pointer<ffi.Int64>,
              ffi.Pointer<ffi.Int64>,
              ffi.Int)>>('rd_kafka_query_watermark_offsets');
  late final _rd_kafka_query_watermark_offsets =
      _rd_kafka_query_watermark_offsetsPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>, int,
              ffi.Pointer<ffi.Int64>, ffi.Pointer<ffi.Int64>, int)>();

  /// @brief Get last known low (oldest/beginning) and high (newest/end) offsets
  /// for partition.
  ///
  /// The low offset is updated periodically (if statistics.interval.ms is set)
  /// while the high offset is updated on each fetched message set from the broker.
  ///
  /// If there is no cached offset (either low or high, or both) then
  /// RD_KAFKA_OFFSET_INVALID will be returned for the respective offset.
  ///
  /// Offsets are returned in \p *low and \p *high respectively.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on failure.
  ///
  /// @remark Shall only be used with an active consumer instance.
  int rd_kafka_get_watermark_offsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> topic,
    int partition,
    ffi.Pointer<ffi.Int64> low,
    ffi.Pointer<ffi.Int64> high,
  ) {
    return _rd_kafka_get_watermark_offsets(
      rk,
      topic,
      partition,
      low,
      high,
    );
  }

  late final _rd_kafka_get_watermark_offsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Pointer<ffi.Int64>,
              ffi.Pointer<ffi.Int64>)>>('rd_kafka_get_watermark_offsets');
  late final _rd_kafka_get_watermark_offsets =
      _rd_kafka_get_watermark_offsetsPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>, int,
              ffi.Pointer<ffi.Int64>, ffi.Pointer<ffi.Int64>)>();

  /// @brief Look up the offsets for the given partitions by timestamp.
  ///
  /// The returned offset for each partition is the earliest offset whose
  /// timestamp is greater than or equal to the given timestamp in the
  /// corresponding partition.
  ///
  /// The timestamps to query are represented as \c offset in \p offsets
  /// on input, and \c offset will contain the offset on output.
  ///
  /// The function will block for at most \p timeout_ms milliseconds.
  ///
  /// @remark Duplicate Topic+Partitions are not supported.
  /// @remark Per-partition errors may be returned in \c
  /// rd_kafka_topic_partition_t.err
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if offsets were be queried (do note
  /// that per-partition errors might be set),
  /// RD_KAFKA_RESP_ERR__TIMED_OUT if not all offsets could be fetched
  /// within \p timeout_ms,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if the \p offsets list is empty,
  /// RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION if all partitions are unknown,
  /// RD_KAFKA_RESP_ERR_LEADER_NOT_AVAILABLE if unable to query leaders
  /// for the given partitions.
  int rd_kafka_offsets_for_times(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
    int timeout_ms,
  ) {
    return _rd_kafka_offsets_for_times(
      rk,
      offsets,
      timeout_ms,
    );
  }

  late final _rd_kafka_offsets_for_timesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Int)>>('rd_kafka_offsets_for_times');
  late final _rd_kafka_offsets_for_times =
      _rd_kafka_offsets_for_timesPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>, int)>();

  /// @brief Allocate and zero memory using the same allocator librdkafka uses.
  ///
  /// This is typically an abstraction for the calloc(3) call and makes sure
  /// the application can use the same memory allocator as librdkafka for
  /// allocating pointers that are used by librdkafka.
  ///
  /// \p rk can be set to return memory allocated by a specific \c rk instance
  /// otherwise pass NULL for \p rk.
  ///
  /// @remark Memory allocated by rd_kafka_mem_calloc() must be freed using
  /// rd_kafka_mem_free()
  ffi.Pointer<ffi.Void> rd_kafka_mem_calloc(
    ffi.Pointer<rd_kafka_t> rk,
    int num,
    int size,
  ) {
    return _rd_kafka_mem_calloc(
      rk,
      num,
      size,
    );
  }

  late final _rd_kafka_mem_callocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_t>, ffi.Size,
              ffi.Size)>>('rd_kafka_mem_calloc');
  late final _rd_kafka_mem_calloc = _rd_kafka_mem_callocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_t>, int, int)>();

  /// @brief Allocate memory using the same allocator librdkafka uses.
  ///
  /// This is typically an abstraction for the malloc(3) call and makes sure
  /// the application can use the same memory allocator as librdkafka for
  /// allocating pointers that are used by librdkafka.
  ///
  /// \p rk can be set to return memory allocated by a specific \c rk instance
  /// otherwise pass NULL for \p rk.
  ///
  /// @remark Memory allocated by rd_kafka_mem_malloc() must be freed using
  /// rd_kafka_mem_free()
  ffi.Pointer<ffi.Void> rd_kafka_mem_malloc(
    ffi.Pointer<rd_kafka_t> rk,
    int size,
  ) {
    return _rd_kafka_mem_malloc(
      rk,
      size,
    );
  }

  late final _rd_kafka_mem_mallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Size)>>('rd_kafka_mem_malloc');
  late final _rd_kafka_mem_malloc = _rd_kafka_mem_mallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Free pointer returned by librdkafka
  ///
  /// This is typically an abstraction for the free(3) call and makes sure
  /// the application can use the same memory allocator as librdkafka for
  /// freeing pointers returned by librdkafka.
  ///
  /// In standard setups it is usually not necessary to use this interface
  /// rather than the free(3) functione.
  ///
  /// \p rk must be set for memory returned by APIs that take an \c rk argument,
  /// for other APIs pass NULL for \p rk.
  ///
  /// @remark rd_kafka_mem_free() must only be used for pointers returned by APIs
  /// that explicitly mention using this function for freeing.
  void rd_kafka_mem_free(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Void> ptr,
  ) {
    return _rd_kafka_mem_free(
      rk,
      ptr,
    );
  }

  late final _rd_kafka_mem_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_mem_free');
  late final _rd_kafka_mem_free = _rd_kafka_mem_freePtr.asFunction<
      void Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Void>)>();

  /// @brief Create a new message queue.
  ///
  /// See rd_kafka_consume_start_queue(), rd_kafka_consume_queue(), et.al.
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_new(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_queue_new(
      rk,
    );
  }

  late final _rd_kafka_queue_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_queue_new');
  late final _rd_kafka_queue_new = _rd_kafka_queue_newPtr.asFunction<
      ffi.Pointer<rd_kafka_queue_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// Destroy a queue, purging all of its enqueued messages.
  void rd_kafka_queue_destroy(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_queue_destroy(
      rkqu,
    );
  }

  late final _rd_kafka_queue_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_queue_destroy');
  late final _rd_kafka_queue_destroy = _rd_kafka_queue_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_queue_t>)>();

  /// @returns a reference to the main librdkafka event queue.
  /// This is the queue served by rd_kafka_poll().
  ///
  /// Use rd_kafka_queue_destroy() to loose the reference.
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_get_main(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_queue_get_main(
      rk,
    );
  }

  late final _rd_kafka_queue_get_mainPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_queue_get_main');
  late final _rd_kafka_queue_get_main = _rd_kafka_queue_get_mainPtr.asFunction<
      ffi.Pointer<rd_kafka_queue_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @returns a reference to the SASL callback queue, if a SASL mechanism
  /// with callbacks is configured (currently only OAUTHBEARER), else
  /// returns NULL.
  ///
  /// Use rd_kafka_queue_destroy() to loose the reference.
  ///
  /// @sa rd_kafka_sasl_background_callbacks_enable()
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_get_sasl(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_queue_get_sasl(
      rk,
    );
  }

  late final _rd_kafka_queue_get_saslPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_queue_get_sasl');
  late final _rd_kafka_queue_get_sasl = _rd_kafka_queue_get_saslPtr.asFunction<
      ffi.Pointer<rd_kafka_queue_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Enable SASL OAUTHBEARER refresh callbacks on the librdkafka
  /// background thread.
  ///
  /// This serves as an alternative for applications that do not call
  /// rd_kafka_poll() (et.al.) at regular intervals (or not at all), as a means
  /// of automatically trigger the refresh callbacks, which are needed to
  /// initiate connections to the brokers in the case a custom OAUTHBEARER
  /// refresh callback is configured.
  ///
  /// @returns NULL on success or an error object on error.
  ///
  /// @sa rd_kafka_queue_get_sasl()
  /// @sa rd_kafka_conf_set_oauthbearer_token_refresh_cb()
  ffi.Pointer<rd_kafka_error_t> rd_kafka_sasl_background_callbacks_enable(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_sasl_background_callbacks_enable(
      rk,
    );
  }

  late final _rd_kafka_sasl_background_callbacks_enablePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>)>>(
      'rd_kafka_sasl_background_callbacks_enable');
  late final _rd_kafka_sasl_background_callbacks_enable =
      _rd_kafka_sasl_background_callbacks_enablePtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Sets SASL credentials used for SASL PLAIN and SCRAM mechanisms by
  /// this Kafka client.
  ///
  /// This function sets or resets the SASL username and password credentials
  /// used by this Kafka client. The new credentials will be used the next time
  /// this client needs to authenticate to a broker. This function
  /// will not disconnect existing connections that might have been made using
  /// the old credentials.
  ///
  /// @remark This function only applies to the SASL PLAIN and SCRAM mechanisms.
  ///
  /// @returns NULL on success or an error object on error.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_sasl_set_credentials(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> username,
    ffi.Pointer<ffi.Char> password,
  ) {
    return _rd_kafka_sasl_set_credentials(
      rk,
      username,
      password,
    );
  }

  late final _rd_kafka_sasl_set_credentialsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_sasl_set_credentials');
  late final _rd_kafka_sasl_set_credentials =
      _rd_kafka_sasl_set_credentialsPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  /// @returns a reference to the librdkafka consumer queue.
  /// This is the queue served by rd_kafka_consumer_poll().
  ///
  /// Use rd_kafka_queue_destroy() to loose the reference.
  ///
  /// @remark rd_kafka_queue_destroy() MUST be called on this queue
  /// prior to calling rd_kafka_consumer_close().
  /// @remark Polling the returned queue counts as a consumer poll, and will reset
  /// the timer for max.poll.interval.ms. If this queue is forwarded to a
  /// "destq", polling destq also counts as a consumer poll (this works
  /// for any number of forwards). However, even if this queue is
  /// unforwarded or forwarded elsewhere, polling destq will continue
  /// to count as a consumer poll.
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_get_consumer(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_queue_get_consumer(
      rk,
    );
  }

  late final _rd_kafka_queue_get_consumerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_queue_get_consumer');
  late final _rd_kafka_queue_get_consumer =
      _rd_kafka_queue_get_consumerPtr.asFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @returns a reference to the partition's queue, or NULL if
  /// partition is invalid.
  ///
  /// Use rd_kafka_queue_destroy() to loose the reference.
  ///
  /// @remark rd_kafka_queue_destroy() MUST be called on this queue
  ///
  /// @remark This function only works on consumers.
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_get_partition(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> topic,
    int partition,
  ) {
    return _rd_kafka_queue_get_partition(
      rk,
      topic,
      partition,
    );
  }

  late final _rd_kafka_queue_get_partitionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('rd_kafka_queue_get_partition');
  late final _rd_kafka_queue_get_partition =
      _rd_kafka_queue_get_partitionPtr.asFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>, int)>();

  /// @returns a reference to the background thread queue, or NULL if the
  /// background queue is not enabled.
  ///
  /// The background thread queue provides the application with an automatically
  /// polled queue that triggers the event callback in a background thread,
  /// this background thread is completely managed by librdkafka.
  ///
  /// The background thread queue is automatically created if a generic event
  /// handler callback is configured with rd_kafka_conf_set_background_event_cb()
  /// or if rd_kafka_queue_get_background() is called.
  ///
  /// The background queue is polled and served by librdkafka and MUST NOT be
  /// polled, forwarded, or otherwise managed by the application, it may only
  /// be used as the destination queue passed to queue-enabled APIs, such as
  /// the Admin API.
  ///
  /// Use rd_kafka_queue_destroy() to loose the reference.
  ///
  /// @warning The background queue MUST NOT be read from (polled, consumed, etc),
  /// or forwarded from.
  ffi.Pointer<rd_kafka_queue_t> rd_kafka_queue_get_background(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_queue_get_background(
      rk,
    );
  }

  late final _rd_kafka_queue_get_backgroundPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_queue_get_background');
  late final _rd_kafka_queue_get_background =
      _rd_kafka_queue_get_backgroundPtr.asFunction<
          ffi.Pointer<rd_kafka_queue_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Forward/re-route queue \p src to \p dst.
  /// If \p dst is \c NULL the forwarding is removed.
  ///
  /// The internal refcounts for both queues are increased.
  ///
  /// @remark Regardless of whether \p dst is NULL or not, after calling this
  /// function, \p src will not forward it's fetch queue to the consumer
  /// queue.
  void rd_kafka_queue_forward(
    ffi.Pointer<rd_kafka_queue_t> src,
    ffi.Pointer<rd_kafka_queue_t> dst,
  ) {
    return _rd_kafka_queue_forward(
      src,
      dst,
    );
  }

  late final _rd_kafka_queue_forwardPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_queue_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_queue_forward');
  late final _rd_kafka_queue_forward = _rd_kafka_queue_forwardPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_queue_t>, ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Forward librdkafka logs (and debug) to the specified queue
  /// for serving with one of the ..poll() calls.
  ///
  /// This allows an application to serve log callbacks (\c log_cb)
  /// in its thread of choice.
  ///
  /// @param rk   Client instance.
  /// @param rkqu Queue to forward logs to. If the value is NULL the logs
  /// are forwarded to the main queue.
  ///
  /// @remark The configuration property \c log.queue MUST also be set to true.
  ///
  /// @remark librdkafka maintains its own reference to the provided queue.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on error,
  /// eg RD_KAFKA_RESP_ERR__NOT_CONFIGURED when log.queue is not set to true.
  int rd_kafka_set_log_queue(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_set_log_queue(
      rk,
      rkqu,
    );
  }

  late final _rd_kafka_set_log_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_set_log_queue');
  late final _rd_kafka_set_log_queue = _rd_kafka_set_log_queuePtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<rd_kafka_queue_t>)>();

  /// @returns the current number of elements in queue.
  int rd_kafka_queue_length(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_queue_length(
      rkqu,
    );
  }

  late final _rd_kafka_queue_lengthPtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_queue_length');
  late final _rd_kafka_queue_length = _rd_kafka_queue_lengthPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Enable IO event triggering for queue.
  ///
  /// To ease integration with IO based polling loops this API
  /// allows an application to create a separate file-descriptor
  /// that librdkafka will write \p payload (of size \p size) to
  /// whenever a new element is enqueued on a previously empty queue.
  ///
  /// To remove event triggering call with \p fd = -1.
  ///
  /// librdkafka will maintain a copy of the \p payload.
  ///
  /// @remark IO and callback event triggering are mutually exclusive.
  /// @remark When using forwarded queues the IO event must only be enabled
  /// on the final forwarded-to (destination) queue.
  /// @remark The file-descriptor/socket must be set to non-blocking.
  void rd_kafka_queue_io_event_enable(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int fd,
    ffi.Pointer<ffi.Void> payload,
    int size,
  ) {
    return _rd_kafka_queue_io_event_enable(
      rkqu,
      fd,
      payload,
      size,
    );
  }

  late final _rd_kafka_queue_io_event_enablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Int,
              ffi.Pointer<ffi.Void>,
              ffi.Size)>>('rd_kafka_queue_io_event_enable');
  late final _rd_kafka_queue_io_event_enable =
      _rd_kafka_queue_io_event_enablePtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_queue_t>, int,
              ffi.Pointer<ffi.Void>, int)>();

  /// @brief Enable callback event triggering for queue.
  ///
  /// The callback will be called from an internal librdkafka thread
  /// when a new element is enqueued on a previously empty queue.
  ///
  /// To remove event triggering call with \p event_cb = NULL.
  ///
  /// The \p qev_opaque is passed to the callback's \p qev_opaque argument.
  ///
  /// @remark IO and callback event triggering are mutually exclusive.
  /// @remark Since the callback may be triggered from internal librdkafka
  /// threads, the application must not perform any pro-longed work in
  /// the callback, or call any librdkafka APIs (for the same rd_kafka_t
  /// handle).
  void rd_kafka_queue_cb_event_enable(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_t> rk,
                    ffi.Pointer<ffi.Void> qev_opaque)>>
        event_cb,
    ffi.Pointer<ffi.Void> qev_opaque,
  ) {
    return _rd_kafka_queue_cb_event_enable(
      rkqu,
      event_cb,
      qev_opaque,
    );
  }

  late final _rd_kafka_queue_cb_event_enablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Void> qev_opaque)>>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_queue_cb_event_enable');
  late final _rd_kafka_queue_cb_event_enable =
      _rd_kafka_queue_cb_event_enablePtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(ffi.Pointer<rd_kafka_t> rk,
                          ffi.Pointer<ffi.Void> qev_opaque)>>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Cancels the current rd_kafka_queue_poll() on \p rkqu.
  ///
  /// An application may use this from another thread to force
  /// an immediate return to the calling code (caller of rd_kafka_queue_poll()).
  /// Must not be used from signal handlers since that may cause deadlocks.
  void rd_kafka_queue_yield(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_queue_yield(
      rkqu,
    );
  }

  late final _rd_kafka_queue_yieldPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_queue_yield');
  late final _rd_kafka_queue_yield = _rd_kafka_queue_yieldPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Start consuming messages for topic \p rkt and \p partition
  /// at offset \p offset which may either be an absolute \c (0..N)
  /// or one of the logical offsets:
  /// - RD_KAFKA_OFFSET_BEGINNING
  /// - RD_KAFKA_OFFSET_END
  /// - RD_KAFKA_OFFSET_STORED
  /// - RD_KAFKA_OFFSET_TAIL
  ///
  /// rdkafka will attempt to keep \c queued.min.messages (config property)
  /// messages in the local queue by repeatedly fetching batches of messages
  /// from the broker until the threshold is reached.
  ///
  /// The application shall use one of the `rd_kafka_consume*()` functions
  /// to consume messages from the local queue, each kafka message being
  /// represented as a `rd_kafka_message_t *` object.
  ///
  /// `rd_kafka_consume_start()` must not be called multiple times for the same
  /// topic and partition without stopping consumption first with
  /// `rd_kafka_consume_stop()`.
  ///
  /// @returns 0 on success or -1 on error in which case errno is set accordingly:
  /// - EBUSY    - Conflicts with an existing or previous subscription
  /// (RD_KAFKA_RESP_ERR__CONFLICT)
  /// - EINVAL   - Invalid offset, or incomplete configuration (lacking group.id)
  /// (RD_KAFKA_RESP_ERR__INVALID_ARG)
  /// - ESRCH    - requested \p partition is invalid.
  /// (RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION)
  /// - ENOENT   - topic is unknown in the Kafka cluster.
  /// (RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC)
  ///
  /// Use `rd_kafka_errno2err()` to convert sytem \c errno to `rd_kafka_resp_err_t`
  int rd_kafka_consume_start(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int offset,
  ) {
    return _rd_kafka_consume_start(
      rkt,
      partition,
      offset,
    );
  }

  late final _rd_kafka_consume_startPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Int32,
              ffi.Int64)>>('rd_kafka_consume_start');
  late final _rd_kafka_consume_start = _rd_kafka_consume_startPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_topic_t>, int, int)>();

  /// @brief Same as rd_kafka_consume_start() but re-routes incoming messages to
  /// the provided queue \p rkqu (which must have been previously allocated
  /// with `rd_kafka_queue_new()`.
  ///
  /// The application must use one of the `rd_kafka_consume_*_queue()` functions
  /// to receive fetched messages.
  ///
  /// `rd_kafka_consume_start_queue()` must not be called multiple times for the
  /// same topic and partition without stopping consumption first with
  /// `rd_kafka_consume_stop()`.
  /// `rd_kafka_consume_start()` and `rd_kafka_consume_start_queue()` must not
  /// be combined for the same topic and partition.
  int rd_kafka_consume_start_queue(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int offset,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_consume_start_queue(
      rkt,
      partition,
      offset,
      rkqu,
    );
  }

  late final _rd_kafka_consume_start_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Int32, ffi.Int64,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_consume_start_queue');
  late final _rd_kafka_consume_start_queue =
      _rd_kafka_consume_start_queuePtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_topic_t>, int, int,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Stop consuming messages for topic \p rkt and \p partition, purging
  /// all messages currently in the local queue.
  ///
  /// NOTE: To enforce synchronisation this call will block until the internal
  /// fetcher has terminated and offsets are committed to configured
  /// storage method.
  ///
  /// The application needs to be stop all consumers before calling
  /// `rd_kafka_destroy()` on the main object handle.
  ///
  /// @returns 0 on success or -1 on error (see `errno`).
  int rd_kafka_consume_stop(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
  ) {
    return _rd_kafka_consume_stop(
      rkt,
      partition,
    );
  }

  late final _rd_kafka_consume_stopPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32)>>('rd_kafka_consume_stop');
  late final _rd_kafka_consume_stop = _rd_kafka_consume_stopPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_topic_t>, int)>();

  /// @brief Seek consumer for topic+partition to \p offset which is either an
  /// absolute or logical offset.
  ///
  /// If \p timeout_ms is specified (not 0) the seek call will wait this long
  /// for the consumer to update its fetcher state for the given partition with
  /// the new offset. This guarantees that no previously fetched messages for the
  /// old offset (or fetch position) will be passed to the application.
  ///
  /// If the timeout is reached the internal state will be unknown to the caller
  /// and this function returns `RD_KAFKA_RESP_ERR__TIMED_OUT`.
  ///
  /// If \p timeout_ms is 0 it will initiate the seek but return
  /// immediately without any error reporting (e.g., async).
  ///
  /// This call will purge all pre-fetched messages for the given partition, which
  /// may be up to \c queued.max.message.kbytes in size. Repeated use of seek
  /// may thus lead to increased network usage as messages are re-fetched from
  /// the broker.
  ///
  /// @remark Seek must only be performed for already assigned/consumed partitions,
  /// use rd_kafka_assign() (et.al) to set the initial starting offset
  /// for a new assignmenmt.
  ///
  /// @returns `RD_KAFKA_RESP_ERR__NO_ERROR` on success else an error code.
  ///
  /// @deprecated Use rd_kafka_seek_partitions().
  int rd_kafka_seek(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int offset,
    int timeout_ms,
  ) {
    return _rd_kafka_seek(
      rkt,
      partition,
      offset,
      timeout_ms,
    );
  }

  late final _rd_kafka_seekPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Int32,
              ffi.Int64, ffi.Int)>>('rd_kafka_seek');
  late final _rd_kafka_seek = _rd_kafka_seekPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_topic_t>, int, int, int)>();

  /// @brief Seek consumer for partitions in \p partitions to the per-partition
  /// offset in the \c .offset field of \p partitions.
  ///
  /// The offset may be either absolute (>= 0) or a logical offset.
  ///
  /// If \p timeout_ms is specified (not 0) the seek call will wait this long
  /// for the consumer to update its fetcher state for the given partition with
  /// the new offset. This guarantees that no previously fetched messages for the
  /// old offset (or fetch position) will be passed to the application.
  ///
  /// If the timeout is reached the internal state will be unknown to the caller
  /// and this function returns `RD_KAFKA_RESP_ERR__TIMED_OUT`.
  ///
  /// If \p timeout_ms is 0 it will initiate the seek but return
  /// immediately without any error reporting (e.g., async).
  ///
  /// This call will purge all pre-fetched messages for the given partition, which
  /// may be up to \c queued.max.message.kbytes in size. Repeated use of seek
  /// may thus lead to increased network usage as messages are re-fetched from
  /// the broker.
  ///
  /// Individual partition errors are reported in the per-partition \c .err field
  /// of \p partitions.
  ///
  /// @remark Seek must only be performed for already assigned/consumed partitions,
  /// use rd_kafka_assign() (et.al) to set the initial starting offset
  /// for a new assignmenmt.
  ///
  /// @returns NULL on success or an error object on failure.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_seek_partitions(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
    int timeout_ms,
  ) {
    return _rd_kafka_seek_partitions(
      rk,
      partitions,
      timeout_ms,
    );
  }

  late final _rd_kafka_seek_partitionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Int)>>('rd_kafka_seek_partitions');
  late final _rd_kafka_seek_partitions =
      _rd_kafka_seek_partitionsPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>, int)>();

  /// @brief Consume a single message from topic \p rkt and \p partition
  ///
  /// \p timeout_ms is maximum amount of time to wait for a message to be received.
  /// Consumer must have been previously started with `rd_kafka_consume_start()`.
  ///
  /// @returns a message object on success or \c NULL on error.
  /// The message object must be destroyed with `rd_kafka_message_destroy()`
  /// when the application is done with it.
  ///
  /// Errors (when returning NULL):
  /// - ETIMEDOUT - \p timeout_ms was reached with no new messages fetched.
  /// - ENOENT    - \p rkt + \p partition is unknown.
  /// (no prior `rd_kafka_consume_start()` call)
  ///
  /// NOTE: The returned message's \c ..->err must be checked for errors.
  /// NOTE: \c ..->err \c == \c RD_KAFKA_RESP_ERR__PARTITION_EOF signals that the
  /// end of the partition has been reached, which should typically not be
  /// considered an error. The application should handle this case
  /// (e.g., ignore).
  ///
  /// @remark on_consume() interceptors may be called from this function prior to
  /// passing message to application.
  ffi.Pointer<rd_kafka_message_t> rd_kafka_consume(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int timeout_ms,
  ) {
    return _rd_kafka_consume(
      rkt,
      partition,
      timeout_ms,
    );
  }

  late final _rd_kafka_consumePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_message_t> Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32,
              ffi.Int)>>('rd_kafka_consume');
  late final _rd_kafka_consume = _rd_kafka_consumePtr.asFunction<
      ffi.Pointer<rd_kafka_message_t> Function(
          ffi.Pointer<rd_kafka_topic_t>, int, int)>();

  /// @brief Consume up to \p rkmessages_size from topic \p rkt and \p partition
  /// putting a pointer to each message in the application provided
  /// array \p rkmessages (of size \p rkmessages_size entries).
  ///
  /// `rd_kafka_consume_batch()` provides higher throughput performance
  /// than `rd_kafka_consume()`.
  ///
  /// \p timeout_ms is the maximum amount of time to wait for all of
  /// \p rkmessages_size messages to be put into \p rkmessages.
  /// If no messages were available within the timeout period this function
  /// returns 0 and \p rkmessages remains untouched.
  /// This differs somewhat from `rd_kafka_consume()`.
  ///
  /// The message objects must be destroyed with `rd_kafka_message_destroy()`
  /// when the application is done with it.
  ///
  /// @returns the number of rkmessages added in \p rkmessages,
  /// or -1 on error (same error codes as for `rd_kafka_consume()`.
  ///
  /// @sa rd_kafka_consume()
  ///
  /// @remark on_consume() interceptors may be called from this function prior to
  /// passing message to application.
  int rd_kafka_consume_batch(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int timeout_ms,
    ffi.Pointer<ffi.Pointer<rd_kafka_message_t>> rkmessages,
    int rkmessages_size,
  ) {
    return _rd_kafka_consume_batch(
      rkt,
      partition,
      timeout_ms,
      rkmessages,
      rkmessages_size,
    );
  }

  late final _rd_kafka_consume_batchPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32,
              ffi.Int,
              ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>,
              ffi.Size)>>('rd_kafka_consume_batch');
  late final _rd_kafka_consume_batch = _rd_kafka_consume_batchPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_topic_t>, int, int,
          ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>, int)>();

  /// @brief Consumes messages from topic \p rkt and \p partition, calling
  /// the provided callback for each consumed messsage.
  ///
  /// `rd_kafka_consume_callback()` provides higher throughput performance
  /// than both `rd_kafka_consume()` and `rd_kafka_consume_batch()`.
  ///
  /// \p timeout_ms is the maximum amount of time to wait for one or more messages
  /// to arrive.
  ///
  /// The provided \p consume_cb function is called for each message,
  /// the application \b MUST \b NOT call `rd_kafka_message_destroy()` on the
  /// provided \p rkmessage.
  ///
  /// The \p commit_opaque argument is passed to the \p consume_cb
  /// as \p commit_opaque.
  ///
  /// @returns the number of messages processed or -1 on error.
  ///
  /// @sa rd_kafka_consume()
  ///
  /// @remark on_consume() interceptors may be called from this function prior to
  /// passing message to application.
  ///
  /// @remark This function will return early if a transaction control message is
  /// received, these messages are not exposed to the application but
  /// still enqueued on the consumer queue to make sure their
  /// offsets are stored.
  ///
  /// @deprecated This API is deprecated and subject for future removal.
  /// There is no new callback-based consume interface, use the
  /// poll/queue based alternatives.
  int rd_kafka_consume_callback(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int timeout_ms,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_message_t> rkmessage,
                    ffi.Pointer<ffi.Void> commit_opaque)>>
        consume_cb,
    ffi.Pointer<ffi.Void> commit_opaque,
  ) {
    return _rd_kafka_consume_callback(
      rkt,
      partition,
      timeout_ms,
      consume_cb,
      commit_opaque,
    );
  }

  late final _rd_kafka_consume_callbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32,
              ffi.Int,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> commit_opaque)>>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_consume_callback');
  late final _rd_kafka_consume_callback =
      _rd_kafka_consume_callbackPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_topic_t>,
              int,
              int,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> commit_opaque)>>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Consume from queue
  ///
  /// @sa rd_kafka_consume()
  ffi.Pointer<rd_kafka_message_t> rd_kafka_consume_queue(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int timeout_ms,
  ) {
    return _rd_kafka_consume_queue(
      rkqu,
      timeout_ms,
    );
  }

  late final _rd_kafka_consume_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_message_t> Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Int)>>('rd_kafka_consume_queue');
  late final _rd_kafka_consume_queue = _rd_kafka_consume_queuePtr.asFunction<
      ffi.Pointer<rd_kafka_message_t> Function(
          ffi.Pointer<rd_kafka_queue_t>, int)>();

  /// @brief Consume batch of messages from queue
  ///
  /// @sa rd_kafka_consume_batch()
  int rd_kafka_consume_batch_queue(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int timeout_ms,
    ffi.Pointer<ffi.Pointer<rd_kafka_message_t>> rkmessages,
    int rkmessages_size,
  ) {
    return _rd_kafka_consume_batch_queue(
      rkqu,
      timeout_ms,
      rkmessages,
      rkmessages_size,
    );
  }

  late final _rd_kafka_consume_batch_queuePtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Int,
              ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>,
              ffi.Size)>>('rd_kafka_consume_batch_queue');
  late final _rd_kafka_consume_batch_queue =
      _rd_kafka_consume_batch_queuePtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_queue_t>, int,
              ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>, int)>();

  /// @brief Consume multiple messages from queue with callback
  ///
  /// @sa rd_kafka_consume_callback()
  ///
  /// @deprecated This API is deprecated and subject for future removal.
  /// There is no new callback-based consume interface, use the
  /// poll/queue based alternatives.
  int rd_kafka_consume_callback_queue(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int timeout_ms,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_message_t> rkmessage,
                    ffi.Pointer<ffi.Void> commit_opaque)>>
        consume_cb,
    ffi.Pointer<ffi.Void> commit_opaque,
  ) {
    return _rd_kafka_consume_callback_queue(
      rkqu,
      timeout_ms,
      consume_cb,
      commit_opaque,
    );
  }

  late final _rd_kafka_consume_callback_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Int,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> commit_opaque)>>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_consume_callback_queue');
  late final _rd_kafka_consume_callback_queue =
      _rd_kafka_consume_callback_queuePtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_queue_t>,
              int,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_message_t> rkmessage,
                          ffi.Pointer<ffi.Void> commit_opaque)>>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Store offset \p offset + 1 for topic \p rkt partition \p partition.
  ///
  /// The \c offset + 1 will be committed (written) to broker (or file) according
  /// to \c `auto.commit.interval.ms` or manual offset-less commit()
  ///
  /// @deprecated This API lacks support for partition leader epochs, which makes
  /// it at risk for unclean leader election log truncation issues.
  /// Use rd_kafka_offsets_store() and rd_kafka_offset_store_message()
  /// instead.
  ///
  /// @warning This method may only be called for partitions that are currently
  /// assigned.
  /// Non-assigned partitions will fail with RD_KAFKA_RESP_ERR__STATE.
  /// Since v1.9.0.
  ///
  /// @warning Avoid storing offsets after calling rd_kafka_seek() (et.al) as
  /// this may later interfere with resuming a paused partition, instead
  /// store offsets prior to calling seek.
  ///
  /// @remark \c `enable.auto.offset.store` must be set to "false" when using
  /// this API.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on error.
  int rd_kafka_offset_store(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int offset,
  ) {
    return _rd_kafka_offset_store(
      rkt,
      partition,
      offset,
    );
  }

  late final _rd_kafka_offset_storePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<rd_kafka_topic_t>, ffi.Int32,
              ffi.Int64)>>('rd_kafka_offset_store');
  late final _rd_kafka_offset_store = _rd_kafka_offset_storePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_topic_t>, int, int)>();

  /// @brief Store offsets for next auto-commit for one or more partitions.
  ///
  /// The offset will be committed (written) to the offset store according
  /// to \c `auto.commit.interval.ms` or manual offset-less commit().
  ///
  /// Per-partition success/error status propagated through each partition's
  /// \c .err for all return values (even NO_ERROR) except INVALID_ARG.
  ///
  /// @warning This method may only be called for partitions that are currently
  /// assigned.
  /// Non-assigned partitions will fail with RD_KAFKA_RESP_ERR__STATE.
  /// Since v1.9.0.
  ///
  /// @warning Avoid storing offsets after calling rd_kafka_seek() (et.al) as
  /// this may later interfere with resuming a paused partition, instead
  /// store offsets prior to calling seek.
  ///
  /// @remark The \c .offset field is stored as is, it will NOT be + 1.
  ///
  /// @remark \c `enable.auto.offset.store` must be set to "false" when using
  /// this API.
  ///
  /// @remark The leader epoch, if set, will be used to fence outdated partition
  /// leaders. See rd_kafka_topic_partition_set_leader_epoch().
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on (partial) success, or
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \c enable.auto.offset.store
  /// is true, or
  /// RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION or RD_KAFKA_RESP_ERR__STATE
  /// if none of the offsets could be stored.
  int rd_kafka_offsets_store(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
  ) {
    return _rd_kafka_offsets_store(
      rk,
      offsets,
    );
  }

  late final _rd_kafka_offsets_storePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_offsets_store');
  late final _rd_kafka_offsets_store = _rd_kafka_offsets_storePtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Store offset +1 for the consumed message.
  ///
  /// The message offset + 1 will be committed to broker according
  /// to \c `auto.commit.interval.ms` or manual offset-less commit()
  ///
  /// @warning This method may only be called for partitions that are currently
  /// assigned.
  /// Non-assigned partitions will fail with RD_KAFKA_RESP_ERR__STATE.
  /// Since v1.9.0.
  ///
  /// @warning Avoid storing offsets after calling rd_kafka_seek() (et.al) as
  /// this may later interfere with resuming a paused partition, instead
  /// store offsets prior to calling seek.
  ///
  /// @remark \c `enable.auto.offset.store` must be set to "false" when using
  /// this API.
  ///
  /// @returns NULL on success or an error object on failure.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_offset_store_message(
    ffi.Pointer<rd_kafka_message_t> rkmessage,
  ) {
    return _rd_kafka_offset_store_message(
      rkmessage,
    );
  }

  late final _rd_kafka_offset_store_messagePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_message_t>)>>(
      'rd_kafka_offset_store_message');
  late final _rd_kafka_offset_store_message =
      _rd_kafka_offset_store_messagePtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_message_t>)>();

  /// @brief Subscribe to topic set using balanced consumer groups.
  ///
  /// Wildcard (regex) topics are supported:
  /// any topic name in the \p topics list that is prefixed with \c \"^\" will
  /// be regex-matched to the full list of topics in the cluster and matching
  /// topics will be added to the subscription list.
  ///
  /// The full topic list is retrieved every \c topic.metadata.refresh.interval.ms
  /// to pick up new or delete topics that match the subscription.
  /// If there is any change to the matched topics the consumer will
  /// immediately rejoin the group with the updated set of subscribed topics.
  ///
  /// Regex and full topic names can be mixed in \p topics.
  ///
  /// @remark Only the \c .topic field is used in the supplied \p topics list,
  /// all other fields are ignored.
  ///
  /// @remark subscribe() is an asynchronous method which returns immediately:
  /// background threads will (re)join the group, wait for group rebalance,
  /// issue any registered rebalance_cb, assign() the assigned partitions,
  /// and then start fetching messages. This cycle may take up to
  /// \c session.timeout.ms * 2 or more to complete.
  ///
  /// @remark After this call returns a consumer error will be returned by
  /// rd_kafka_consumer_poll (et.al) for each unavailable topic in the
  /// \p topics. The error will be RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_OR_PART
  /// for non-existent topics, and
  /// RD_KAFKA_RESP_ERR_TOPIC_AUTHORIZATION_FAILED for unauthorized topics.
  /// The consumer error will be raised through rd_kafka_consumer_poll()
  /// (et.al.) with the \c rd_kafka_message_t.err field set to one of the
  /// error codes mentioned above.
  /// The subscribe function itself is asynchronous and will not return
  /// an error on unavailable topics.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if list is empty, contains invalid
  /// topics or regexes or duplicate entries,
  /// RD_KAFKA_RESP_ERR__FATAL if the consumer has raised a fatal error.
  int rd_kafka_subscribe(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> topics,
  ) {
    return _rd_kafka_subscribe(
      rk,
      topics,
    );
  }

  late final _rd_kafka_subscribePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_subscribe');
  late final _rd_kafka_subscribe = _rd_kafka_subscribePtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Unsubscribe from the current subscription set.
  int rd_kafka_unsubscribe(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_unsubscribe(
      rk,
    );
  }

  late final _rd_kafka_unsubscribePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_unsubscribe');
  late final _rd_kafka_unsubscribe = _rd_kafka_unsubscribePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Returns the current topic subscription
  ///
  /// @returns An error code on failure, otherwise \p topic is updated
  /// to point to a newly allocated topic list (possibly empty).
  ///
  /// @remark The application is responsible for calling
  /// rd_kafka_topic_partition_list_destroy on the returned list.
  int rd_kafka_subscription(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>> topics,
  ) {
    return _rd_kafka_subscription(
      rk,
      topics,
    );
  }

  late final _rd_kafka_subscriptionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>>)>>(
      'rd_kafka_subscription');
  late final _rd_kafka_subscription = _rd_kafka_subscriptionPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>>)>();

  /// @brief Poll the consumer for messages or events.
  ///
  /// Will block for at most \p timeout_ms milliseconds.
  ///
  /// @remark  An application should make sure to call consumer_poll() at regular
  /// intervals, even if no messages are expected, to serve any
  /// queued callbacks waiting to be called. This is especially
  /// important when a rebalance_cb has been registered as it needs
  /// to be called and handled properly to synchronize internal
  /// consumer state.
  ///
  /// @returns A message object which is a proper message if \p ->err is
  /// RD_KAFKA_RESP_ERR_NO_ERROR, or an event or error for any other
  /// value.
  ///
  /// @remark on_consume() interceptors may be called from this function prior to
  /// passing message to application.
  ///
  /// @remark When subscribing to topics the application must call poll at
  /// least every \c max.poll.interval.ms to remain a member of the
  /// consumer group.
  ///
  /// Noteworthy errors returned in \c ->err:
  /// - RD_KAFKA_RESP_ERR__MAX_POLL_EXCEEDED - application failed to call
  /// poll within `max.poll.interval.ms`.
  ///
  /// @sa rd_kafka_message_t
  ffi.Pointer<rd_kafka_message_t> rd_kafka_consumer_poll(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_consumer_poll(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_consumer_pollPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_message_t> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_consumer_poll');
  late final _rd_kafka_consumer_poll = _rd_kafka_consumer_pollPtr.asFunction<
      ffi.Pointer<rd_kafka_message_t> Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Close the consumer.
  ///
  /// This call will block until the consumer has revoked its assignment,
  /// calling the \c rebalance_cb if it is configured, committed offsets
  /// to broker, and left the consumer group (if applicable).
  /// The maximum blocking time is roughly limited to session.timeout.ms.
  ///
  /// @returns An error code indicating if the consumer close was succesful
  /// or not.
  /// RD_KAFKA_RESP_ERR__FATAL is returned if the consumer has raised
  /// a fatal error.
  ///
  /// @remark The application still needs to call rd_kafka_destroy() after
  /// this call finishes to clean up the underlying handle resources.
  int rd_kafka_consumer_close(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_consumer_close(
      rk,
    );
  }

  late final _rd_kafka_consumer_closePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_consumer_close');
  late final _rd_kafka_consumer_close = _rd_kafka_consumer_closePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Asynchronously close the consumer.
  ///
  /// Performs the same actions as rd_kafka_consumer_close() but in a
  /// background thread.
  ///
  /// Rebalance events/callbacks (etc) will be forwarded to the
  /// application-provided \p rkqu. The application must poll/serve this queue
  /// until rd_kafka_consumer_closed() returns true.
  ///
  /// @remark Depending on consumer group join state there may or may not be
  /// rebalance events emitted on \p rkqu.
  ///
  /// @returns an error object if the consumer close failed, else NULL.
  ///
  /// @sa rd_kafka_consumer_closed()
  ffi.Pointer<rd_kafka_error_t> rd_kafka_consumer_close_queue(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_consumer_close_queue(
      rk,
      rkqu,
    );
  }

  late final _rd_kafka_consumer_close_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_consumer_close_queue');
  late final _rd_kafka_consumer_close_queue =
      _rd_kafka_consumer_close_queuePtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Pointer<rd_kafka_queue_t>)>();

  /// @returns 1 if the consumer is closed, else 0.
  ///
  /// Should be used in conjunction with rd_kafka_consumer_close_queue() to know
  /// when the consumer has been closed.
  ///
  /// @sa rd_kafka_consumer_close_queue()
  int rd_kafka_consumer_closed(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_consumer_closed(
      rk,
    );
  }

  late final _rd_kafka_consumer_closedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_consumer_closed');
  late final _rd_kafka_consumer_closed = _rd_kafka_consumer_closedPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Incrementally add \p partitions to the current assignment.
  ///
  /// If a COOPERATIVE assignor (i.e. incremental rebalancing) is being used,
  /// this method should be used in a rebalance callback to adjust the current
  /// assignment appropriately in the case where the rebalance type is
  /// RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS. The application must pass the
  /// partition list passed to the callback (or a copy of it), even if the
  /// list is empty. \p partitions must not be NULL. This method may also be
  /// used outside the context of a rebalance callback.
  ///
  /// @returns NULL on success, or an error object if the operation was
  /// unsuccessful.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_incremental_assign(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_incremental_assign(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_incremental_assignPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_incremental_assign');
  late final _rd_kafka_incremental_assign =
      _rd_kafka_incremental_assignPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Incrementally remove \p partitions from the current assignment.
  ///
  /// If a COOPERATIVE assignor (i.e. incremental rebalancing) is being used,
  /// this method should be used in a rebalance callback to adjust the current
  /// assignment appropriately in the case where the rebalance type is
  /// RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS. The application must pass the
  /// partition list passed to the callback (or a copy of it), even if the
  /// list is empty. \p partitions must not be NULL. This method may also be
  /// used outside the context of a rebalance callback.
  ///
  /// @returns NULL on success, or an error object if the operation was
  /// unsuccessful.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_incremental_unassign(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_incremental_unassign(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_incremental_unassignPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_incremental_unassign');
  late final _rd_kafka_incremental_unassign =
      _rd_kafka_incremental_unassignPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief The rebalance protocol currently in use. This will be
  /// "NONE" if the consumer has not (yet) joined a group, else it will
  /// match the rebalance protocol ("EAGER", "COOPERATIVE") of the
  /// configured and selected assignor(s). All configured
  /// assignors must have the same protocol type, meaning
  /// online migration of a consumer group from using one
  /// protocol to another (in particular upgading from EAGER
  /// to COOPERATIVE) without a restart is not currently
  /// supported.
  ///
  /// @returns NULL on error, or one of "NONE", "EAGER", "COOPERATIVE" on success.
  ffi.Pointer<ffi.Char> rd_kafka_rebalance_protocol(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_rebalance_protocol(
      rk,
    );
  }

  late final _rd_kafka_rebalance_protocolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_rebalance_protocol');
  late final _rd_kafka_rebalance_protocol = _rd_kafka_rebalance_protocolPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Atomic assignment of partitions to consume.
  ///
  /// The new \p partitions will replace the existing assignment.
  ///
  /// A zero-length \p partitions will treat the partitions as a valid,
  /// albeit empty assignment, and maintain internal state, while a \c NULL
  /// value for \p partitions will reset and clear the internal state.
  ///
  /// When used from a rebalance callback, the application should pass the
  /// partition list passed to the callback (or a copy of it) even if the list
  /// is empty (i.e. should not pass NULL in this case) so as to maintain
  /// internal join state. This is not strictly required - the application
  /// may adjust the assignment provided by the group. However, this is rarely
  /// useful in practice.
  ///
  /// @returns An error code indicating if the new assignment was applied or not.
  /// RD_KAFKA_RESP_ERR__FATAL is returned if the consumer has raised
  /// a fatal error.
  int rd_kafka_assign(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_assign(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_assignPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_assign');
  late final _rd_kafka_assign = _rd_kafka_assignPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Returns the current partition assignment as set by rd_kafka_assign()
  /// or rd_kafka_incremental_assign().
  ///
  /// @returns An error code on failure, otherwise \p partitions is updated
  /// to point to a newly allocated partition list (possibly empty).
  ///
  /// @remark The application is responsible for calling
  /// rd_kafka_topic_partition_list_destroy on the returned list.
  ///
  /// @remark This assignment represents the partitions assigned through the
  /// assign functions and not the partitions assigned to this consumer
  /// instance by the consumer group leader.
  /// They are usually the same following a rebalance but not necessarily
  /// since an application is free to assign any partitions.
  int rd_kafka_assignment(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>> partitions,
  ) {
    return _rd_kafka_assignment(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_assignmentPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>>)>>(
      'rd_kafka_assignment');
  late final _rd_kafka_assignment = _rd_kafka_assignmentPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_partition_list_t>>)>();

  /// @brief Check whether the consumer considers the current assignment to
  /// have been lost involuntarily. This method is only applicable for
  /// use with a high level subscribing consumer. Assignments are revoked
  /// immediately when determined to have been lost, so this method
  /// is only useful when reacting to a RD_KAFKA_EVENT_REBALANCE event
  /// or from within a rebalance_cb. Partitions that have been lost may
  /// already be owned by other members in the group and therefore
  /// commiting offsets, for example, may fail.
  ///
  /// @remark Calling rd_kafka_assign(), rd_kafka_incremental_assign() or
  /// rd_kafka_incremental_unassign() resets this flag.
  ///
  /// @returns Returns 1 if the current partition assignment is considered
  /// lost, 0 otherwise.
  int rd_kafka_assignment_lost(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_assignment_lost(
      rk,
    );
  }

  late final _rd_kafka_assignment_lostPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_assignment_lost');
  late final _rd_kafka_assignment_lost = _rd_kafka_assignment_lostPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Commit offsets on broker for the provided list of partitions.
  ///
  /// \p offsets should contain \c topic, \c partition, \c offset and possibly
  /// \c metadata. The \c offset should be the offset where consumption will
  /// resume, i.e., the last processed offset + 1.
  /// If \p offsets is NULL the current partition assignment will be used instead.
  ///
  /// If \p async is false this operation will block until the broker offset commit
  /// is done, returning the resulting success or error code.
  ///
  /// If a rd_kafka_conf_set_offset_commit_cb() offset commit callback has been
  /// configured the callback will be enqueued for a future call to
  /// rd_kafka_poll(), rd_kafka_consumer_poll() or similar.
  ///
  /// @returns An error code indiciating if the commit was successful,
  /// or successfully scheduled if asynchronous, or failed.
  /// RD_KAFKA_RESP_ERR__FATAL is returned if the consumer has raised
  /// a fatal error.
  ///
  /// FIXME: Update below documentation.
  ///
  /// RD_KAFKA_RESP_ERR_STALE_MEMBER_EPOCH is returned, when
  /// using `group.protocol=consumer`, if the commit failed because the
  /// member has switched to a new member epoch.
  /// This error code can be retried.
  /// Partition level error is also set in the \p offsets.
  ///
  /// RD_KAFKA_RESP_ERR_UNKNOWN_MEMBER_ID is returned, when
  /// using `group.protocol=consumer`, if the member has been
  /// removed from the consumer group
  /// This error code is permanent, uncommitted messages will be
  /// reprocessed by this or a different member and committed there.
  /// Partition level error is also set in the \p offsets.
  int rd_kafka_commit(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
    int async1,
  ) {
    return _rd_kafka_commit(
      rk,
      offsets,
      async1,
    );
  }

  late final _rd_kafka_commitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Int)>>('rd_kafka_commit');
  late final _rd_kafka_commit = _rd_kafka_commitPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>, int)>();

  /// @brief Commit message's offset on broker for the message's partition.
  /// The committed offset is the message's offset + 1.
  ///
  /// @sa rd_kafka_commit
  int rd_kafka_commit_message(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_message_t> rkmessage,
    int async1,
  ) {
    return _rd_kafka_commit_message(
      rk,
      rkmessage,
      async1,
    );
  }

  late final _rd_kafka_commit_messagePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_message_t>,
              ffi.Int)>>('rd_kafka_commit_message');
  late final _rd_kafka_commit_message = _rd_kafka_commit_messagePtr.asFunction<
      int Function(
          ffi.Pointer<rd_kafka_t>, ffi.Pointer<rd_kafka_message_t>, int)>();

  /// @brief Commit offsets on broker for the provided list of partitions.
  ///
  /// See rd_kafka_commit for \p offsets semantics.
  ///
  /// The result of the offset commit will be posted on the provided \p rkqu queue.
  ///
  /// If the application uses one of the poll APIs (rd_kafka_poll(),
  /// rd_kafka_consumer_poll(), rd_kafka_queue_poll(), ..) to serve the queue
  /// the \p cb callback is required.
  ///
  /// The \p commit_opaque argument is passed to the callback as \p commit_opaque,
  /// or if using the event API the callback is ignored and the offset commit
  /// result will be returned as an RD_KAFKA_EVENT_COMMIT event and the
  /// \p commit_opaque value will be available with rd_kafka_event_opaque().
  ///
  /// If \p rkqu is NULL a temporary queue will be created and the callback will
  /// be served by this call.
  ///
  /// @sa rd_kafka_commit()
  /// @sa rd_kafka_conf_set_offset_commit_cb()
  int rd_kafka_commit_queue(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(
                    ffi.Pointer<rd_kafka_t> rk,
                    ffi.Int32 err,
                    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
                    ffi.Pointer<ffi.Void> commit_opaque)>>
        cb,
    ffi.Pointer<ffi.Void> commit_opaque,
  ) {
    return _rd_kafka_commit_queue(
      rk,
      offsets,
      rkqu,
      cb,
      commit_opaque,
    );
  }

  late final _rd_kafka_commit_queuePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<rd_kafka_queue_t>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<rd_kafka_t> rk,
                          ffi.Int32 err,
                          ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
                          ffi.Pointer<ffi.Void> commit_opaque)>>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_commit_queue');
  late final _rd_kafka_commit_queue = _rd_kafka_commit_queuePtr.asFunction<
      int Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>,
          ffi.Pointer<rd_kafka_queue_t>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Void Function(
                      ffi.Pointer<rd_kafka_t> rk,
                      ffi.Int32 err,
                      ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
                      ffi.Pointer<ffi.Void> commit_opaque)>>,
          ffi.Pointer<ffi.Void>)>();

  /// @brief Retrieve committed offsets for topics+partitions.
  ///
  /// The \p offset field of each requested partition will either be set to
  /// stored offset or to RD_KAFKA_OFFSET_INVALID in case there was no stored
  /// offset for that partition.
  ///
  /// Committed offsets will be returned according to the `isolation.level`
  /// configuration property, if set to `read_committed` (default) then only
  /// stable offsets for fully committed transactions will be returned, while
  /// `read_uncommitted` may return offsets for not yet committed transactions.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success in which case the
  /// \p offset or \p err field of each \p partitions' element is filled
  /// in with the stored offset, or a partition specific error.
  /// Else returns an error code.
  int rd_kafka_committed(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
    int timeout_ms,
  ) {
    return _rd_kafka_committed(
      rk,
      partitions,
      timeout_ms,
    );
  }

  late final _rd_kafka_committedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Int)>>('rd_kafka_committed');
  late final _rd_kafka_committed = _rd_kafka_committedPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>, int)>();

  /// @brief Retrieve current positions (offsets) for topics+partitions.
  ///
  /// The \p offset field of each requested partition will be set to the offset
  /// of the last consumed message + 1, or RD_KAFKA_OFFSET_INVALID in case there
  /// was no previous message.
  ///
  /// @remark  In this context the last consumed message is the offset consumed
  /// by the current librdkafka instance and, in case of rebalancing, not
  /// necessarily the last message fetched from the partition.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success in which case the
  /// \p offset or \p err field of each \p partitions' element is filled
  /// in with the stored offset, or a partition specific error.
  /// Else returns an error code.
  int rd_kafka_position(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_position(
      rk,
      partitions,
    );
  }

  late final _rd_kafka_positionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_position');
  late final _rd_kafka_position = _rd_kafka_positionPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @returns the current consumer group metadata associated with this consumer,
  /// or NULL if \p rk is not a consumer configured with a \c group.id.
  /// This metadata object should be passed to the transactional
  /// producer's rd_kafka_send_offsets_to_transaction() API.
  ///
  /// @remark The returned pointer must be freed by the application using
  /// rd_kafka_consumer_group_metadata_destroy().
  ///
  /// @sa rd_kafka_send_offsets_to_transaction()
  ffi.Pointer<rd_kafka_consumer_group_metadata_t>
      rd_kafka_consumer_group_metadata(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_consumer_group_metadata(
      rk,
    );
  }

  late final _rd_kafka_consumer_group_metadataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_consumer_group_metadata');
  late final _rd_kafka_consumer_group_metadata =
      _rd_kafka_consumer_group_metadataPtr.asFunction<
          ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
              ffi.Pointer<rd_kafka_t>)>();

  /// @brief Create a new consumer group metadata object.
  /// This is typically only used for writing tests.
  ///
  /// @param group_id The group id.
  ///
  /// @remark The returned pointer must be freed by the application using
  /// rd_kafka_consumer_group_metadata_destroy().
  ffi.Pointer<rd_kafka_consumer_group_metadata_t>
      rd_kafka_consumer_group_metadata_new(
    ffi.Pointer<ffi.Char> group_id,
  ) {
    return _rd_kafka_consumer_group_metadata_new(
      group_id,
    );
  }

  late final _rd_kafka_consumer_group_metadata_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
              ffi.Pointer<ffi.Char>)>>('rd_kafka_consumer_group_metadata_new');
  late final _rd_kafka_consumer_group_metadata_new =
      _rd_kafka_consumer_group_metadata_newPtr.asFunction<
          ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
              ffi.Pointer<ffi.Char>)>();

  /// @brief Create a new consumer group metadata object.
  /// This is typically only used for writing tests.
  ///
  /// @param group_id The group id.
  /// @param generation_id The group generation id.
  /// @param member_id The group member id.
  /// @param group_instance_id The group instance id (may be NULL).
  ///
  /// @remark The returned pointer must be freed by the application using
  /// rd_kafka_consumer_group_metadata_destroy().
  ffi.Pointer<rd_kafka_consumer_group_metadata_t>
      rd_kafka_consumer_group_metadata_new_with_genid(
    ffi.Pointer<ffi.Char> group_id,
    int generation_id,
    ffi.Pointer<ffi.Char> member_id,
    ffi.Pointer<ffi.Char> group_instance_id,
  ) {
    return _rd_kafka_consumer_group_metadata_new_with_genid(
      group_id,
      generation_id,
      member_id,
      group_instance_id,
    );
  }

  late final _rd_kafka_consumer_group_metadata_new_with_genidPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
                  ffi.Pointer<ffi.Char>,
                  ffi.Int32,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<ffi.Char>)>>(
      'rd_kafka_consumer_group_metadata_new_with_genid');
  late final _rd_kafka_consumer_group_metadata_new_with_genid =
      _rd_kafka_consumer_group_metadata_new_with_genidPtr.asFunction<
          ffi.Pointer<rd_kafka_consumer_group_metadata_t> Function(
              ffi.Pointer<ffi.Char>,
              int,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>();

  /// @brief Get member id of a group metadata.
  ///
  /// @param group_metadata The group metadata
  ///
  /// @returns The member id contained in the passed \p group_metadata.
  ///
  /// @remark The returned pointer has the same lifetime as \p group_metadata.
  ffi.Pointer<ffi.Char> rd_kafka_consumer_group_metadata_member_id(
    ffi.Pointer<rd_kafka_consumer_group_metadata_t> group_metadata,
  ) {
    return _rd_kafka_consumer_group_metadata_member_id(
      group_metadata,
    );
  }

  late final _rd_kafka_consumer_group_metadata_member_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_consumer_group_metadata_t>)>>(
      'rd_kafka_consumer_group_metadata_member_id');
  late final _rd_kafka_consumer_group_metadata_member_id =
      _rd_kafka_consumer_group_metadata_member_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_consumer_group_metadata_t>)>();

  /// @brief Frees the consumer group metadata object as returned by
  /// rd_kafka_consumer_group_metadata().
  void rd_kafka_consumer_group_metadata_destroy(
    ffi.Pointer<rd_kafka_consumer_group_metadata_t> arg0,
  ) {
    return _rd_kafka_consumer_group_metadata_destroy(
      arg0,
    );
  }

  late final _rd_kafka_consumer_group_metadata_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_consumer_group_metadata_t>)>>(
      'rd_kafka_consumer_group_metadata_destroy');
  late final _rd_kafka_consumer_group_metadata_destroy =
      _rd_kafka_consumer_group_metadata_destroyPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_consumer_group_metadata_t>)>();

  /// @brief Serialize the consumer group metadata to a binary format.
  /// This is mainly for client binding use and not for application use.
  ///
  /// @remark The serialized metadata format is private and is not compatible
  /// across different versions or even builds of librdkafka.
  /// It should only be used in the same process runtime and must only
  /// be passed to rd_kafka_consumer_group_metadata_read().
  ///
  /// @param cgmd Metadata to be serialized.
  /// @param bufferp On success this pointer will be updated to point to na
  /// allocated buffer containing the serialized metadata.
  /// The buffer must be freed with rd_kafka_mem_free().
  /// @param sizep The pointed to size will be updated with the size of
  /// the serialized buffer.
  ///
  /// @returns NULL on success or an error object on failure.
  ///
  /// @sa rd_kafka_consumer_group_metadata_read()
  ffi.Pointer<rd_kafka_error_t> rd_kafka_consumer_group_metadata_write(
    ffi.Pointer<rd_kafka_consumer_group_metadata_t> cgmd,
    ffi.Pointer<ffi.Pointer<ffi.Void>> bufferp,
    ffi.Pointer<ffi.Size> sizep,
  ) {
    return _rd_kafka_consumer_group_metadata_write(
      cgmd,
      bufferp,
      sizep,
    );
  }

  late final _rd_kafka_consumer_group_metadata_writePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_consumer_group_metadata_t>,
                  ffi.Pointer<ffi.Pointer<ffi.Void>>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_consumer_group_metadata_write');
  late final _rd_kafka_consumer_group_metadata_write =
      _rd_kafka_consumer_group_metadata_writePtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_consumer_group_metadata_t>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Reads serialized consumer group metadata and returns a
  /// consumer group metadata object.
  /// This is mainly for client binding use and not for application use.
  ///
  /// @remark The serialized metadata format is private and is not compatible
  /// across different versions or even builds of librdkafka.
  /// It should only be used in the same process runtime and must only
  /// be passed to rd_kafka_consumer_group_metadata_read().
  ///
  /// @param cgmdp On success this pointer will be updated to point to a new
  /// consumer group metadata object which must be freed with
  /// rd_kafka_consumer_group_metadata_destroy().
  /// @param buffer Pointer to the serialized data.
  /// @param size Size of the serialized data.
  ///
  /// @returns NULL on success or an error object on failure.
  ///
  /// @sa rd_kafka_consumer_group_metadata_write()
  ffi.Pointer<rd_kafka_error_t> rd_kafka_consumer_group_metadata_read(
    ffi.Pointer<ffi.Pointer<rd_kafka_consumer_group_metadata_t>> cgmdp,
    ffi.Pointer<ffi.Void> buffer,
    int size,
  ) {
    return _rd_kafka_consumer_group_metadata_read(
      cgmdp,
      buffer,
      size,
    );
  }

  late final _rd_kafka_consumer_group_metadata_readPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_consumer_group_metadata_t>>,
              ffi.Pointer<ffi.Void>,
              ffi.Size)>>('rd_kafka_consumer_group_metadata_read');
  late final _rd_kafka_consumer_group_metadata_read =
      _rd_kafka_consumer_group_metadata_readPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_consumer_group_metadata_t>>,
              ffi.Pointer<ffi.Void>,
              int)>();

  /// @brief Produce and send a single message to broker.
  ///
  /// \p rkt is the target topic which must have been previously created with
  /// `rd_kafka_topic_new()`.
  ///
  /// `rd_kafka_produce()` is an asynchronous non-blocking API.
  /// See `rd_kafka_conf_set_dr_msg_cb` on how to setup a callback to be called
  /// once the delivery status (success or failure) is known. The delivery report
  /// is triggered by the application calling `rd_kafka_poll()` (at regular
  /// intervals) or `rd_kafka_flush()` (at termination).
  ///
  /// Since producing is asynchronous, you should call `rd_kafka_flush()` before
  /// you destroy the producer. Otherwise, any outstanding messages will be
  /// silently discarded.
  ///
  /// When temporary errors occur, librdkafka automatically retries to produce the
  /// messages. Retries are triggered after retry.backoff.ms and when the
  /// leader broker for the given partition is available. Otherwise, librdkafka
  /// falls back to polling the topic metadata to monitor when a new leader is
  /// elected (see the topic.metadata.refresh.fast.interval.ms and
  /// topic.metadata.refresh.interval.ms configurations) and then performs a
  /// retry. A delivery error will occur if the message could not be produced
  /// within message.timeout.ms.
  ///
  /// See the "Message reliability" chapter in INTRODUCTION.md for more
  /// information.
  ///
  /// \p partition is the target partition, either:
  /// - RD_KAFKA_PARTITION_UA (unassigned) for
  /// automatic partitioning using the topic's partitioner function, or
  /// - a fixed partition (0..N)
  ///
  /// \p msgflags is zero or more of the following flags OR:ed together:
  /// RD_KAFKA_MSG_F_BLOCK - block \p produce*() call if
  /// \p queue.buffering.max.messages or
  /// \p queue.buffering.max.kbytes are exceeded.
  /// Messages are considered in-queue from the point
  /// they are accepted by produce() until their corresponding delivery report
  /// callback/event returns. It is thus a requirement to call rd_kafka_poll() (or
  /// equiv.) from a separate thread when F_BLOCK is used. See WARNING on \c
  /// RD_KAFKA_MSG_F_BLOCK above.
  ///
  /// RD_KAFKA_MSG_F_FREE - rdkafka will free(3) \p payload when it is done
  /// with it.
  /// RD_KAFKA_MSG_F_COPY - the \p payload data will be copied and the
  /// \p payload pointer will not be used by rdkafka
  /// after the call returns.
  /// RD_KAFKA_MSG_F_PARTITION - produce_batch() will honour per-message
  /// partition, either set manually or by the
  /// configured partitioner.
  ///
  /// .._F_FREE and .._F_COPY are mutually exclusive. If neither of these are
  /// set, the caller must ensure that the memory backing \p payload remains
  /// valid and is not modified or reused until the delivery callback is
  /// invoked. Other buffers passed to `rd_kafka_produce()` don't have this
  /// restriction on reuse, i.e. the memory backing the key or the topic name
  /// may be reused as soon as `rd_kafka_produce()` returns.
  ///
  /// If the function returns -1 and RD_KAFKA_MSG_F_FREE was specified, then
  /// the memory associated with the payload is still the caller's
  /// responsibility.
  ///
  /// \p payload is the message payload of size \p len bytes.
  ///
  /// \p key is an optional message key of size \p keylen bytes, if non-NULL it
  /// will be passed to the topic partitioner as well as be sent with the
  /// message to the broker and passed on to the consumer.
  ///
  /// \p msg_opaque is an optional application-provided per-message opaque
  /// pointer that will provided in the message's delivery report callback
  /// (\c dr_msg_cb or \c dr_cb) and the \c rd_kafka_message_t \c _private field.
  ///
  /// @remark on_send() and on_acknowledgement() interceptors may be called
  /// from this function. on_acknowledgement() will only be called if the
  /// message fails partitioning.
  ///
  /// @remark If the producer is transactional (\c transactional.id is configured)
  /// producing is only allowed during an on-going transaction, namely
  /// after rd_kafka_begin_transaction() has been called.
  ///
  /// @returns 0 on success or -1 on error in which case errno is set accordingly:
  /// - ENOBUFS  - maximum number of outstanding messages has been reached:
  /// "queue.buffering.max.messages"
  /// (RD_KAFKA_RESP_ERR__QUEUE_FULL)
  /// - EMSGSIZE - message is larger than configured max size:
  /// "messages.max.bytes".
  /// (RD_KAFKA_RESP_ERR_MSG_SIZE_TOO_LARGE)
  /// - ESRCH    - requested \p partition is unknown in the Kafka cluster.
  /// (RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION)
  /// - ENOENT   - topic is unknown in the Kafka cluster.
  /// (RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC)
  /// - ECANCELED - fatal error has been raised on producer, see
  /// rd_kafka_fatal_error(),
  /// (RD_KAFKA_RESP_ERR__FATAL).
  /// - ENOEXEC  - transactional state forbids producing
  /// (RD_KAFKA_RESP_ERR__STATE)
  ///
  /// @sa Use rd_kafka_errno2err() to convert `errno` to rdkafka error code.
  int rd_kafka_produce(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int msgflags,
    ffi.Pointer<ffi.Void> payload,
    int len,
    ffi.Pointer<ffi.Void> key,
    int keylen,
    ffi.Pointer<ffi.Void> msg_opaque,
  ) {
    return _rd_kafka_produce(
      rkt,
      partition,
      msgflags,
      payload,
      len,
      key,
      keylen,
      msg_opaque,
    );
  }

  late final _rd_kafka_producePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32,
              ffi.Int,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_produce');
  late final _rd_kafka_produce = _rd_kafka_producePtr.asFunction<
      int Function(
          ffi.Pointer<rd_kafka_topic_t>,
          int,
          int,
          ffi.Pointer<ffi.Void>,
          int,
          ffi.Pointer<ffi.Void>,
          int,
          ffi.Pointer<ffi.Void>)>();

  /// @brief Produce and send a single message to broker.
  ///
  /// The message is defined by a va-arg list using \c rd_kafka_vtype_t
  /// tag tuples which must be terminated with a single \c RD_KAFKA_V_END.
  ///
  /// @returns \c RD_KAFKA_RESP_ERR_NO_ERROR on success, else an error code as
  /// described in rd_kafka_produce().
  /// \c RD_KAFKA_RESP_ERR__CONFLICT is returned if _V_HEADER and
  /// _V_HEADERS are mixed.
  ///
  /// @sa rd_kafka_produce, rd_kafka_produceva, RD_KAFKA_V_END
  int rd_kafka_producev(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_producev(
      rk,
    );
  }

  late final _rd_kafka_producevPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_producev');
  late final _rd_kafka_producev =
      _rd_kafka_producevPtr.asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Produce and send a single message to broker.
  ///
  /// The message is defined by an array of \c rd_kafka_vu_t of
  /// count \p cnt.
  ///
  /// @returns an error object on failure or NULL on success.
  /// See rd_kafka_producev() for specific error codes.
  ///
  /// @sa rd_kafka_produce, rd_kafka_producev, RD_KAFKA_V_END
  ffi.Pointer<rd_kafka_error_t> rd_kafka_produceva(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_vu_t> vus,
    int cnt,
  ) {
    return _rd_kafka_produceva(
      rk,
      vus,
      cnt,
    );
  }

  late final _rd_kafka_producevaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_vu_t>, ffi.Size)>>('rd_kafka_produceva');
  late final _rd_kafka_produceva = _rd_kafka_producevaPtr.asFunction<
      ffi.Pointer<rd_kafka_error_t> Function(
          ffi.Pointer<rd_kafka_t>, ffi.Pointer<rd_kafka_vu_t>, int)>();

  /// @brief Produce multiple messages.
  ///
  /// If partition is RD_KAFKA_PARTITION_UA the configured partitioner will
  /// be run for each message (slower), otherwise the messages will be enqueued
  /// to the specified partition directly (faster).
  ///
  /// The messages are provided in the array \p rkmessages of count \p message_cnt
  /// elements.
  /// The \p partition and \p msgflags are used for all provided messages.
  ///
  /// Honoured \p rkmessages[] fields are:
  /// - payload,len    Message payload and length
  /// - key,key_len    Optional message key
  /// - _private       Message opaque pointer (msg_opaque)
  /// - err            Will be set according to success or failure, see
  /// rd_kafka_produce() for possible error codes.
  /// Application only needs to check for errors if
  /// return value != \p message_cnt.
  ///
  /// @remark If \c RD_KAFKA_MSG_F_PARTITION is set in \p msgflags, the
  /// \c .partition field of the \p rkmessages is used instead of
  /// \p partition.
  ///
  /// @returns the number of messages succesfully enqueued for producing.
  ///
  /// @remark This interface does NOT support setting message headers on
  /// the provided \p rkmessages.
  int rd_kafka_produce_batch(
    ffi.Pointer<rd_kafka_topic_t> rkt,
    int partition,
    int msgflags,
    ffi.Pointer<rd_kafka_message_t> rkmessages,
    int message_cnt,
  ) {
    return _rd_kafka_produce_batch(
      rkt,
      partition,
      msgflags,
      rkmessages,
      message_cnt,
    );
  }

  late final _rd_kafka_produce_batchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Int32,
              ffi.Int,
              ffi.Pointer<rd_kafka_message_t>,
              ffi.Int)>>('rd_kafka_produce_batch');
  late final _rd_kafka_produce_batch = _rd_kafka_produce_batchPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_topic_t>, int, int,
          ffi.Pointer<rd_kafka_message_t>, int)>();

  /// @brief Wait until all outstanding produce requests, et.al, are completed.
  /// This should typically be done prior to destroying a producer instance
  /// to make sure all queued and in-flight produce requests are completed
  /// before terminating.
  ///
  /// @remark This function will call rd_kafka_poll() and thus trigger callbacks.
  ///
  /// @remark The \c linger.ms time will be ignored for the duration of the call,
  /// queued messages will be sent to the broker as soon as possible.
  ///
  /// @remark If RD_KAFKA_EVENT_DR has been enabled
  /// (through rd_kafka_conf_set_events()) this function will not call
  /// rd_kafka_poll() but instead wait for the librdkafka-handled
  /// message count to reach zero. This requires the application to
  /// serve the event queue in a separate thread.
  /// In this mode only messages are counted, not other types of
  /// queued events.
  ///
  /// @returns RD_KAFKA_RESP_ERR__TIMED_OUT if \p timeout_ms was reached before all
  /// outstanding requests were completed, else RD_KAFKA_RESP_ERR_NO_ERROR
  ///
  /// @sa rd_kafka_outq_len()
  int rd_kafka_flush(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_flush(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_flushPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_flush');
  late final _rd_kafka_flush = _rd_kafka_flushPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Purge messages currently handled by the producer instance.
  ///
  /// @param rk          Client instance.
  /// @param purge_flags Tells which messages to purge and how.
  ///
  /// The application will need to call rd_kafka_poll() or rd_kafka_flush()
  /// afterwards to serve the delivery report callbacks of the purged messages.
  ///
  /// Messages purged from internal queues fail with the delivery report
  /// error code set to RD_KAFKA_RESP_ERR__PURGE_QUEUE, while purged messages that
  /// are in-flight to or from the broker will fail with the error code set to
  /// RD_KAFKA_RESP_ERR__PURGE_INFLIGHT.
  ///
  /// @warning Purging messages that are in-flight to or from the broker
  /// will ignore any subsequent acknowledgement for these messages
  /// received from the broker, effectively making it impossible
  /// for the application to know if the messages were successfully
  /// produced or not. This may result in duplicate messages if the
  /// application retries these messages at a later time.
  ///
  /// @remark This call may block for a short time while background thread
  /// queues are purged.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if the \p purge flags are invalid
  /// or unknown,
  /// RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED if called on a non-producer
  /// client instance.
  int rd_kafka_purge(
    ffi.Pointer<rd_kafka_t> rk,
    int purge_flags,
  ) {
    return _rd_kafka_purge(
      rk,
      purge_flags,
    );
  }

  late final _rd_kafka_purgePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_purge');
  late final _rd_kafka_purge = _rd_kafka_purgePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Request Metadata from broker.
  ///
  /// Parameters:
  /// - \p all_topics  if non-zero: request info about all topics in cluster,
  /// if zero: only request info about locally known topics.
  /// - \p only_rkt    only request info about this topic
  /// - \p metadatap   pointer to hold metadata result.
  /// The \p *metadatap pointer must be released
  /// with rd_kafka_metadata_destroy().
  /// - \p timeout_ms  maximum response time before failing.
  ///
  /// @remark Consumer: If \p all_topics is non-zero the Metadata response
  /// information may trigger a re-join if any subscribed topics
  /// have changed partition count or existence state.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success (in which case *metadatap)
  /// will be set, else RD_KAFKA_RESP_ERR__TIMED_OUT on timeout or
  /// other error code on error.
  int rd_kafka_metadata1(
    ffi.Pointer<rd_kafka_t> rk,
    int all_topics,
    ffi.Pointer<rd_kafka_topic_t> only_rkt,
    ffi.Pointer<ffi.Pointer<rd_kafka_metadata>> metadatap,
    int timeout_ms,
  ) {
    return _rd_kafka_metadata1(
      rk,
      all_topics,
      only_rkt,
      metadatap,
      timeout_ms,
    );
  }

  late final _rd_kafka_metadata1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Int,
              ffi.Pointer<rd_kafka_topic_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_metadata>>,
              ffi.Int)>>('rd_kafka_metadata');
  late final _rd_kafka_metadata1 = _rd_kafka_metadata1Ptr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>, int, ffi.Pointer<rd_kafka_topic_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_metadata>>, int)>();

  /// @brief Release metadata memory.
  void rd_kafka_metadata_destroy(
    ffi.Pointer<rd_kafka_metadata> metadata,
  ) {
    return _rd_kafka_metadata_destroy(
      metadata,
    );
  }

  late final _rd_kafka_metadata_destroyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_metadata>)>>(
      'rd_kafka_metadata_destroy');
  late final _rd_kafka_metadata_destroy = _rd_kafka_metadata_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_metadata>)>();

  /// @brief Get the id of \p node.
  ///
  /// @param node The Node instance.
  ///
  /// @return The node id.
  int rd_kafka_Node_id(
    ffi.Pointer<rd_kafka_Node_t> node,
  ) {
    return _rd_kafka_Node_id(
      node,
    );
  }

  late final _rd_kafka_Node_idPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_Node_t>)>>(
      'rd_kafka_Node_id');
  late final _rd_kafka_Node_id = _rd_kafka_Node_idPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_Node_t>)>();

  /// @brief Get the host of \p node.
  ///
  /// @param node The Node instance.
  ///
  /// @return The node host.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p node object.
  ffi.Pointer<ffi.Char> rd_kafka_Node_host(
    ffi.Pointer<rd_kafka_Node_t> node,
  ) {
    return _rd_kafka_Node_host(
      node,
    );
  }

  late final _rd_kafka_Node_hostPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_Node_t>)>>('rd_kafka_Node_host');
  late final _rd_kafka_Node_host = _rd_kafka_Node_hostPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_Node_t>)>();

  /// @brief Get the port of \p node.
  ///
  /// @param node The Node instance.
  ///
  /// @return The node port.
  int rd_kafka_Node_port(
    ffi.Pointer<rd_kafka_Node_t> node,
  ) {
    return _rd_kafka_Node_port(
      node,
    );
  }

  late final _rd_kafka_Node_portPtr = _lookup<
          ffi
          .NativeFunction<ffi.Uint16 Function(ffi.Pointer<rd_kafka_Node_t>)>>(
      'rd_kafka_Node_port');
  late final _rd_kafka_Node_port = _rd_kafka_Node_portPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_Node_t>)>();

  /// @brief Get the rack of \p node.
  ///
  /// @param node The Node instance
  ///
  /// @return The node rack id. May be NULL.
  ffi.Pointer<ffi.Char> rd_kafka_Node_rack(
    ffi.Pointer<rd_kafka_Node_t> node,
  ) {
    return _rd_kafka_Node_rack(
      node,
    );
  }

  late final _rd_kafka_Node_rackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_Node_t>)>>('rd_kafka_Node_rack');
  late final _rd_kafka_Node_rack = _rd_kafka_Node_rackPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_Node_t>)>();

  /// @brief List and describe client groups in cluster.
  ///
  /// \p group is an optional group name to describe, otherwise (\c NULL) all
  /// groups are returned.
  ///
  /// \p timeout_ms is the (approximate) maximum time to wait for response
  /// from brokers and must be a positive value.
  ///
  /// @returns \c RD_KAFKA_RESP_ERR__NO_ERROR on success and \p grplistp is
  /// updated to point to a newly allocated list of groups.
  /// \c RD_KAFKA_RESP_ERR__PARTIAL if not all brokers responded
  /// in time but at least one group is returned in  \p grplistlp.
  /// \c RD_KAFKA_RESP_ERR__TIMED_OUT if no groups were returned in the
  /// given timeframe but not all brokers have yet responded, or
  /// if the list of brokers in the cluster could not be obtained within
  /// the given timeframe.
  /// \c RD_KAFKA_RESP_ERR__TRANSPORT if no brokers were found.
  /// Other error codes may also be returned from the request layer.
  ///
  /// The \p grplistp remains untouched if any error code is returned,
  /// with the exception of RD_KAFKA_RESP_ERR__PARTIAL which behaves
  /// as RD_KAFKA_RESP_ERR__NO_ERROR (success) but with an incomplete
  /// group list.
  ///
  /// @sa Use rd_kafka_group_list_destroy() to release list memory.
  ///
  /// @deprecated Use rd_kafka_ListConsumerGroups() and
  /// rd_kafka_DescribeConsumerGroups() instead.
  int rd_kafka_list_groups(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> group,
    ffi.Pointer<ffi.Pointer<rd_kafka_group_list>> grplistp,
    int timeout_ms,
  ) {
    return _rd_kafka_list_groups(
      rk,
      group,
      grplistp,
      timeout_ms,
    );
  }

  late final _rd_kafka_list_groupsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<rd_kafka_group_list>>,
              ffi.Int)>>('rd_kafka_list_groups');
  late final _rd_kafka_list_groups = _rd_kafka_list_groupsPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<rd_kafka_group_list>>, int)>();

  /// @brief Returns a name for a state code.
  ///
  /// @param state The state value.
  ///
  /// @return The group state name corresponding to the provided group state value.
  ffi.Pointer<ffi.Char> rd_kafka_consumer_group_state_name(
    int state,
  ) {
    return _rd_kafka_consumer_group_state_name(
      state,
    );
  }

  late final _rd_kafka_consumer_group_state_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_consumer_group_state_name');
  late final _rd_kafka_consumer_group_state_name =
      _rd_kafka_consumer_group_state_namePtr
          .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @brief Returns a code for a state name.
  ///
  /// @param name The state name.
  ///
  /// @return The group state value corresponding to the provided group state name.
  int rd_kafka_consumer_group_state_code(
    ffi.Pointer<ffi.Char> name,
  ) {
    return _rd_kafka_consumer_group_state_code(
      name,
    );
  }

  late final _rd_kafka_consumer_group_state_codePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Char>)>>(
          'rd_kafka_consumer_group_state_code');
  late final _rd_kafka_consumer_group_state_code =
      _rd_kafka_consumer_group_state_codePtr
          .asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  /// @brief Release list memory
  void rd_kafka_group_list_destroy(
    ffi.Pointer<rd_kafka_group_list> grplist,
  ) {
    return _rd_kafka_group_list_destroy(
      grplist,
    );
  }

  late final _rd_kafka_group_list_destroyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_group_list>)>>(
      'rd_kafka_group_list_destroy');
  late final _rd_kafka_group_list_destroy = _rd_kafka_group_list_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_group_list>)>();

  /// @brief Adds one or more brokers to the kafka handle's list of initial
  /// bootstrap brokers.
  ///
  /// Additional brokers will be discovered automatically as soon as rdkafka
  /// connects to a broker by querying the broker metadata.
  ///
  /// If a broker name resolves to multiple addresses (and possibly
  /// address families) all will be used for connection attempts in
  /// round-robin fashion.
  ///
  /// \p brokerlist is a ,-separated list of brokers in the format:
  /// \c \<broker1\>,\<broker2\>,..
  /// Where each broker is in either the host or URL based format:
  /// \c \<host\>[:\<port\>]
  /// \c \<proto\>://\<host\>[:port]
  /// \c \<proto\> is either \c PLAINTEXT, \c SSL, \c SASL, \c SASL_PLAINTEXT
  /// The two formats can be mixed but ultimately the value of the
  /// `security.protocol` config property decides what brokers are allowed.
  ///
  /// Example:
  /// brokerlist = "broker1:10000,broker2"
  /// brokerlist = "SSL://broker3:9000,ssl://broker2"
  ///
  /// @returns the number of brokers successfully added.
  ///
  /// @remark Brokers may also be defined with the \c metadata.broker.list or
  /// \c bootstrap.servers configuration property (preferred method).
  ///
  /// @deprecated Set bootstrap servers with the \c bootstrap.servers
  /// configuration property.
  int rd_kafka_brokers_add(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> brokerlist,
  ) {
    return _rd_kafka_brokers_add(
      rk,
      brokerlist,
    );
  }

  late final _rd_kafka_brokers_addPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_brokers_add');
  late final _rd_kafka_brokers_add = _rd_kafka_brokers_addPtr.asFunction<
      int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>)>();

  /// @brief Set logger function.
  ///
  /// The default is to print to stderr, but a syslog logger is also available,
  /// see rd_kafka_log_(print|syslog) for the builtin alternatives.
  /// Alternatively the application may provide its own logger callback.
  /// Or pass 'func' as NULL to disable logging.
  ///
  /// @deprecated Use rd_kafka_conf_set_log_cb()
  ///
  /// @remark \p rk may be passed as NULL in the callback.
  void rd_kafka_set_logger(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Void Function(ffi.Pointer<rd_kafka_t> rk, ffi.Int level,
                    ffi.Pointer<ffi.Char> fac, ffi.Pointer<ffi.Char> buf)>>
        func,
  ) {
    return _rd_kafka_set_logger(
      rk,
      func,
    );
  }

  late final _rd_kafka_set_loggerPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<
                      ffi.NativeFunction<
                          ffi.Void Function(
                              ffi.Pointer<rd_kafka_t> rk,
                              ffi.Int level,
                              ffi.Pointer<ffi.Char> fac,
                              ffi.Pointer<ffi.Char> buf)>>)>>(
      'rd_kafka_set_logger');
  late final _rd_kafka_set_logger = _rd_kafka_set_loggerPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Void Function(
                      ffi.Pointer<rd_kafka_t> rk,
                      ffi.Int level,
                      ffi.Pointer<ffi.Char> fac,
                      ffi.Pointer<ffi.Char> buf)>>)>();

  /// @brief Specifies the maximum logging level emitted by
  /// internal kafka logging and debugging.
  ///
  /// @deprecated Set the \c "log_level" configuration property instead.
  ///
  /// @remark If the \p \"debug\" configuration property is set the log level is
  /// automatically adjusted to \c LOG_DEBUG (7).
  void rd_kafka_set_log_level(
    ffi.Pointer<rd_kafka_t> rk,
    int level,
  ) {
    return _rd_kafka_set_log_level(
      rk,
      level,
    );
  }

  late final _rd_kafka_set_log_levelPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_t>, ffi.Int)>>(
      'rd_kafka_set_log_level');
  late final _rd_kafka_set_log_level = _rd_kafka_set_log_levelPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Builtin (default) log sink: print to stderr
  void rd_kafka_log_print(
    ffi.Pointer<rd_kafka_t> rk,
    int level,
    ffi.Pointer<ffi.Char> fac,
    ffi.Pointer<ffi.Char> buf,
  ) {
    return _rd_kafka_log_print(
      rk,
      level,
      fac,
      buf,
    );
  }

  late final _rd_kafka_log_printPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_log_print');
  late final _rd_kafka_log_print = _rd_kafka_log_printPtr.asFunction<
      void Function(ffi.Pointer<rd_kafka_t>, int, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>)>();

  /// @brief Builtin log sink: print to syslog.
  /// @remark This logger is only available if librdkafka was built
  /// with syslog support.
  void rd_kafka_log_syslog(
    ffi.Pointer<rd_kafka_t> rk,
    int level,
    ffi.Pointer<ffi.Char> fac,
    ffi.Pointer<ffi.Char> buf,
  ) {
    return _rd_kafka_log_syslog(
      rk,
      level,
      fac,
      buf,
    );
  }

  late final _rd_kafka_log_syslogPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_log_syslog');
  late final _rd_kafka_log_syslog = _rd_kafka_log_syslogPtr.asFunction<
      void Function(ffi.Pointer<rd_kafka_t>, int, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>)>();

  /// @brief Returns the current out queue length.
  ///
  /// The out queue length is the sum of:
  /// - number of messages waiting to be sent to, or acknowledged by,
  /// the broker.
  /// - number of delivery reports (e.g., dr_msg_cb) waiting to be served
  /// by rd_kafka_poll() or rd_kafka_flush().
  /// - number of callbacks (e.g., error_cb, stats_cb, etc) waiting to be
  /// served by rd_kafka_poll(), rd_kafka_consumer_poll() or rd_kafka_flush().
  /// - number of events waiting to be served by background_event_cb() in
  /// the background queue (see rd_kafka_conf_set_background_event_cb).
  ///
  /// An application should wait for the return value of this function to reach
  /// zero before terminating to make sure outstanding messages,
  /// requests (such as offset commits), callbacks and events are fully processed.
  /// See rd_kafka_flush().
  ///
  /// @returns number of messages and events waiting in queues.
  ///
  /// @sa rd_kafka_flush()
  int rd_kafka_outq_len(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_outq_len(
      rk,
    );
  }

  late final _rd_kafka_outq_lenPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_outq_len');
  late final _rd_kafka_outq_len =
      _rd_kafka_outq_lenPtr.asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Dumps rdkafka's internal state for handle \p rk to stream \p fp
  ///
  /// This is only useful for debugging rdkafka, showing state and statistics
  /// for brokers, topics, partitions, etc.
  void rd_kafka_dump(
    ffi.Pointer<FILE> fp,
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_dump(
      fp,
      rk,
    );
  }

  late final _rd_kafka_dumpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<FILE>, ffi.Pointer<rd_kafka_t>)>>('rd_kafka_dump');
  late final _rd_kafka_dump = _rd_kafka_dumpPtr
      .asFunction<void Function(ffi.Pointer<FILE>, ffi.Pointer<rd_kafka_t>)>();

  /// @brief Retrieve the current number of threads in use by librdkafka.
  ///
  /// Used by regression tests.
  int rd_kafka_thread_cnt() {
    return _rd_kafka_thread_cnt();
  }

  late final _rd_kafka_thread_cntPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('rd_kafka_thread_cnt');
  late final _rd_kafka_thread_cnt =
      _rd_kafka_thread_cntPtr.asFunction<int Function()>();

  /// @brief Wait for all rd_kafka_t objects to be destroyed.
  ///
  /// Returns 0 if all kafka objects are now destroyed, or -1 if the
  /// timeout was reached.
  ///
  /// @remark This function is deprecated.
  int rd_kafka_wait_destroyed(
    int timeout_ms,
  ) {
    return _rd_kafka_wait_destroyed(
      timeout_ms,
    );
  }

  late final _rd_kafka_wait_destroyedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'rd_kafka_wait_destroyed');
  late final _rd_kafka_wait_destroyed =
      _rd_kafka_wait_destroyedPtr.asFunction<int Function(int)>();

  /// @brief Run librdkafka's built-in unit-tests.
  ///
  /// @returns the number of failures, or 0 if all tests passed.
  int rd_kafka_unittest() {
    return _rd_kafka_unittest();
  }

  late final _rd_kafka_unittestPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('rd_kafka_unittest');
  late final _rd_kafka_unittest =
      _rd_kafka_unittestPtr.asFunction<int Function()>();

  /// @brief Redirect the main (rd_kafka_poll()) queue to the KafkaConsumer's
  /// queue (rd_kafka_consumer_poll()).
  ///
  /// @warning It is not permitted to call rd_kafka_poll() after directing the
  /// main queue with rd_kafka_poll_set_consumer().
  int rd_kafka_poll_set_consumer(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_poll_set_consumer(
      rk,
    );
  }

  late final _rd_kafka_poll_set_consumerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_t>)>>(
          'rd_kafka_poll_set_consumer');
  late final _rd_kafka_poll_set_consumer = _rd_kafka_poll_set_consumerPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_t>)>();

  /// @returns the event type for the given event.
  ///
  /// @remark As a convenience it is okay to pass \p rkev as NULL in which case
  /// RD_KAFKA_EVENT_NONE is returned.
  int rd_kafka_event_type(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_type(
      rkev,
    );
  }

  late final _rd_kafka_event_typePtr = _lookup<
      ffi.NativeFunction<
          rd_kafka_event_type_t Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_type');
  late final _rd_kafka_event_type = _rd_kafka_event_typePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the event type's name for the given event.
  ///
  /// @remark As a convenience it is okay to pass \p rkev as NULL in which case
  /// the name for RD_KAFKA_EVENT_NONE is returned.
  ffi.Pointer<ffi.Char> rd_kafka_event_name(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_name(
      rkev,
    );
  }

  late final _rd_kafka_event_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_name');
  late final _rd_kafka_event_name = _rd_kafka_event_namePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Destroy an event.
  ///
  /// @remark Any references to this event, such as extracted messages,
  /// will not be usable after this call.
  ///
  /// @remark As a convenience it is okay to pass \p rkev as NULL in which case
  /// no action is performed.
  void rd_kafka_event_destroy(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_destroy(
      rkev,
    );
  }

  late final _rd_kafka_event_destroyPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_destroy');
  late final _rd_kafka_event_destroy = _rd_kafka_event_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the next message from an event.
  ///
  /// Call repeatedly until it returns NULL.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_FETCH  (1 message)
  /// - RD_KAFKA_EVENT_DR     (>=1 message(s))
  ///
  /// @remark The returned message(s) MUST NOT be
  /// freed with rd_kafka_message_destroy().
  ///
  /// @remark on_consume() interceptor may be called
  /// from this function prior to passing message to application.
  ffi.Pointer<rd_kafka_message_t> rd_kafka_event_message_next(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_message_next(
      rkev,
    );
  }

  late final _rd_kafka_event_message_nextPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_message_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_message_next');
  late final _rd_kafka_event_message_next =
      _rd_kafka_event_message_nextPtr.asFunction<
          ffi.Pointer<rd_kafka_message_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Extacts \p size message(s) from the event into the
  /// pre-allocated array \p rkmessages.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_FETCH  (1 message)
  /// - RD_KAFKA_EVENT_DR     (>=1 message(s))
  ///
  /// @returns the number of messages extracted.
  ///
  /// @remark on_consume() interceptor may be called
  /// from this function prior to passing message to application.
  int rd_kafka_event_message_array(
    ffi.Pointer<rd_kafka_event_t> rkev,
    ffi.Pointer<ffi.Pointer<rd_kafka_message_t>> rkmessages,
    int size,
  ) {
    return _rd_kafka_event_message_array(
      rkev,
      rkmessages,
      size,
    );
  }

  late final _rd_kafka_event_message_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<rd_kafka_event_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>,
              ffi.Size)>>('rd_kafka_event_message_array');
  late final _rd_kafka_event_message_array =
      _rd_kafka_event_message_arrayPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_event_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_message_t>>, int)>();

  /// @returns the number of remaining messages in the event.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_FETCH  (1 message)
  /// - RD_KAFKA_EVENT_DR     (>=1 message(s))
  int rd_kafka_event_message_count(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_message_count(
      rkev,
    );
  }

  late final _rd_kafka_event_message_countPtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_message_count');
  late final _rd_kafka_event_message_count = _rd_kafka_event_message_countPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the associated configuration string for the event, or NULL
  /// if the configuration property is not set or if
  /// not applicable for the given event type.
  ///
  /// The returned memory is read-only and its lifetime is the same as the
  /// event object.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_OAUTHBEARER_TOKEN_REFRESH: value of sasl.oauthbearer.config
  ffi.Pointer<ffi.Char> rd_kafka_event_config_string(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_config_string(
      rkev,
    );
  }

  late final _rd_kafka_event_config_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_config_string');
  late final _rd_kafka_event_config_string =
      _rd_kafka_event_config_stringPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the error code for the event.
  ///
  /// Use rd_kafka_event_error_is_fatal() to detect if this is a fatal error.
  ///
  /// Event types:
  /// - all
  int rd_kafka_event_error(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_error(
      rkev,
    );
  }

  late final _rd_kafka_event_errorPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int32 Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_error');
  late final _rd_kafka_event_error = _rd_kafka_event_errorPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the error string (if any).
  /// An application should check that rd_kafka_event_error() returns
  /// non-zero before calling this function.
  ///
  /// Event types:
  /// - all
  ffi.Pointer<ffi.Char> rd_kafka_event_error_string(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_error_string(
      rkev,
    );
  }

  late final _rd_kafka_event_error_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_error_string');
  late final _rd_kafka_event_error_string =
      _rd_kafka_event_error_stringPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns 1 if the error is a fatal error, else 0.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_ERROR
  ///
  /// @sa rd_kafka_fatal_error()
  int rd_kafka_event_error_is_fatal(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_error_is_fatal(
      rkev,
    );
  }

  late final _rd_kafka_event_error_is_fatalPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_error_is_fatal');
  late final _rd_kafka_event_error_is_fatal = _rd_kafka_event_error_is_fatalPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the event opaque (if any) as passed to rd_kafka_commit() (et.al) or
  /// rd_kafka_AdminOptions_set_opaque(), depending on event type.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_OFFSET_COMMIT
  /// - RD_KAFKA_EVENT_CREATETOPICS_RESULT
  /// - RD_KAFKA_EVENT_DELETETOPICS_RESULT
  /// - RD_KAFKA_EVENT_CREATEPARTITIONS_RESULT
  /// - RD_KAFKA_EVENT_CREATEACLS_RESULT
  /// - RD_KAFKA_EVENT_DESCRIBEACLS_RESULT
  /// - RD_KAFKA_EVENT_DELETEACLS_RESULT
  /// - RD_KAFKA_EVENT_ALTERCONFIGS_RESULT
  /// - RD_KAFKA_EVENT_INCREMENTAL_ALTERCONFIGS_RESULT
  /// - RD_KAFKA_EVENT_DESCRIBECONFIGS_RESULT
  /// - RD_KAFKA_EVENT_DELETEGROUPS_RESULT
  /// - RD_KAFKA_EVENT_DELETECONSUMERGROUPOFFSETS_RESULT
  /// - RD_KAFKA_EVENT_DELETERECORDS_RESULT
  /// - RD_KAFKA_EVENT_LISTCONSUMERGROUPS_RESULT
  /// - RD_KAFKA_EVENT_DESCRIBECONSUMERGROUPS_RESULT
  /// - RD_KAFKA_EVENT_LISTCONSUMERGROUPOFFSETS_RESULT
  /// - RD_KAFKA_EVENT_ALTERCONSUMERGROUPOFFSETS_RESULT
  /// - RD_KAFKA_EVENT_DESCRIBETOPICS_RESULT
  /// - RD_KAFKA_EVENT_DESCRIBECLUSTER_RESULT
  /// - RD_KAFKA_EVENT_LISTOFFSETS_RESULT
  ffi.Pointer<ffi.Void> rd_kafka_event_opaque(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_opaque(
      rkev,
    );
  }

  late final _rd_kafka_event_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_opaque');
  late final _rd_kafka_event_opaque = _rd_kafka_event_opaquePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Extract log message from the event.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_LOG
  ///
  /// @returns 0 on success or -1 if unsupported event type.
  int rd_kafka_event_log(
    ffi.Pointer<rd_kafka_event_t> rkev,
    ffi.Pointer<ffi.Pointer<ffi.Char>> fac,
    ffi.Pointer<ffi.Pointer<ffi.Char>> str,
    ffi.Pointer<ffi.Int> level,
  ) {
    return _rd_kafka_event_log(
      rkev,
      fac,
      str,
      level,
    );
  }

  late final _rd_kafka_event_logPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<rd_kafka_event_t>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Int>)>>('rd_kafka_event_log');
  late final _rd_kafka_event_log = _rd_kafka_event_logPtr.asFunction<
      int Function(
          ffi.Pointer<rd_kafka_event_t>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Int>)>();

  /// @brief Extract log debug context from event.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_LOG
  ///
  /// @param rkev the event to extract data from.
  /// @param dst destination string for comma separated list.
  /// @param dstsize size of provided dst buffer.
  /// @returns 0 on success or -1 if unsupported event type.
  int rd_kafka_event_debug_contexts(
    ffi.Pointer<rd_kafka_event_t> rkev,
    ffi.Pointer<ffi.Char> dst,
    int dstsize,
  ) {
    return _rd_kafka_event_debug_contexts(
      rkev,
      dst,
      dstsize,
    );
  }

  late final _rd_kafka_event_debug_contextsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_event_t>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_event_debug_contexts');
  late final _rd_kafka_event_debug_contexts =
      _rd_kafka_event_debug_contextsPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_event_t>, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Extract stats from the event.
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_STATS
  ///
  /// @returns stats json string.
  ///
  /// @remark the returned string will be freed automatically along with the event
  /// object
  ffi.Pointer<ffi.Char> rd_kafka_event_stats(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_stats(
      rkev,
    );
  }

  late final _rd_kafka_event_statsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_event_t>)>>('rd_kafka_event_stats');
  late final _rd_kafka_event_stats = _rd_kafka_event_statsPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the topic partition list from the event.
  ///
  /// @remark The list MUST NOT be freed with
  /// rd_kafka_topic_partition_list_destroy()
  ///
  /// Event types:
  /// - RD_KAFKA_EVENT_REBALANCE
  /// - RD_KAFKA_EVENT_OFFSET_COMMIT
  ffi.Pointer<rd_kafka_topic_partition_list_t>
      rd_kafka_event_topic_partition_list(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_topic_partition_list(
      rkev,
    );
  }

  late final _rd_kafka_event_topic_partition_listPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_topic_partition_list');
  late final _rd_kafka_event_topic_partition_list =
      _rd_kafka_event_topic_partition_listPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns a newly allocated topic_partition container, if applicable for the
  /// event type, else NULL.
  ///
  /// @remark The returned pointer MUST be freed with
  /// rd_kafka_topic_partition_destroy().
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_ERROR  (for partition level errors)
  ffi.Pointer<rd_kafka_topic_partition_t> rd_kafka_event_topic_partition(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_topic_partition(
      rkev,
    );
  }

  late final _rd_kafka_event_topic_partitionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_topic_partition');
  late final _rd_kafka_event_topic_partition =
      _rd_kafka_event_topic_partitionPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get CreateTopics result.
  ///
  /// @returns the result of a CreateTopics request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_CREATETOPICS_RESULT
  ffi.Pointer<rd_kafka_CreateTopics_result_t>
      rd_kafka_event_CreateTopics_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_CreateTopics_result(
      rkev,
    );
  }

  late final _rd_kafka_event_CreateTopics_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_CreateTopics_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_CreateTopics_result');
  late final _rd_kafka_event_CreateTopics_result =
      _rd_kafka_event_CreateTopics_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_CreateTopics_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DeleteTopics result.
  ///
  /// @returns the result of a DeleteTopics request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DELETETOPICS_RESULT
  ffi.Pointer<rd_kafka_DeleteTopics_result_t>
      rd_kafka_event_DeleteTopics_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DeleteTopics_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DeleteTopics_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteTopics_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DeleteTopics_result');
  late final _rd_kafka_event_DeleteTopics_result =
      _rd_kafka_event_DeleteTopics_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteTopics_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get CreatePartitions result.
  ///
  /// @returns the result of a CreatePartitions request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_CREATEPARTITIONS_RESULT
  ffi.Pointer<rd_kafka_CreatePartitions_result_t>
      rd_kafka_event_CreatePartitions_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_CreatePartitions_result(
      rkev,
    );
  }

  late final _rd_kafka_event_CreatePartitions_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_CreatePartitions_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_CreatePartitions_result');
  late final _rd_kafka_event_CreatePartitions_result =
      _rd_kafka_event_CreatePartitions_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_CreatePartitions_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get AlterConfigs result.
  ///
  /// @returns the result of a AlterConfigs request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_ALTERCONFIGS_RESULT
  ffi.Pointer<rd_kafka_AlterConfigs_result_t>
      rd_kafka_event_AlterConfigs_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_AlterConfigs_result(
      rkev,
    );
  }

  late final _rd_kafka_event_AlterConfigs_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_AlterConfigs_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_AlterConfigs_result');
  late final _rd_kafka_event_AlterConfigs_result =
      _rd_kafka_event_AlterConfigs_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_AlterConfigs_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get IncrementalAlterConfigs result.
  ///
  /// @returns the result of a IncrementalAlterConfigs request, or NULL if event is
  /// of different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_INCREMENTALALTERCONFIGS_RESULT
  ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t>
      rd_kafka_event_IncrementalAlterConfigs_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_IncrementalAlterConfigs_result(
      rkev,
    );
  }

  late final _rd_kafka_event_IncrementalAlterConfigs_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_IncrementalAlterConfigs_result');
  late final _rd_kafka_event_IncrementalAlterConfigs_result =
      _rd_kafka_event_IncrementalAlterConfigs_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DescribeConfigs result.
  ///
  /// @returns the result of a DescribeConfigs request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBECONFIGS_RESULT
  ffi.Pointer<rd_kafka_DescribeConfigs_result_t>
      rd_kafka_event_DescribeConfigs_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeConfigs_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeConfigs_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeConfigs_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeConfigs_result');
  late final _rd_kafka_event_DescribeConfigs_result =
      _rd_kafka_event_DescribeConfigs_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeConfigs_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the result of a DeleteRecords request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DELETERECORDS_RESULT
  ffi.Pointer<rd_kafka_DeleteRecords_result_t>
      rd_kafka_event_DeleteRecords_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DeleteRecords_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DeleteRecords_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteRecords_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DeleteRecords_result');
  late final _rd_kafka_event_DeleteRecords_result =
      _rd_kafka_event_DeleteRecords_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteRecords_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get ListConsumerGroups result.
  ///
  /// @returns the result of a ListConsumerGroups request, or NULL if event is of
  /// different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_LISTCONSUMERGROUPS_RESULT
  ffi.Pointer<rd_kafka_ListConsumerGroups_result_t>
      rd_kafka_event_ListConsumerGroups_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_ListConsumerGroups_result(
      rkev,
    );
  }

  late final _rd_kafka_event_ListConsumerGroups_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_ListConsumerGroups_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_ListConsumerGroups_result');
  late final _rd_kafka_event_ListConsumerGroups_result =
      _rd_kafka_event_ListConsumerGroups_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_ListConsumerGroups_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DescribeConsumerGroups result.
  ///
  /// @returns the result of a DescribeConsumerGroups request, or NULL if event is
  /// of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBECONSUMERGROUPS_RESULT
  ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t>
      rd_kafka_event_DescribeConsumerGroups_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeConsumerGroups_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeConsumerGroups_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeConsumerGroups_result');
  late final _rd_kafka_event_DescribeConsumerGroups_result =
      _rd_kafka_event_DescribeConsumerGroups_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DescribeTopics result.
  ///
  /// @returns the result of a DescribeTopics request, or NULL if event is
  /// of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBETOPICS_RESULT
  ffi.Pointer<rd_kafka_DescribeTopics_result_t>
      rd_kafka_event_DescribeTopics_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeTopics_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeTopics_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeTopics_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeTopics_result');
  late final _rd_kafka_event_DescribeTopics_result =
      _rd_kafka_event_DescribeTopics_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeTopics_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DescribeCluster result.
  ///
  /// @returns the result of a DescribeCluster request, or NULL if event is
  /// of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBECLUSTER_RESULT
  ffi.Pointer<rd_kafka_DescribeCluster_result_t>
      rd_kafka_event_DescribeCluster_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeCluster_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeCluster_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeCluster_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeCluster_result');
  late final _rd_kafka_event_DescribeCluster_result =
      _rd_kafka_event_DescribeCluster_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeCluster_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DeleteGroups result.
  ///
  /// @returns the result of a DeleteGroups request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DELETEGROUPS_RESULT
  ffi.Pointer<rd_kafka_DeleteGroups_result_t>
      rd_kafka_event_DeleteGroups_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DeleteGroups_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DeleteGroups_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteGroups_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DeleteGroups_result');
  late final _rd_kafka_event_DeleteGroups_result =
      _rd_kafka_event_DeleteGroups_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteGroups_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DeleteConsumerGroupOffsets result.
  ///
  /// @returns the result of a DeleteConsumerGroupOffsets request, or NULL if
  /// event is of different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DELETECONSUMERGROUPOFFSETS_RESULT
  ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t>
      rd_kafka_event_DeleteConsumerGroupOffsets_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DeleteConsumerGroupOffsets_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DeleteConsumerGroupOffsets_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t>
                  Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DeleteConsumerGroupOffsets_result');
  late final _rd_kafka_event_DeleteConsumerGroupOffsets_result =
      _rd_kafka_event_DeleteConsumerGroupOffsets_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the result of a CreateAcls request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_CREATEACLS_RESULT
  ffi.Pointer<rd_kafka_CreateAcls_result_t> rd_kafka_event_CreateAcls_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_CreateAcls_result(
      rkev,
    );
  }

  late final _rd_kafka_event_CreateAcls_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_CreateAcls_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_CreateAcls_result');
  late final _rd_kafka_event_CreateAcls_result =
      _rd_kafka_event_CreateAcls_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_CreateAcls_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the result of a DescribeAcls request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBEACLS_RESULT
  ffi.Pointer<rd_kafka_DescribeAcls_result_t>
      rd_kafka_event_DescribeAcls_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeAcls_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeAcls_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeAcls_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeAcls_result');
  late final _rd_kafka_event_DescribeAcls_result =
      _rd_kafka_event_DescribeAcls_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeAcls_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @returns the result of a DeleteAcls request, or NULL if event is of
  /// different type.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DELETEACLS_RESULT
  ffi.Pointer<rd_kafka_DeleteAcls_result_t> rd_kafka_event_DeleteAcls_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DeleteAcls_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DeleteAcls_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteAcls_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DeleteAcls_result');
  late final _rd_kafka_event_DeleteAcls_result =
      _rd_kafka_event_DeleteAcls_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteAcls_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get ListConsumerGroupOffsets result.
  ///
  /// @returns the result of a ListConsumerGroupOffsets request, or NULL if
  /// event is of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_LISTCONSUMERGROUPOFFSETS_RESULT
  ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t>
      rd_kafka_event_ListConsumerGroupOffsets_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_ListConsumerGroupOffsets_result(
      rkev,
    );
  }

  late final _rd_kafka_event_ListConsumerGroupOffsets_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_ListConsumerGroupOffsets_result');
  late final _rd_kafka_event_ListConsumerGroupOffsets_result =
      _rd_kafka_event_ListConsumerGroupOffsets_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get AlterConsumerGroupOffsets result.
  ///
  /// @returns the result of a AlterConsumerGroupOffsets request, or NULL if
  /// event is of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_ALTERCONSUMERGROUPOFFSETS_RESULT
  ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t>
      rd_kafka_event_AlterConsumerGroupOffsets_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_AlterConsumerGroupOffsets_result(
      rkev,
    );
  }

  late final _rd_kafka_event_AlterConsumerGroupOffsets_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_AlterConsumerGroupOffsets_result');
  late final _rd_kafka_event_AlterConsumerGroupOffsets_result =
      _rd_kafka_event_AlterConsumerGroupOffsets_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get ListOffsets result.
  ///
  /// @returns the result of a ListOffsets request, or NULL if
  /// event is of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_LISTOFFSETS_RESULT
  ffi.Pointer<rd_kafka_ListOffsets_result_t> rd_kafka_event_ListOffsets_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_ListOffsets_result(
      rkev,
    );
  }

  late final _rd_kafka_event_ListOffsets_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_ListOffsets_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_ListOffsets_result');
  late final _rd_kafka_event_ListOffsets_result =
      _rd_kafka_event_ListOffsets_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_ListOffsets_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get DescribeUserScramCredentials result.
  ///
  /// @returns the result of a DescribeUserScramCredentials request, or NULL if
  /// event is of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_DESCRIBEUSERSCRAMCREDENTIALS_RESULT
  ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t>
      rd_kafka_event_DescribeUserScramCredentials_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_DescribeUserScramCredentials_result(
      rkev,
    );
  }

  late final _rd_kafka_event_DescribeUserScramCredentials_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t>
                  Function(ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_DescribeUserScramCredentials_result');
  late final _rd_kafka_event_DescribeUserScramCredentials_result =
      _rd_kafka_event_DescribeUserScramCredentials_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Get AlterUserScramCredentials result.
  ///
  /// @returns the result of a AlterUserScramCredentials request, or NULL if
  /// event is of different type.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p rkev object.
  ///
  /// Event types:
  /// RD_KAFKA_EVENT_ALTERUSERSCRAMCREDENTIALS_RESULT
  ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t>
      rd_kafka_event_AlterUserScramCredentials_result(
    ffi.Pointer<rd_kafka_event_t> rkev,
  ) {
    return _rd_kafka_event_AlterUserScramCredentials_result(
      rkev,
    );
  }

  late final _rd_kafka_event_AlterUserScramCredentials_resultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t> Function(
                  ffi.Pointer<rd_kafka_event_t>)>>(
      'rd_kafka_event_AlterUserScramCredentials_result');
  late final _rd_kafka_event_AlterUserScramCredentials_result =
      _rd_kafka_event_AlterUserScramCredentials_resultPtr.asFunction<
          ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t> Function(
              ffi.Pointer<rd_kafka_event_t>)>();

  /// @brief Poll a queue for an event for max \p timeout_ms.
  ///
  /// @returns an event, or NULL.
  ///
  /// @remark Use rd_kafka_event_destroy() to free the event.
  ///
  /// @sa rd_kafka_conf_set_background_event_cb()
  ffi.Pointer<rd_kafka_event_t> rd_kafka_queue_poll(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int timeout_ms,
  ) {
    return _rd_kafka_queue_poll(
      rkqu,
      timeout_ms,
    );
  }

  late final _rd_kafka_queue_pollPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_event_t> Function(
              ffi.Pointer<rd_kafka_queue_t>, ffi.Int)>>('rd_kafka_queue_poll');
  late final _rd_kafka_queue_poll = _rd_kafka_queue_pollPtr.asFunction<
      ffi.Pointer<rd_kafka_event_t> Function(
          ffi.Pointer<rd_kafka_queue_t>, int)>();

  /// @brief Poll a queue for events served through callbacks for max \p
  /// timeout_ms.
  ///
  /// @returns the number of events served.
  ///
  /// @remark This API must only be used for queues with callbacks registered
  /// for all expected event types. E.g., not a message queue.
  ///
  /// @remark Also see rd_kafka_conf_set_background_event_cb() for triggering
  /// event callbacks from a librdkafka-managed background thread.
  ///
  /// @sa rd_kafka_conf_set_background_event_cb()
  int rd_kafka_queue_poll_callback(
    ffi.Pointer<rd_kafka_queue_t> rkqu,
    int timeout_ms,
  ) {
    return _rd_kafka_queue_poll_callback(
      rkqu,
      timeout_ms,
    );
  }

  late final _rd_kafka_queue_poll_callbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<rd_kafka_queue_t>,
              ffi.Int)>>('rd_kafka_queue_poll_callback');
  late final _rd_kafka_queue_poll_callback = _rd_kafka_queue_poll_callbackPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_queue_t>, int)>();

  /// @brief Append an on_conf_set() interceptor.
  ///
  /// @param conf Configuration object.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_conf_set Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_conf_interceptor_add_on_conf_set(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_conf_set_t> on_conf_set,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_conf_interceptor_add_on_conf_set(
      conf,
      ic_name,
      on_conf_set,
      ic_opaque,
    );
  }

  late final _rd_kafka_conf_interceptor_add_on_conf_setPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_conf_set_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_conf_interceptor_add_on_conf_set');
  late final _rd_kafka_conf_interceptor_add_on_conf_set =
      _rd_kafka_conf_interceptor_add_on_conf_setPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_conf_set_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_conf_dup() interceptor.
  ///
  /// @param conf Configuration object.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_conf_dup Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_conf_interceptor_add_on_conf_dup(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_conf_dup_t> on_conf_dup,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_conf_interceptor_add_on_conf_dup(
      conf,
      ic_name,
      on_conf_dup,
      ic_opaque,
    );
  }

  late final _rd_kafka_conf_interceptor_add_on_conf_dupPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_conf_dup_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_conf_interceptor_add_on_conf_dup');
  late final _rd_kafka_conf_interceptor_add_on_conf_dup =
      _rd_kafka_conf_interceptor_add_on_conf_dupPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_conf_dup_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_conf_destroy() interceptor.
  ///
  /// @param conf Configuration object.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_conf_destroy Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR
  ///
  /// @remark Multiple on_conf_destroy() interceptors are allowed to be added
  /// to the same configuration object.
  int rd_kafka_conf_interceptor_add_on_conf_destroy(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_conf_destroy_t> on_conf_destroy,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_conf_interceptor_add_on_conf_destroy(
      conf,
      ic_name,
      on_conf_destroy,
      ic_opaque,
    );
  }

  late final _rd_kafka_conf_interceptor_add_on_conf_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_conf_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_conf_destroy_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_conf_interceptor_add_on_conf_destroy');
  late final _rd_kafka_conf_interceptor_add_on_conf_destroy =
      _rd_kafka_conf_interceptor_add_on_conf_destroyPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_conf_destroy_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_new() interceptor.
  ///
  /// @param conf Configuration object.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_new Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @remark Since the on_new() interceptor is added to the configuration object
  /// it may be copied by rd_kafka_conf_dup().
  /// An interceptor implementation must thus be able to handle
  /// the same interceptor,ic_opaque tuple to be used by multiple
  /// client instances.
  ///
  /// @remark An interceptor plugin should check the return value to make sure it
  /// has not already been added.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_conf_interceptor_add_on_new(
    ffi.Pointer<rd_kafka_conf_t> conf,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_new_t> on_new,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_conf_interceptor_add_on_new(
      conf,
      ic_name,
      on_new,
      ic_opaque,
    );
  }

  late final _rd_kafka_conf_interceptor_add_on_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_new_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_conf_interceptor_add_on_new');
  late final _rd_kafka_conf_interceptor_add_on_new =
      _rd_kafka_conf_interceptor_add_on_newPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_conf_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_new_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_destroy() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_destroy Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_destroy(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_destroy_t> on_destroy,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_destroy(
      rk,
      ic_name,
      on_destroy,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_destroyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_destroy_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_interceptor_add_on_destroy');
  late final _rd_kafka_interceptor_add_on_destroy =
      _rd_kafka_interceptor_add_on_destroyPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_destroy_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_send() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_send Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing intercepted with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_send(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_send_t> on_send,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_send(
      rk,
      ic_name,
      on_send,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_sendPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_send_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_interceptor_add_on_send');
  late final _rd_kafka_interceptor_add_on_send =
      _rd_kafka_interceptor_add_on_sendPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_send_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_acknowledgement() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_acknowledgement Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_acknowledgement(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_acknowledgement_t> on_acknowledgement,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_acknowledgement(
      rk,
      ic_name,
      on_acknowledgement,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_acknowledgementPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_acknowledgement_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_acknowledgement');
  late final _rd_kafka_interceptor_add_on_acknowledgement =
      _rd_kafka_interceptor_add_on_acknowledgementPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_acknowledgement_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_consume() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_consume Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_consume(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_consume_t> on_consume,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_consume(
      rk,
      ic_name,
      on_consume,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_consumePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_consume_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_interceptor_add_on_consume');
  late final _rd_kafka_interceptor_add_on_consume =
      _rd_kafka_interceptor_add_on_consumePtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_consume_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_commit() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_commit() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_commit(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_commit_t> on_commit,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_commit(
      rk,
      ic_name,
      on_commit,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_commitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_commit_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_interceptor_add_on_commit');
  late final _rd_kafka_interceptor_add_on_commit =
      _rd_kafka_interceptor_add_on_commitPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_commit_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_request_sent() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_request_sent() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_request_sent(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_request_sent_t> on_request_sent,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_request_sent(
      rk,
      ic_name,
      on_request_sent,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_request_sentPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_request_sent_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_request_sent');
  late final _rd_kafka_interceptor_add_on_request_sent =
      _rd_kafka_interceptor_add_on_request_sentPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_request_sent_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_response_received() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_response_received() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_response_received(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_response_received_t>
        on_response_received,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_response_received(
      rk,
      ic_name,
      on_response_received,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_response_receivedPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_response_received_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_response_received');
  late final _rd_kafka_interceptor_add_on_response_received =
      _rd_kafka_interceptor_add_on_response_receivedPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_response_received_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_thread_start() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_thread_start() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_thread_start(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_thread_start_t> on_thread_start,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_thread_start(
      rk,
      ic_name,
      on_thread_start,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_thread_startPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_thread_start_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_thread_start');
  late final _rd_kafka_interceptor_add_on_thread_start =
      _rd_kafka_interceptor_add_on_thread_startPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_thread_start_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_thread_exit() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_thread_exit() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_thread_exit(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_thread_exit_t> on_thread_exit,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_thread_exit(
      rk,
      ic_name,
      on_thread_exit,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_thread_exitPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_thread_exit_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_thread_exit');
  late final _rd_kafka_interceptor_add_on_thread_exit =
      _rd_kafka_interceptor_add_on_thread_exitPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_thread_exit_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @brief Append an on_broker_state_change() interceptor.
  ///
  /// @param rk Client instance.
  /// @param ic_name Interceptor name, used in logging.
  /// @param on_broker_state_change() Function pointer.
  /// @param ic_opaque Opaque value that will be passed to the function.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__CONFLICT
  /// if an existing interceptor with the same \p ic_name and function
  /// has already been added to \p conf.
  int rd_kafka_interceptor_add_on_broker_state_change(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> ic_name,
    ffi.Pointer<rd_kafka_interceptor_f_on_broker_state_change_t>
        on_broker_state_change,
    ffi.Pointer<ffi.Void> ic_opaque,
  ) {
    return _rd_kafka_interceptor_add_on_broker_state_change(
      rk,
      ic_name,
      on_broker_state_change,
      ic_opaque,
    );
  }

  late final _rd_kafka_interceptor_add_on_broker_state_changePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_interceptor_f_on_broker_state_change_t>,
                  ffi.Pointer<ffi.Void>)>>(
      'rd_kafka_interceptor_add_on_broker_state_change');
  late final _rd_kafka_interceptor_add_on_broker_state_change =
      _rd_kafka_interceptor_add_on_broker_state_changePtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_interceptor_f_on_broker_state_change_t>,
              ffi.Pointer<ffi.Void>)>();

  /// @returns the error code for the given topic result.
  int rd_kafka_topic_result_error(
    ffi.Pointer<rd_kafka_topic_result_t> topicres,
  ) {
    return _rd_kafka_topic_result_error(
      topicres,
    );
  }

  late final _rd_kafka_topic_result_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_topic_result_t>)>>(
      'rd_kafka_topic_result_error');
  late final _rd_kafka_topic_result_error = _rd_kafka_topic_result_errorPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_topic_result_t>)>();

  /// @returns the human readable error string for the given topic result,
  /// or NULL if there was no error.
  ///
  /// @remark lifetime of the returned string is the same as the \p topicres.
  ffi.Pointer<ffi.Char> rd_kafka_topic_result_error_string(
    ffi.Pointer<rd_kafka_topic_result_t> topicres,
  ) {
    return _rd_kafka_topic_result_error_string(
      topicres,
    );
  }

  late final _rd_kafka_topic_result_error_stringPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_topic_result_t>)>>(
      'rd_kafka_topic_result_error_string');
  late final _rd_kafka_topic_result_error_string =
      _rd_kafka_topic_result_error_stringPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_topic_result_t>)>();

  /// @returns the name of the topic for the given topic result.
  /// @remark lifetime of the returned string is the same as the \p topicres.
  ffi.Pointer<ffi.Char> rd_kafka_topic_result_name(
    ffi.Pointer<rd_kafka_topic_result_t> topicres,
  ) {
    return _rd_kafka_topic_result_name(
      topicres,
    );
  }

  late final _rd_kafka_topic_result_namePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_topic_result_t>)>>(
      'rd_kafka_topic_result_name');
  late final _rd_kafka_topic_result_name =
      _rd_kafka_topic_result_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_topic_result_t>)>();

  /// @returns the error for the given group result, or NULL on success.
  /// @remark lifetime of the returned error is the same as the \p groupres.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_group_result_error(
    ffi.Pointer<rd_kafka_group_result_t> groupres,
  ) {
    return _rd_kafka_group_result_error(
      groupres,
    );
  }

  late final _rd_kafka_group_result_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_group_result_t>)>>(
      'rd_kafka_group_result_error');
  late final _rd_kafka_group_result_error =
      _rd_kafka_group_result_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_group_result_t>)>();

  /// @returns the name of the group for the given group result.
  /// @remark lifetime of the returned string is the same as the \p groupres.
  ffi.Pointer<ffi.Char> rd_kafka_group_result_name(
    ffi.Pointer<rd_kafka_group_result_t> groupres,
  ) {
    return _rd_kafka_group_result_name(
      groupres,
    );
  }

  late final _rd_kafka_group_result_namePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_group_result_t>)>>(
      'rd_kafka_group_result_name');
  late final _rd_kafka_group_result_name =
      _rd_kafka_group_result_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_group_result_t>)>();

  /// @returns the partitions/offsets for the given group result, if applicable
  /// to the request type, else NULL.
  /// @remark lifetime of the returned list is the same as the \p groupres.
  ffi.Pointer<rd_kafka_topic_partition_list_t> rd_kafka_group_result_partitions(
    ffi.Pointer<rd_kafka_group_result_t> groupres,
  ) {
    return _rd_kafka_group_result_partitions(
      groupres,
    );
  }

  late final _rd_kafka_group_result_partitionsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
                  ffi.Pointer<rd_kafka_group_result_t>)>>(
      'rd_kafka_group_result_partitions');
  late final _rd_kafka_group_result_partitions =
      _rd_kafka_group_result_partitionsPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Pointer<rd_kafka_group_result_t>)>();

  /// @brief Create a new AdminOptions object.
  ///
  /// The options object is not modified by the Admin API request APIs,
  /// (e.g. CreateTopics) and may be reused for multiple calls.
  ///
  /// @param rk Client instance.
  /// @param for_api Specifies what Admin API this AdminOptions object will be used
  /// for, which will enforce what AdminOptions_set_..() calls may
  /// be used based on the API, causing unsupported set..() calls
  /// to fail.
  /// Specifying RD_KAFKA_ADMIN_OP_ANY disables the enforcement
  /// allowing any option to be set, even if the option
  /// is not used in a future call to an Admin API method.
  ///
  /// @returns a new AdminOptions object (which must be freed with
  /// rd_kafka_AdminOptions_destroy()), or NULL if \p for_api was set to
  /// an unknown API op type.
  ffi.Pointer<rd_kafka_AdminOptions_t> rd_kafka_AdminOptions_new(
    ffi.Pointer<rd_kafka_t> rk,
    int for_api,
  ) {
    return _rd_kafka_AdminOptions_new(
      rk,
      for_api,
    );
  }

  late final _rd_kafka_AdminOptions_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_AdminOptions_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Int32)>>('rd_kafka_AdminOptions_new');
  late final _rd_kafka_AdminOptions_new =
      _rd_kafka_AdminOptions_newPtr.asFunction<
          ffi.Pointer<rd_kafka_AdminOptions_t> Function(
              ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Destroy a AdminOptions object.
  void rd_kafka_AdminOptions_destroy(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
  ) {
    return _rd_kafka_AdminOptions_destroy(
      options,
    );
  }

  late final _rd_kafka_AdminOptions_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_AdminOptions_t>)>>(
      'rd_kafka_AdminOptions_destroy');
  late final _rd_kafka_AdminOptions_destroy = _rd_kafka_AdminOptions_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_AdminOptions_t>)>();

  /// @brief Sets the overall request timeout, including broker lookup,
  /// request transmission, operation time on broker, and response.
  ///
  /// @param options Admin options.
  /// @param timeout_ms Timeout in milliseconds. Defaults to `socket.timeout.ms`.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success, or
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if timeout was out of range in which
  /// case an error string will be written \p errstr.
  ///
  /// @remark This option is valid for all Admin API requests.
  int rd_kafka_AdminOptions_set_request_timeout(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int timeout_ms,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AdminOptions_set_request_timeout(
      options,
      timeout_ms,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AdminOptions_set_request_timeoutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AdminOptions_set_request_timeout');
  late final _rd_kafka_AdminOptions_set_request_timeout =
      _rd_kafka_AdminOptions_set_request_timeoutPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_AdminOptions_t>, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Sets the broker's operation timeout, such as the timeout for
  /// CreateTopics to complete the creation of topics on the controller
  /// before returning a result to the application.
  ///
  /// CreateTopics: values <= 0 will return immediately after triggering topic
  /// creation, while > 0 will wait this long for topic creation to propagate
  /// in cluster. Default: 60 seconds.
  ///
  /// DeleteTopics: same semantics as CreateTopics.
  /// CreatePartitions: same semantics as CreateTopics.
  ///
  /// @param options Admin options.
  /// @param timeout_ms Timeout in milliseconds.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success, or
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if timeout was out of range in which
  /// case an error string will be written \p errstr.
  ///
  /// @remark This option is valid for CreateTopics, DeleteTopics,
  /// CreatePartitions, and DeleteRecords.
  int rd_kafka_AdminOptions_set_operation_timeout(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int timeout_ms,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AdminOptions_set_operation_timeout(
      options,
      timeout_ms,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AdminOptions_set_operation_timeoutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AdminOptions_set_operation_timeout');
  late final _rd_kafka_AdminOptions_set_operation_timeout =
      _rd_kafka_AdminOptions_set_operation_timeoutPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_AdminOptions_t>, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Tell broker to only validate the request, without performing
  /// the requested operation (create topics, etc).
  ///
  /// @param options Admin options.
  /// @param true_or_false Defaults to false.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an
  /// error code on failure in which case an error string will
  /// be written \p errstr.
  ///
  /// @remark This option is valid for CreateTopics,
  /// CreatePartitions, AlterConfigs.
  int rd_kafka_AdminOptions_set_validate_only(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int true_or_false,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AdminOptions_set_validate_only(
      options,
      true_or_false,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AdminOptions_set_validate_onlyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AdminOptions_set_validate_only');
  late final _rd_kafka_AdminOptions_set_validate_only =
      _rd_kafka_AdminOptions_set_validate_onlyPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_AdminOptions_t>, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Override what broker the Admin request will be sent to.
  ///
  /// By default, Admin requests are sent to the controller broker, with
  /// the following exceptions:
  /// - AlterConfigs with a BROKER resource are sent to the broker id set
  /// as the resource name.
  /// - IncrementalAlterConfigs with a BROKER resource are sent to the broker id
  /// set as the resource name.
  /// - DescribeConfigs with a BROKER resource are sent to the broker id set
  /// as the resource name.
  ///
  /// @param options Admin Options.
  /// @param broker_id The broker to send the request to.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an
  /// error code on failure in which case an error string will
  /// be written \p errstr.
  ///
  /// @remark This API should typically not be used, but serves as a workaround
  /// if new resource types are to the broker that the client
  /// does not know where to send.
  int rd_kafka_AdminOptions_set_broker(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int broker_id,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AdminOptions_set_broker(
      options,
      broker_id,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AdminOptions_set_brokerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AdminOptions_set_broker');
  late final _rd_kafka_AdminOptions_set_broker =
      _rd_kafka_AdminOptions_set_brokerPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_AdminOptions_t>, int,
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Whether broker should return stable offsets
  /// (transaction-committed).
  ///
  /// @param options Admin options.
  /// @param true_or_false Defaults to false.
  ///
  /// @return NULL on success, a new error instance that must be
  /// released with rd_kafka_error_destroy() in case of error.
  ///
  /// @remark This option is valid for ListConsumerGroupOffsets.
  ffi.Pointer<rd_kafka_error_t>
      rd_kafka_AdminOptions_set_require_stable_offsets(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int true_or_false,
  ) {
    return _rd_kafka_AdminOptions_set_require_stable_offsets(
      options,
      true_or_false,
    );
  }

  late final _rd_kafka_AdminOptions_set_require_stable_offsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int)>>('rd_kafka_AdminOptions_set_require_stable_offsets');
  late final _rd_kafka_AdminOptions_set_require_stable_offsets =
      _rd_kafka_AdminOptions_set_require_stable_offsetsPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>, int)>();

  /// @brief Whether broker should return authorized operations for the given
  /// resource in the DescribeConsumerGroups, DescribeTopics, or
  /// DescribeCluster calls.
  ///
  /// @param options Admin options.
  /// @param true_or_false Defaults to false.
  ///
  /// @return NULL on success, a new error instance that must be
  /// released with rd_kafka_error_destroy() in case of error.
  ///
  /// @remark This option is valid for DescribeConsumerGroups, DescribeTopics,
  /// DescribeCluster.
  ffi.Pointer<rd_kafka_error_t>
      rd_kafka_AdminOptions_set_include_authorized_operations(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int true_or_false,
  ) {
    return _rd_kafka_AdminOptions_set_include_authorized_operations(
      options,
      true_or_false,
    );
  }

  late final _rd_kafka_AdminOptions_set_include_authorized_operationsPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<rd_kafka_error_t> Function(
                      ffi.Pointer<rd_kafka_AdminOptions_t>, ffi.Int)>>(
          'rd_kafka_AdminOptions_set_include_authorized_operations');
  late final _rd_kafka_AdminOptions_set_include_authorized_operations =
      _rd_kafka_AdminOptions_set_include_authorized_operationsPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>, int)>();

  /// @brief Set consumer groups states to query for.
  ///
  /// @param options Admin options.
  /// @param consumer_group_states Array of consumer group states.
  /// @param consumer_group_states_cnt Size of the \p consumer_group_states array.
  ///
  /// @return NULL on success, a new error instance that must be
  /// released with rd_kafka_error_destroy() in case of error.
  ///
  /// @remark This option is valid for ListConsumerGroups.
  ffi.Pointer<rd_kafka_error_t>
      rd_kafka_AdminOptions_set_match_consumer_group_states(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<ffi.Int32> consumer_group_states,
    int consumer_group_states_cnt,
  ) {
    return _rd_kafka_AdminOptions_set_match_consumer_group_states(
      options,
      consumer_group_states,
      consumer_group_states_cnt,
    );
  }

  late final _rd_kafka_AdminOptions_set_match_consumer_group_statesPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<rd_kafka_error_t> Function(
                      ffi.Pointer<rd_kafka_AdminOptions_t>,
                      ffi.Pointer<ffi.Int32>,
                      ffi.Size)>>(
          'rd_kafka_AdminOptions_set_match_consumer_group_states');
  late final _rd_kafka_AdminOptions_set_match_consumer_group_states =
      _rd_kafka_AdminOptions_set_match_consumer_group_statesPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<ffi.Int32>,
              int)>();

  /// @brief Set Isolation Level to an allowed `rd_kafka_IsolationLevel_t` value.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_AdminOptions_set_isolation_level(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    int value,
  ) {
    return _rd_kafka_AdminOptions_set_isolation_level(
      options,
      value,
    );
  }

  late final _rd_kafka_AdminOptions_set_isolation_levelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Int32)>>('rd_kafka_AdminOptions_set_isolation_level');
  late final _rd_kafka_AdminOptions_set_isolation_level =
      _rd_kafka_AdminOptions_set_isolation_levelPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>, int)>();

  /// @brief Set application opaque value that can be extracted from the
  /// result event using rd_kafka_event_opaque()
  void rd_kafka_AdminOptions_set_opaque(
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<ffi.Void> ev_opaque,
  ) {
    return _rd_kafka_AdminOptions_set_opaque(
      options,
      ev_opaque,
    );
  }

  late final _rd_kafka_AdminOptions_set_opaquePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<ffi.Void>)>>('rd_kafka_AdminOptions_set_opaque');
  late final _rd_kafka_AdminOptions_set_opaque =
      _rd_kafka_AdminOptions_set_opaquePtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_AdminOptions_t>, ffi.Pointer<ffi.Void>)>();

  /// @brief Create a new NewTopic object. This object is later passed to
  /// rd_kafka_CreateTopics().
  ///
  /// @param topic Topic name to create.
  /// @param num_partitions Number of partitions in topic, or -1 to use the
  /// broker's default partition count (>= 2.4.0).
  /// @param replication_factor Default replication factor for the topic's
  /// partitions, or -1 to use the broker's default
  /// replication factor (>= 2.4.0) or if
  /// set_replica_assignment() will be used.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  ///
  /// @returns a new allocated NewTopic object, or NULL if the input parameters
  /// are invalid.
  /// Use rd_kafka_NewTopic_destroy() to free object when done.
  ffi.Pointer<rd_kafka_NewTopic_t> rd_kafka_NewTopic_new(
    ffi.Pointer<ffi.Char> topic,
    int num_partitions,
    int replication_factor,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_NewTopic_new(
      topic,
      num_partitions,
      replication_factor,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_NewTopic_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_NewTopic_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Int,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_NewTopic_new');
  late final _rd_kafka_NewTopic_new = _rd_kafka_NewTopic_newPtr.asFunction<
      ffi.Pointer<rd_kafka_NewTopic_t> Function(
          ffi.Pointer<ffi.Char>, int, int, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Destroy and free a NewTopic object previously created with
  /// rd_kafka_NewTopic_new()
  void rd_kafka_NewTopic_destroy(
    ffi.Pointer<rd_kafka_NewTopic_t> new_topic,
  ) {
    return _rd_kafka_NewTopic_destroy(
      new_topic,
    );
  }

  late final _rd_kafka_NewTopic_destroyPtr = _lookup<
          ffi
          .NativeFunction<ffi.Void Function(ffi.Pointer<rd_kafka_NewTopic_t>)>>(
      'rd_kafka_NewTopic_destroy');
  late final _rd_kafka_NewTopic_destroy = _rd_kafka_NewTopic_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_NewTopic_t>)>();

  /// @brief Helper function to destroy all NewTopic objects in the \p new_topics
  /// array (of \p new_topic_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_NewTopic_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>> new_topics,
    int new_topic_cnt,
  ) {
    return _rd_kafka_NewTopic_destroy_array(
      new_topics,
      new_topic_cnt,
    );
  }

  late final _rd_kafka_NewTopic_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>>,
              ffi.Size)>>('rd_kafka_NewTopic_destroy_array');
  late final _rd_kafka_NewTopic_destroy_array =
      _rd_kafka_NewTopic_destroy_arrayPtr.asFunction<
          void Function(ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>>, int)>();

  /// @brief Set the replica (broker) assignment for \p partition to the
  /// replica set in \p broker_ids (of \p broker_id_cnt elements).
  ///
  /// @remark When this method is used, rd_kafka_NewTopic_new() must have
  /// been called with a \c replication_factor of -1.
  ///
  /// @remark An application must either set the replica assignment for
  /// all new partitions, or none.
  ///
  /// @remark If called, this function must be called consecutively for each
  /// partition, starting at 0.
  ///
  /// @remark Use rd_kafka_metadata() to retrieve the list of brokers
  /// in the cluster.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success, or an error code
  /// if the arguments were invalid.
  ///
  /// @sa rd_kafka_AdminOptions_set_validate_only()
  int rd_kafka_NewTopic_set_replica_assignment(
    ffi.Pointer<rd_kafka_NewTopic_t> new_topic,
    int partition,
    ffi.Pointer<ffi.Int32> broker_ids,
    int broker_id_cnt,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_NewTopic_set_replica_assignment(
      new_topic,
      partition,
      broker_ids,
      broker_id_cnt,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_NewTopic_set_replica_assignmentPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_NewTopic_t>,
              ffi.Int32,
              ffi.Pointer<ffi.Int32>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_NewTopic_set_replica_assignment');
  late final _rd_kafka_NewTopic_set_replica_assignment =
      _rd_kafka_NewTopic_set_replica_assignmentPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_NewTopic_t>, int,
              ffi.Pointer<ffi.Int32>, int, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Set (broker-side) topic configuration name/value pair.
  ///
  /// @remark The name and value are not validated by the client, the validation
  /// takes place on the broker.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success, or an error code
  /// if the arguments were invalid.
  ///
  /// @sa rd_kafka_AdminOptions_set_validate_only()
  /// @sa http://kafka.apache.org/documentation.html#topicconfigs
  int rd_kafka_NewTopic_set_config(
    ffi.Pointer<rd_kafka_NewTopic_t> new_topic,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> value,
  ) {
    return _rd_kafka_NewTopic_set_config(
      new_topic,
      name,
      value,
    );
  }

  late final _rd_kafka_NewTopic_set_configPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_NewTopic_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_NewTopic_set_config');
  late final _rd_kafka_NewTopic_set_config =
      _rd_kafka_NewTopic_set_configPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_NewTopic_t>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>();

  /// @brief Create topics in cluster as specified by the \p new_topics
  /// array of size \p new_topic_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param new_topics Array of new topics to create.
  /// @param new_topic_cnt Number of elements in \p new_topics array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_validate_only() - default false
  /// - rd_kafka_AdminOptions_set_operation_timeout() - default 60 seconds
  /// - rd_kafka_AdminOptions_set_request_timeout() - default socket.timeout.ms
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_CREATETOPICS_RESULT
  void rd_kafka_CreateTopics(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>> new_topics,
    int new_topic_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_CreateTopics(
      rk,
      new_topics,
      new_topic_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_CreateTopicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_CreateTopics');
  late final _rd_kafka_CreateTopics = _rd_kafka_CreateTopicsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_NewTopic_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of topic results from a CreateTopics result.
  ///
  /// The returned \p topics life-time is the same as the \p result object.
  ///
  /// @param result Result to get topics from.
  /// @param cntp Updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>>
      rd_kafka_CreateTopics_result_topics(
    ffi.Pointer<rd_kafka_CreateTopics_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_CreateTopics_result_topics(
      result,
      cntp,
    );
  }

  late final _rd_kafka_CreateTopics_result_topicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
              ffi.Pointer<rd_kafka_CreateTopics_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_CreateTopics_result_topics');
  late final _rd_kafka_CreateTopics_result_topics =
      _rd_kafka_CreateTopics_result_topicsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
              ffi.Pointer<rd_kafka_CreateTopics_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new DeleteTopic object. This object is later passed to
  /// rd_kafka_DeleteTopics().
  ///
  /// @param topic Topic name to delete.
  ///
  /// @returns a new allocated DeleteTopic object.
  /// Use rd_kafka_DeleteTopic_destroy() to free object when done.
  ffi.Pointer<rd_kafka_DeleteTopic_t> rd_kafka_DeleteTopic_new(
    ffi.Pointer<ffi.Char> topic,
  ) {
    return _rd_kafka_DeleteTopic_new(
      topic,
    );
  }

  late final _rd_kafka_DeleteTopic_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_DeleteTopic_t> Function(
              ffi.Pointer<ffi.Char>)>>('rd_kafka_DeleteTopic_new');
  late final _rd_kafka_DeleteTopic_new =
      _rd_kafka_DeleteTopic_newPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteTopic_t> Function(
              ffi.Pointer<ffi.Char>)>();

  /// @brief Destroy and free a DeleteTopic object previously created with
  /// rd_kafka_DeleteTopic_new()
  void rd_kafka_DeleteTopic_destroy(
    ffi.Pointer<rd_kafka_DeleteTopic_t> del_topic,
  ) {
    return _rd_kafka_DeleteTopic_destroy(
      del_topic,
    );
  }

  late final _rd_kafka_DeleteTopic_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_DeleteTopic_t>)>>(
      'rd_kafka_DeleteTopic_destroy');
  late final _rd_kafka_DeleteTopic_destroy = _rd_kafka_DeleteTopic_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_DeleteTopic_t>)>();

  /// @brief Helper function to destroy all DeleteTopic objects in
  /// the \p del_topics array (of \p del_topic_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_DeleteTopic_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>> del_topics,
    int del_topic_cnt,
  ) {
    return _rd_kafka_DeleteTopic_destroy_array(
      del_topics,
      del_topic_cnt,
    );
  }

  late final _rd_kafka_DeleteTopic_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>>,
              ffi.Size)>>('rd_kafka_DeleteTopic_destroy_array');
  late final _rd_kafka_DeleteTopic_destroy_array =
      _rd_kafka_DeleteTopic_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>>, int)>();

  /// @brief Delete topics from cluster as specified by the \p topics
  /// array of size \p topic_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param del_topics Array of topics to delete.
  /// @param del_topic_cnt Number of elements in \p topics array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DELETETOPICS_RESULT
  void rd_kafka_DeleteTopics(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>> del_topics,
    int del_topic_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DeleteTopics(
      rk,
      del_topics,
      del_topic_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DeleteTopicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DeleteTopics');
  late final _rd_kafka_DeleteTopics = _rd_kafka_DeleteTopicsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_DeleteTopic_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of topic results from a DeleteTopics result.
  ///
  /// The returned \p topics life-time is the same as the \p result object.
  ///
  /// @param result Result to get topic results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>>
      rd_kafka_DeleteTopics_result_topics(
    ffi.Pointer<rd_kafka_DeleteTopics_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DeleteTopics_result_topics(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DeleteTopics_result_topicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
              ffi.Pointer<rd_kafka_DeleteTopics_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DeleteTopics_result_topics');
  late final _rd_kafka_DeleteTopics_result_topics =
      _rd_kafka_DeleteTopics_result_topicsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
              ffi.Pointer<rd_kafka_DeleteTopics_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new NewPartitions. This object is later passed to
  /// rd_kafka_CreatePartitions() to increase the number of partitions
  /// to \p new_total_cnt for an existing topic.
  ///
  /// @param topic Topic name to create more partitions for.
  /// @param new_total_cnt Increase the topic's partition count to this value.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// @returns a new allocated NewPartitions object, or NULL if the
  /// input parameters are invalid.
  /// Use rd_kafka_NewPartitions_destroy() to free object when done.
  ffi.Pointer<rd_kafka_NewPartitions_t> rd_kafka_NewPartitions_new(
    ffi.Pointer<ffi.Char> topic,
    int new_total_cnt,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_NewPartitions_new(
      topic,
      new_total_cnt,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_NewPartitions_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_NewPartitions_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_NewPartitions_new');
  late final _rd_kafka_NewPartitions_new =
      _rd_kafka_NewPartitions_newPtr.asFunction<
          ffi.Pointer<rd_kafka_NewPartitions_t> Function(
              ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Destroy and free a NewPartitions object previously created with
  /// rd_kafka_NewPartitions_new()
  void rd_kafka_NewPartitions_destroy(
    ffi.Pointer<rd_kafka_NewPartitions_t> new_parts,
  ) {
    return _rd_kafka_NewPartitions_destroy(
      new_parts,
    );
  }

  late final _rd_kafka_NewPartitions_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_NewPartitions_t>)>>(
      'rd_kafka_NewPartitions_destroy');
  late final _rd_kafka_NewPartitions_destroy =
      _rd_kafka_NewPartitions_destroyPtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_NewPartitions_t>)>();

  /// @brief Helper function to destroy all NewPartitions objects in the
  /// \p new_parts array (of \p new_parts_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_NewPartitions_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>> new_parts,
    int new_parts_cnt,
  ) {
    return _rd_kafka_NewPartitions_destroy_array(
      new_parts,
      new_parts_cnt,
    );
  }

  late final _rd_kafka_NewPartitions_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>>,
              ffi.Size)>>('rd_kafka_NewPartitions_destroy_array');
  late final _rd_kafka_NewPartitions_destroy_array =
      _rd_kafka_NewPartitions_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>>, int)>();

  /// @brief Set the replica (broker id) assignment for \p new_partition_idx to the
  /// replica set in \p broker_ids (of \p broker_id_cnt elements).
  ///
  /// @remark An application must either set the replica assignment for
  /// all new partitions, or none.
  ///
  /// @remark If called, this function must be called consecutively for each
  /// new partition being created,
  /// where \p new_partition_idx 0 is the first new partition,
  /// 1 is the second, and so on.
  ///
  /// @remark \p broker_id_cnt should match the topic's replication factor.
  ///
  /// @remark Use rd_kafka_metadata() to retrieve the list of brokers
  /// in the cluster.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success, or an error code
  /// if the arguments were invalid.
  ///
  /// @sa rd_kafka_AdminOptions_set_validate_only()
  int rd_kafka_NewPartitions_set_replica_assignment(
    ffi.Pointer<rd_kafka_NewPartitions_t> new_parts,
    int new_partition_idx,
    ffi.Pointer<ffi.Int32> broker_ids,
    int broker_id_cnt,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_NewPartitions_set_replica_assignment(
      new_parts,
      new_partition_idx,
      broker_ids,
      broker_id_cnt,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_NewPartitions_set_replica_assignmentPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_NewPartitions_t>,
              ffi.Int32,
              ffi.Pointer<ffi.Int32>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_NewPartitions_set_replica_assignment');
  late final _rd_kafka_NewPartitions_set_replica_assignment =
      _rd_kafka_NewPartitions_set_replica_assignmentPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_NewPartitions_t>, int,
              ffi.Pointer<ffi.Int32>, int, ffi.Pointer<ffi.Char>, int)>();

  /// @brief Create additional partitions for the given topics, as specified
  /// by the \p new_parts array of size \p new_parts_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param new_parts Array of topics for which new partitions are to be created.
  /// @param new_parts_cnt Number of elements in \p new_parts array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_validate_only() - default false
  /// - rd_kafka_AdminOptions_set_operation_timeout() - default 60 seconds
  /// - rd_kafka_AdminOptions_set_request_timeout() - default socket.timeout.ms
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_CREATEPARTITIONS_RESULT
  void rd_kafka_CreatePartitions(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>> new_parts,
    int new_parts_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_CreatePartitions(
      rk,
      new_parts,
      new_parts_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_CreatePartitionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_CreatePartitions');
  late final _rd_kafka_CreatePartitions =
      _rd_kafka_CreatePartitionsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_NewPartitions_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of topic results from a CreatePartitions result.
  ///
  /// The returned \p topics life-time is the same as the \p result object.
  ///
  /// @param result Result o get topic results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>>
      rd_kafka_CreatePartitions_result_topics(
    ffi.Pointer<rd_kafka_CreatePartitions_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_CreatePartitions_result_topics(
      result,
      cntp,
    );
  }

  late final _rd_kafka_CreatePartitions_result_topicsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
                  ffi.Pointer<rd_kafka_CreatePartitions_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_CreatePartitions_result_topics');
  late final _rd_kafka_CreatePartitions_result_topics =
      _rd_kafka_CreatePartitions_result_topicsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_topic_result_t>> Function(
              ffi.Pointer<rd_kafka_CreatePartitions_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @returns a string representation of the \p confsource.
  ffi.Pointer<ffi.Char> rd_kafka_ConfigSource_name(
    int confsource,
  ) {
    return _rd_kafka_ConfigSource_name(
      confsource,
    );
  }

  late final _rd_kafka_ConfigSource_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_ConfigSource_name');
  late final _rd_kafka_ConfigSource_name = _rd_kafka_ConfigSource_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @returns the configuration property name
  ffi.Pointer<ffi.Char> rd_kafka_ConfigEntry_name(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_name(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_namePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_name');
  late final _rd_kafka_ConfigEntry_name =
      _rd_kafka_ConfigEntry_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns the configuration value, may be NULL for sensitive or unset
  /// properties.
  ffi.Pointer<ffi.Char> rd_kafka_ConfigEntry_value(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_value(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_valuePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_value');
  late final _rd_kafka_ConfigEntry_value =
      _rd_kafka_ConfigEntry_valuePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns the config source.
  int rd_kafka_ConfigEntry_source(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_source(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_sourcePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_source');
  late final _rd_kafka_ConfigEntry_source = _rd_kafka_ConfigEntry_sourcePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns 1 if the config property is read-only on the broker, else 0.
  /// @remark Shall only be used on a DescribeConfigs result, otherwise returns -1.
  int rd_kafka_ConfigEntry_is_read_only(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_is_read_only(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_is_read_onlyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_is_read_only');
  late final _rd_kafka_ConfigEntry_is_read_only =
      _rd_kafka_ConfigEntry_is_read_onlyPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns 1 if the config property is set to its default value on the broker,
  /// else 0.
  /// @remark Shall only be used on a DescribeConfigs result, otherwise returns -1.
  int rd_kafka_ConfigEntry_is_default(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_is_default(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_is_defaultPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_is_default');
  late final _rd_kafka_ConfigEntry_is_default =
      _rd_kafka_ConfigEntry_is_defaultPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns 1 if the config property contains sensitive information (such as
  /// security configuration), else 0.
  /// @remark An application should take care not to include the value of
  /// sensitive configuration entries in its output.
  /// @remark Shall only be used on a DescribeConfigs result, otherwise returns -1.
  int rd_kafka_ConfigEntry_is_sensitive(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_is_sensitive(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_is_sensitivePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_is_sensitive');
  late final _rd_kafka_ConfigEntry_is_sensitive =
      _rd_kafka_ConfigEntry_is_sensitivePtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns 1 if this entry is a synonym, else 0.
  int rd_kafka_ConfigEntry_is_synonym(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
  ) {
    return _rd_kafka_ConfigEntry_is_synonym(
      entry,
    );
  }

  late final _rd_kafka_ConfigEntry_is_synonymPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>>(
      'rd_kafka_ConfigEntry_is_synonym');
  late final _rd_kafka_ConfigEntry_is_synonym =
      _rd_kafka_ConfigEntry_is_synonymPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigEntry_t>)>();

  /// @returns the synonym config entry array.
  ///
  /// @param entry Entry to get synonyms for.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned entry is the same as \p conf .
  /// @remark Shall only be used on a DescribeConfigs result,
  /// otherwise returns NULL.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>>
      rd_kafka_ConfigEntry_synonyms(
    ffi.Pointer<rd_kafka_ConfigEntry_t> entry,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ConfigEntry_synonyms(
      entry,
      cntp,
    );
  }

  late final _rd_kafka_ConfigEntry_synonymsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>> Function(
              ffi.Pointer<rd_kafka_ConfigEntry_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_ConfigEntry_synonyms');
  late final _rd_kafka_ConfigEntry_synonyms =
      _rd_kafka_ConfigEntry_synonymsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>> Function(
              ffi.Pointer<rd_kafka_ConfigEntry_t>, ffi.Pointer<ffi.Size>)>();

  /// @returns a string representation of the \p resource_pattern_type
  ffi.Pointer<ffi.Char> rd_kafka_ResourcePatternType_name(
    int resource_pattern_type,
  ) {
    return _rd_kafka_ResourcePatternType_name(
      resource_pattern_type,
    );
  }

  late final _rd_kafka_ResourcePatternType_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_ResourcePatternType_name');
  late final _rd_kafka_ResourcePatternType_name =
      _rd_kafka_ResourcePatternType_namePtr
          .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @returns a string representation of the \p restype
  ffi.Pointer<ffi.Char> rd_kafka_ResourceType_name(
    int restype,
  ) {
    return _rd_kafka_ResourceType_name(
      restype,
    );
  }

  late final _rd_kafka_ResourceType_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_ResourceType_name');
  late final _rd_kafka_ResourceType_name = _rd_kafka_ResourceType_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @brief Create new ConfigResource object.
  ///
  /// @param restype The resource type (e.g., RD_KAFKA_RESOURCE_TOPIC)
  /// @param resname The resource name (e.g., the topic name)
  ///
  /// @returns a newly allocated object
  ffi.Pointer<rd_kafka_ConfigResource_t> rd_kafka_ConfigResource_new(
    int restype,
    ffi.Pointer<ffi.Char> resname,
  ) {
    return _rd_kafka_ConfigResource_new(
      restype,
      resname,
    );
  }

  late final _rd_kafka_ConfigResource_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_ConfigResource_t> Function(ffi.Int32,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_ConfigResource_new');
  late final _rd_kafka_ConfigResource_new =
      _rd_kafka_ConfigResource_newPtr.asFunction<
          ffi.Pointer<rd_kafka_ConfigResource_t> Function(
              int, ffi.Pointer<ffi.Char>)>();

  /// @brief Destroy and free a ConfigResource object previously created with
  /// rd_kafka_ConfigResource_new()
  void rd_kafka_ConfigResource_destroy(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
  ) {
    return _rd_kafka_ConfigResource_destroy(
      config,
    );
  }

  late final _rd_kafka_ConfigResource_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>>(
      'rd_kafka_ConfigResource_destroy');
  late final _rd_kafka_ConfigResource_destroy =
      _rd_kafka_ConfigResource_destroyPtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>();

  /// @brief Helper function to destroy all ConfigResource objects in
  /// the \p configs array (of \p config_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_ConfigResource_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> config,
    int config_cnt,
  ) {
    return _rd_kafka_ConfigResource_destroy_array(
      config,
      config_cnt,
    );
  }

  late final _rd_kafka_ConfigResource_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
              ffi.Size)>>('rd_kafka_ConfigResource_destroy_array');
  late final _rd_kafka_ConfigResource_destroy_array =
      _rd_kafka_ConfigResource_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>, int)>();

  /// @brief Set configuration name value pair.
  ///
  /// @param config ConfigResource to set config property on.
  /// @param name Configuration name, depends on resource type.
  /// @param value Configuration value, depends on resource type and \p name.
  /// Set to \c NULL to revert configuration value to default.
  ///
  /// This will overwrite the current value.
  ///
  /// @returns RD_KAFKA_RESP_ERR_NO_ERROR if config was added to resource,
  /// or RD_KAFKA_RESP_ERR__INVALID_ARG on invalid input.
  int rd_kafka_ConfigResource_set_config(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Char> value,
  ) {
    return _rd_kafka_ConfigResource_set_config(
      config,
      name,
      value,
    );
  }

  late final _rd_kafka_ConfigResource_set_configPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('rd_kafka_ConfigResource_set_config');
  late final _rd_kafka_ConfigResource_set_config =
      _rd_kafka_ConfigResource_set_configPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConfigResource_t>,
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  /// @brief Add the value of the configuration entry for a subsequent
  /// incremental alter config operation. APPEND and SUBTRACT are
  /// possible for list-type configuration entries only.
  ///
  /// @param config ConfigResource to add config property to.
  /// @param name Configuration name, depends on resource type.
  /// @param op_type Operation type, one of rd_kafka_AlterConfigOpType_t.
  /// @param value Configuration value, depends on resource type and \p name.
  /// Set to \c NULL, only with with op_type set to DELETE,
  /// to revert configuration value to default.
  ///
  /// @returns NULL on success, or an rd_kafka_error_t *
  /// with the corresponding error code and string.
  /// Error ownership belongs to the caller.
  /// Possible error codes:
  /// - RD_KAFKA_RESP_ERR__INVALID_ARG on invalid input.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_ConfigResource_add_incremental_config(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
    ffi.Pointer<ffi.Char> name,
    int op_type,
    ffi.Pointer<ffi.Char> value,
  ) {
    return _rd_kafka_ConfigResource_add_incremental_config(
      config,
      name,
      op_type,
      value,
    );
  }

  late final _rd_kafka_ConfigResource_add_incremental_configPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_ConfigResource_t>,
                  ffi.Pointer<ffi.Char>,
                  ffi.Int32,
                  ffi.Pointer<ffi.Char>)>>(
      'rd_kafka_ConfigResource_add_incremental_config');
  late final _rd_kafka_ConfigResource_add_incremental_config =
      _rd_kafka_ConfigResource_add_incremental_configPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>,
              ffi.Pointer<ffi.Char>,
              int,
              ffi.Pointer<ffi.Char>)>();

  /// @brief Get an array of config entries from a ConfigResource object.
  ///
  /// The returned object life-times are the same as the \p config object.
  ///
  /// @param config ConfigResource to get configs from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>>
      rd_kafka_ConfigResource_configs(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ConfigResource_configs(
      config,
      cntp,
    );
  }

  late final _rd_kafka_ConfigResource_configsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>> Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_ConfigResource_configs');
  late final _rd_kafka_ConfigResource_configs =
      _rd_kafka_ConfigResource_configsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigEntry_t>> Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>, ffi.Pointer<ffi.Size>)>();

  /// @returns the ResourceType for \p config
  int rd_kafka_ConfigResource_type(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
  ) {
    return _rd_kafka_ConfigResource_type(
      config,
    );
  }

  late final _rd_kafka_ConfigResource_typePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>>(
      'rd_kafka_ConfigResource_type');
  late final _rd_kafka_ConfigResource_type = _rd_kafka_ConfigResource_typePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>();

  /// @returns the name for \p config
  ffi.Pointer<ffi.Char> rd_kafka_ConfigResource_name(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
  ) {
    return _rd_kafka_ConfigResource_name(
      config,
    );
  }

  late final _rd_kafka_ConfigResource_namePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConfigResource_t>)>>(
      'rd_kafka_ConfigResource_name');
  late final _rd_kafka_ConfigResource_name =
      _rd_kafka_ConfigResource_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>)>();

  /// @returns the error for this resource from an AlterConfigs request
  int rd_kafka_ConfigResource_error(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
  ) {
    return _rd_kafka_ConfigResource_error(
      config,
    );
  }

  late final _rd_kafka_ConfigResource_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>>(
      'rd_kafka_ConfigResource_error');
  late final _rd_kafka_ConfigResource_error = _rd_kafka_ConfigResource_errorPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_ConfigResource_t>)>();

  /// @returns the error string for this resource from an AlterConfigs
  /// request, or NULL if no error.
  ffi.Pointer<ffi.Char> rd_kafka_ConfigResource_error_string(
    ffi.Pointer<rd_kafka_ConfigResource_t> config,
  ) {
    return _rd_kafka_ConfigResource_error_string(
      config,
    );
  }

  late final _rd_kafka_ConfigResource_error_stringPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConfigResource_t>)>>(
      'rd_kafka_ConfigResource_error_string');
  late final _rd_kafka_ConfigResource_error_string =
      _rd_kafka_ConfigResource_error_stringPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConfigResource_t>)>();

  /// @brief Update the configuration for the specified resources.
  /// Updates are not transactional so they may succeed for a subset
  /// of the provided resources while the others fail.
  /// The configuration for a particular resource is updated atomically,
  /// replacing values using the provided ConfigEntrys and reverting
  /// unspecified ConfigEntrys to their default values.
  ///
  /// @remark Requires broker version >=0.11.0.0
  ///
  /// @warning AlterConfigs will replace all existing configuration for
  /// the provided resources with the new configuration given,
  /// reverting all other configuration to their default values.
  ///
  /// @remark Multiple resources and resource types may be set, but at most one
  /// resource of type \c RD_KAFKA_RESOURCE_BROKER is allowed per call
  /// since these resource requests must be sent to the broker specified
  /// in the resource.
  ///
  /// @deprecated Use rd_kafka_IncrementalAlterConfigs().
  void rd_kafka_AlterConfigs(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> configs,
    int config_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_AlterConfigs(
      rk,
      configs,
      config_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_AlterConfigsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_AlterConfigs');
  late final _rd_kafka_AlterConfigs = _rd_kafka_AlterConfigsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of resource results from a AlterConfigs result.
  ///
  /// Use \c rd_kafka_ConfigResource_error() and
  /// \c rd_kafka_ConfigResource_error_string() to extract per-resource error
  /// results on the returned array elements.
  ///
  /// The returned object life-times are the same as the \p result object.
  ///
  /// @param result Result object to get resource results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @returns an array of ConfigResource elements, or NULL if not available.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>
      rd_kafka_AlterConfigs_result_resources(
    ffi.Pointer<rd_kafka_AlterConfigs_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_AlterConfigs_result_resources(
      result,
      cntp,
    );
  }

  late final _rd_kafka_AlterConfigs_result_resourcesPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
                  ffi.Pointer<rd_kafka_AlterConfigs_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_AlterConfigs_result_resources');
  late final _rd_kafka_AlterConfigs_result_resources =
      _rd_kafka_AlterConfigs_result_resourcesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
              ffi.Pointer<rd_kafka_AlterConfigs_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Incrementally update the configuration for the specified resources.
  /// Updates are not transactional so they may succeed for some resources
  /// while fail for others. The configs for a particular resource are
  /// updated atomically, executing the corresponding incremental operations
  /// on the provided configurations.
  ///
  /// @remark Requires broker version >=2.3.0
  ///
  /// @remark Multiple resources and resource types may be set, but at most one
  /// resource of type \c RD_KAFKA_RESOURCE_BROKER is allowed per call
  /// since these resource requests must be sent to the broker specified
  /// in the resource. Broker option will be ignored in this case.
  ///
  /// @param rk Client instance.
  /// @param configs Array of config entries to alter.
  /// @param config_cnt Number of elements in \p configs array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  void rd_kafka_IncrementalAlterConfigs(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> configs,
    int config_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_IncrementalAlterConfigs(
      rk,
      configs,
      config_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_IncrementalAlterConfigsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
                  ffi.Size,
                  ffi.Pointer<rd_kafka_AdminOptions_t>,
                  ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_IncrementalAlterConfigs');
  late final _rd_kafka_IncrementalAlterConfigs =
      _rd_kafka_IncrementalAlterConfigsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of resource results from a IncrementalAlterConfigs
  /// result.
  ///
  /// Use \c rd_kafka_ConfigResource_error() and
  /// \c rd_kafka_ConfigResource_error_string() to extract per-resource error
  /// results on the returned array elements.
  ///
  /// The returned object life-times are the same as the \p result object.
  ///
  /// @param result Result object to get resource results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @returns an array of ConfigResource elements, or NULL if not available.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>
      rd_kafka_IncrementalAlterConfigs_result_resources(
    ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_IncrementalAlterConfigs_result_resources(
      result,
      cntp,
    );
  }

  late final _rd_kafka_IncrementalAlterConfigs_result_resourcesPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
                  ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_IncrementalAlterConfigs_result_resources');
  late final _rd_kafka_IncrementalAlterConfigs_result_resources =
      _rd_kafka_IncrementalAlterConfigs_result_resourcesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
              ffi.Pointer<rd_kafka_IncrementalAlterConfigs_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Get configuration for the specified resources in \p configs.
  ///
  /// The returned configuration includes default values and the
  /// rd_kafka_ConfigEntry_is_default() or rd_kafka_ConfigEntry_source()
  /// methods may be used to distinguish them from user supplied values.
  ///
  /// The value of config entries where rd_kafka_ConfigEntry_is_sensitive()
  /// is true will always be NULL to avoid disclosing sensitive
  /// information, such as security settings.
  ///
  /// Configuration entries where rd_kafka_ConfigEntry_is_read_only()
  /// is true can't be updated (with rd_kafka_AlterConfigs()).
  ///
  /// Synonym configuration entries are returned if the broker supports
  /// it (broker version >= 1.1.0). See rd_kafka_ConfigEntry_synonyms().
  ///
  /// @remark Requires broker version >=0.11.0.0
  ///
  /// @remark Multiple resources and resource types may be requested, but at most
  /// one resource of type \c RD_KAFKA_RESOURCE_BROKER is allowed per call
  /// since these resource requests must be sent to the broker specified
  /// in the resource.
  void rd_kafka_DescribeConfigs(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> configs,
    int config_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeConfigs(
      rk,
      configs,
      config_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeConfigsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DescribeConfigs');
  late final _rd_kafka_DescribeConfigs =
      _rd_kafka_DescribeConfigsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of resource results from a DescribeConfigs result.
  ///
  /// The returned \p resources life-time is the same as the \p result object.
  ///
  /// @param result Result object to get resource results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>>
      rd_kafka_DescribeConfigs_result_resources(
    ffi.Pointer<rd_kafka_DescribeConfigs_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeConfigs_result_resources(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeConfigs_result_resourcesPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
                  ffi.Pointer<rd_kafka_DescribeConfigs_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_DescribeConfigs_result_resources');
  late final _rd_kafka_DescribeConfigs_result_resources =
      _rd_kafka_DescribeConfigs_result_resourcesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConfigResource_t>> Function(
              ffi.Pointer<rd_kafka_DescribeConfigs_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new DeleteRecords object. This object is later passed to
  /// rd_kafka_DeleteRecords().
  ///
  /// \p before_offsets must contain \c topic, \c partition, and
  /// \c offset is the offset before which the messages will
  /// be deleted (exclusive).
  /// Set \c offset to RD_KAFKA_OFFSET_END (high-watermark) in order to
  /// delete all data in the partition.
  ///
  /// @param before_offsets For each partition delete all messages up to but not
  /// including the specified offset.
  ///
  /// @returns a new allocated DeleteRecords object.
  /// Use rd_kafka_DeleteRecords_destroy() to free object when done.
  ffi.Pointer<rd_kafka_DeleteRecords_t> rd_kafka_DeleteRecords_new(
    ffi.Pointer<rd_kafka_topic_partition_list_t> before_offsets,
  ) {
    return _rd_kafka_DeleteRecords_new(
      before_offsets,
    );
  }

  late final _rd_kafka_DeleteRecords_newPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteRecords_t> Function(
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_DeleteRecords_new');
  late final _rd_kafka_DeleteRecords_new =
      _rd_kafka_DeleteRecords_newPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteRecords_t> Function(
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Destroy and free a DeleteRecords object previously created with
  /// rd_kafka_DeleteRecords_new()
  void rd_kafka_DeleteRecords_destroy(
    ffi.Pointer<rd_kafka_DeleteRecords_t> del_records,
  ) {
    return _rd_kafka_DeleteRecords_destroy(
      del_records,
    );
  }

  late final _rd_kafka_DeleteRecords_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_DeleteRecords_t>)>>(
      'rd_kafka_DeleteRecords_destroy');
  late final _rd_kafka_DeleteRecords_destroy =
      _rd_kafka_DeleteRecords_destroyPtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_DeleteRecords_t>)>();

  /// @brief Helper function to destroy all DeleteRecords objects in
  /// the \p del_groups array (of \p del_group_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_DeleteRecords_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>> del_records,
    int del_record_cnt,
  ) {
    return _rd_kafka_DeleteRecords_destroy_array(
      del_records,
      del_record_cnt,
    );
  }

  late final _rd_kafka_DeleteRecords_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>>,
              ffi.Size)>>('rd_kafka_DeleteRecords_destroy_array');
  late final _rd_kafka_DeleteRecords_destroy_array =
      _rd_kafka_DeleteRecords_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>>, int)>();

  /// @brief Delete records (messages) in topic partitions older than the
  /// offsets provided.
  ///
  /// @param rk Client instance.
  /// @param del_records The offsets to delete (up to).
  /// Currently only one DeleteRecords_t (but containing
  /// multiple offsets) is supported.
  /// @param del_record_cnt The number of elements in del_records, must be 1.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_operation_timeout() - default 60 seconds.
  /// Controls how long the brokers will wait for records to be deleted.
  /// - rd_kafka_AdminOptions_set_request_timeout() - default socket.timeout.ms.
  /// Controls how long \c rdkafka will wait for the request to complete.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DELETERECORDS_RESULT
  void rd_kafka_DeleteRecords(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>> del_records,
    int del_record_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DeleteRecords(
      rk,
      del_records,
      del_record_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DeleteRecordsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DeleteRecords');
  late final _rd_kafka_DeleteRecords = _rd_kafka_DeleteRecordsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_DeleteRecords_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get a list of topic and partition results from a DeleteRecords result.
  /// The returned objects will contain \c topic, \c partition, \c offset
  /// and \c err. \c offset will be set to the post-deletion low-watermark
  /// (smallest available offset of all live replicas). \c err will be set
  /// per-partition if deletion failed.
  ///
  /// The returned object's life-time is the same as the \p result object.
  ffi.Pointer<rd_kafka_topic_partition_list_t>
      rd_kafka_DeleteRecords_result_offsets(
    ffi.Pointer<rd_kafka_DeleteRecords_result_t> result,
  ) {
    return _rd_kafka_DeleteRecords_result_offsets(
      result,
    );
  }

  late final _rd_kafka_DeleteRecords_result_offsetsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
                  ffi.Pointer<rd_kafka_DeleteRecords_result_t>)>>(
      'rd_kafka_DeleteRecords_result_offsets');
  late final _rd_kafka_DeleteRecords_result_offsets =
      _rd_kafka_DeleteRecords_result_offsetsPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Pointer<rd_kafka_DeleteRecords_result_t>)>();

  /// @brief Creates a new TopicCollection for passing to rd_kafka_DescribeTopics.
  ///
  /// @param topics A list of topics.
  /// @param topics_cnt Count of topics.
  ///
  /// @return a newly allocated TopicCollection object. Must be freed using
  /// rd_kafka_TopicCollection_destroy when done.
  ffi.Pointer<rd_kafka_TopicCollection_t>
      rd_kafka_TopicCollection_of_topic_names(
    ffi.Pointer<ffi.Pointer<ffi.Char>> topics,
    int topics_cnt,
  ) {
    return _rd_kafka_TopicCollection_of_topic_names(
      topics,
      topics_cnt,
    );
  }

  late final _rd_kafka_TopicCollection_of_topic_namesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_TopicCollection_t> Function(
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Size)>>('rd_kafka_TopicCollection_of_topic_names');
  late final _rd_kafka_TopicCollection_of_topic_names =
      _rd_kafka_TopicCollection_of_topic_namesPtr.asFunction<
          ffi.Pointer<rd_kafka_TopicCollection_t> Function(
              ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  /// @brief Destroy and free a TopicCollection object created with
  /// rd_kafka_TopicCollection_new_* methods.
  void rd_kafka_TopicCollection_destroy(
    ffi.Pointer<rd_kafka_TopicCollection_t> topics,
  ) {
    return _rd_kafka_TopicCollection_destroy(
      topics,
    );
  }

  late final _rd_kafka_TopicCollection_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_TopicCollection_t>)>>(
      'rd_kafka_TopicCollection_destroy');
  late final _rd_kafka_TopicCollection_destroy =
      _rd_kafka_TopicCollection_destroyPtr
          .asFunction<void Function(ffi.Pointer<rd_kafka_TopicCollection_t>)>();

  /// @brief Describe topics as specified by the \p topics
  /// array of size \p topics_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param topics Collection of topics to describe.
  /// @param options Optional admin options, or NULL for defaults.
  /// Valid options:
  /// - include_authorized_operations
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DESCRIBETOPICS_RESULT
  void rd_kafka_DescribeTopics(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_TopicCollection_t> topics,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeTopics(
      rk,
      topics,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeTopicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_TopicCollection_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DescribeTopics');
  late final _rd_kafka_DescribeTopics = _rd_kafka_DescribeTopicsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_TopicCollection_t>,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of topic results from a DescribeTopics result.
  ///
  /// @param result Result to get topics results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_TopicDescription_t>>
      rd_kafka_DescribeTopics_result_topics(
    ffi.Pointer<rd_kafka_DescribeTopics_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeTopics_result_topics(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeTopics_result_topicsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_TopicDescription_t>> Function(
              ffi.Pointer<rd_kafka_DescribeTopics_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DescribeTopics_result_topics');
  late final _rd_kafka_DescribeTopics_result_topics =
      _rd_kafka_DescribeTopics_result_topicsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_TopicDescription_t>> Function(
              ffi.Pointer<rd_kafka_DescribeTopics_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets an array of partitions for the \p topicdesc topic.
  ///
  /// @param topicdesc The topic description.
  /// @param cntp is updated to the number of partitions in the array.
  ///
  /// @return An array of TopicPartitionInfos.
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p topicdesc object.
  ffi.Pointer<ffi.Pointer<rd_kafka_TopicPartitionInfo_t>>
      rd_kafka_TopicDescription_partitions(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_TopicDescription_partitions(
      topicdesc,
      cntp,
    );
  }

  late final _rd_kafka_TopicDescription_partitionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_TopicPartitionInfo_t>> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_TopicDescription_partitions');
  late final _rd_kafka_TopicDescription_partitions =
      _rd_kafka_TopicDescription_partitionsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_TopicPartitionInfo_t>> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the partition id for \p partition.
  ///
  /// @param partition The partition info.
  ///
  /// @return The partition id.
  int rd_kafka_TopicPartitionInfo_partition(
    ffi.Pointer<rd_kafka_TopicPartitionInfo_t> partition,
  ) {
    return _rd_kafka_TopicPartitionInfo_partition(
      partition,
    );
  }

  late final _rd_kafka_TopicPartitionInfo_partitionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_TopicPartitionInfo_t>)>>(
      'rd_kafka_TopicPartitionInfo_partition');
  late final _rd_kafka_TopicPartitionInfo_partition =
      _rd_kafka_TopicPartitionInfo_partitionPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_TopicPartitionInfo_t>)>();

  /// @brief Gets the partition leader for \p partition.
  ///
  /// @param partition The partition info.
  ///
  /// @return The partition leader.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p partition object.
  ffi.Pointer<rd_kafka_Node_t> rd_kafka_TopicPartitionInfo_leader(
    ffi.Pointer<rd_kafka_TopicPartitionInfo_t> partition,
  ) {
    return _rd_kafka_TopicPartitionInfo_leader(
      partition,
    );
  }

  late final _rd_kafka_TopicPartitionInfo_leaderPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_Node_t> Function(
                  ffi.Pointer<rd_kafka_TopicPartitionInfo_t>)>>(
      'rd_kafka_TopicPartitionInfo_leader');
  late final _rd_kafka_TopicPartitionInfo_leader =
      _rd_kafka_TopicPartitionInfo_leaderPtr.asFunction<
          ffi.Pointer<rd_kafka_Node_t> Function(
              ffi.Pointer<rd_kafka_TopicPartitionInfo_t>)>();

  /// @brief Gets the partition in-sync replicas for \p partition.
  ///
  /// @param partition The partition info.
  /// @param cntp is updated with in-sync replicas count.
  ///
  /// @return The in-sync replica nodes.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p partition object.
  ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> rd_kafka_TopicPartitionInfo_isr(
    ffi.Pointer<rd_kafka_TopicPartitionInfo_t> partition,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_TopicPartitionInfo_isr(
      partition,
      cntp,
    );
  }

  late final _rd_kafka_TopicPartitionInfo_isrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_TopicPartitionInfo_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_TopicPartitionInfo_isr');
  late final _rd_kafka_TopicPartitionInfo_isr =
      _rd_kafka_TopicPartitionInfo_isrPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_TopicPartitionInfo_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the partition replicas for \p partition.
  ///
  /// @param partition The partition info.
  /// @param cntp is updated with partition replicas count.
  ///
  /// @return The partition replicas nodes.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p partition object.
  ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>>
      rd_kafka_TopicPartitionInfo_replicas(
    ffi.Pointer<rd_kafka_TopicPartitionInfo_t> partition,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_TopicPartitionInfo_replicas(
      partition,
      cntp,
    );
  }

  late final _rd_kafka_TopicPartitionInfo_replicasPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_TopicPartitionInfo_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_TopicPartitionInfo_replicas');
  late final _rd_kafka_TopicPartitionInfo_replicas =
      _rd_kafka_TopicPartitionInfo_replicasPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_TopicPartitionInfo_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the topic authorized ACL operations for the \p topicdesc topic.
  ///
  /// @param topicdesc The topic description.
  /// @param cntp is updated with authorized ACL operations count.
  ///
  /// @return The topic authorized operations. Is NULL if operations were not
  /// requested.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p topicdesc object.
  ffi.Pointer<ffi.Int32> rd_kafka_TopicDescription_authorized_operations(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_TopicDescription_authorized_operations(
      topicdesc,
      cntp,
    );
  }

  late final _rd_kafka_TopicDescription_authorized_operationsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Int32> Function(
                  ffi.Pointer<rd_kafka_TopicDescription_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_TopicDescription_authorized_operations');
  late final _rd_kafka_TopicDescription_authorized_operations =
      _rd_kafka_TopicDescription_authorized_operationsPtr.asFunction<
          ffi.Pointer<ffi.Int32> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the topic name for the \p topicdesc topic.
  ///
  /// @param topicdesc The topic description.
  ///
  /// @return The topic name.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p topicdesc object.
  ffi.Pointer<ffi.Char> rd_kafka_TopicDescription_name(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
  ) {
    return _rd_kafka_TopicDescription_name(
      topicdesc,
    );
  }

  late final _rd_kafka_TopicDescription_namePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_TopicDescription_t>)>>(
      'rd_kafka_TopicDescription_name');
  late final _rd_kafka_TopicDescription_name =
      _rd_kafka_TopicDescription_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>)>();

  /// @brief Gets the topic id for the \p topicdesc topic.
  ///
  /// @param topicdesc The topic description.
  /// @return The topic id
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p topicdesc object.
  ffi.Pointer<rd_kafka_Uuid_t> rd_kafka_TopicDescription_topic_id(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
  ) {
    return _rd_kafka_TopicDescription_topic_id(
      topicdesc,
    );
  }

  late final _rd_kafka_TopicDescription_topic_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_Uuid_t> Function(
                  ffi.Pointer<rd_kafka_TopicDescription_t>)>>(
      'rd_kafka_TopicDescription_topic_id');
  late final _rd_kafka_TopicDescription_topic_id =
      _rd_kafka_TopicDescription_topic_idPtr.asFunction<
          ffi.Pointer<rd_kafka_Uuid_t> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>)>();

  /// @brief Gets if the \p topicdesc topic is internal.
  ///
  /// @param topicdesc The topic description.
  ///
  /// @return 1 if the topic is internal to Kafka, 0 otherwise.
  int rd_kafka_TopicDescription_is_internal(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
  ) {
    return _rd_kafka_TopicDescription_is_internal(
      topicdesc,
    );
  }

  late final _rd_kafka_TopicDescription_is_internalPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<rd_kafka_TopicDescription_t>)>>(
      'rd_kafka_TopicDescription_is_internal');
  late final _rd_kafka_TopicDescription_is_internal =
      _rd_kafka_TopicDescription_is_internalPtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_TopicDescription_t>)>();

  /// @brief Gets the error for the \p topicdesc topic.
  ///
  /// @param topicdesc The topic description.
  ///
  /// @return The topic description error.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p topicdesc object.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_TopicDescription_error(
    ffi.Pointer<rd_kafka_TopicDescription_t> topicdesc,
  ) {
    return _rd_kafka_TopicDescription_error(
      topicdesc,
    );
  }

  late final _rd_kafka_TopicDescription_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_TopicDescription_t>)>>(
      'rd_kafka_TopicDescription_error');
  late final _rd_kafka_TopicDescription_error =
      _rd_kafka_TopicDescription_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_TopicDescription_t>)>();

  /// @brief Describes the cluster.
  ///
  /// @param rk Client instance.
  /// @param options Optional admin options, or NULL for defaults.
  /// Valid options:
  /// - include_authorized_operations
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DESCRIBECLUSTER_RESULT
  void rd_kafka_DescribeCluster(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeCluster(
      rk,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeClusterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DescribeCluster');
  late final _rd_kafka_DescribeCluster =
      _rd_kafka_DescribeClusterPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Gets the broker nodes for the \p result cluster.
  ///
  /// @param result The result of DescribeCluster.
  /// @param cntp is updated with the count of broker nodes.
  ///
  /// @return An array of broker nodes.
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>>
      rd_kafka_DescribeCluster_result_nodes(
    ffi.Pointer<rd_kafka_DescribeCluster_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeCluster_result_nodes(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeCluster_result_nodesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_DescribeCluster_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DescribeCluster_result_nodes');
  late final _rd_kafka_DescribeCluster_result_nodes =
      _rd_kafka_DescribeCluster_result_nodesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_Node_t>> Function(
              ffi.Pointer<rd_kafka_DescribeCluster_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the authorized ACL operations for the \p result cluster.
  ///
  /// @param result The result of DescribeCluster.
  /// @param cntp is updated with authorized ACL operations count.
  ///
  /// @return The cluster authorized operations. Is NULL if operations were not
  /// requested.
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Int32> rd_kafka_DescribeCluster_result_authorized_operations(
    ffi.Pointer<rd_kafka_DescribeCluster_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeCluster_result_authorized_operations(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeCluster_result_authorized_operationsPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<ffi.Int32> Function(
                      ffi.Pointer<rd_kafka_DescribeCluster_result_t>,
                      ffi.Pointer<ffi.Size>)>>(
          'rd_kafka_DescribeCluster_result_authorized_operations');
  late final _rd_kafka_DescribeCluster_result_authorized_operations =
      _rd_kafka_DescribeCluster_result_authorized_operationsPtr.asFunction<
          ffi.Pointer<ffi.Int32> Function(
              ffi.Pointer<rd_kafka_DescribeCluster_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the current controller for the \p result cluster.
  ///
  /// @param result The result of DescribeCluster.
  ///
  /// @return The cluster current controller.
  ffi.Pointer<rd_kafka_Node_t> rd_kafka_DescribeCluster_result_controller(
    ffi.Pointer<rd_kafka_DescribeCluster_result_t> result,
  ) {
    return _rd_kafka_DescribeCluster_result_controller(
      result,
    );
  }

  late final _rd_kafka_DescribeCluster_result_controllerPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_Node_t> Function(
                  ffi.Pointer<rd_kafka_DescribeCluster_result_t>)>>(
      'rd_kafka_DescribeCluster_result_controller');
  late final _rd_kafka_DescribeCluster_result_controller =
      _rd_kafka_DescribeCluster_result_controllerPtr.asFunction<
          ffi.Pointer<rd_kafka_Node_t> Function(
              ffi.Pointer<rd_kafka_DescribeCluster_result_t>)>();

  /// @brief Gets the cluster id for the \p result cluster.
  ///
  /// @param result The result of DescribeCluster.
  ///
  /// @return The cluster id.
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Char> rd_kafka_DescribeCluster_result_cluster_id(
    ffi.Pointer<rd_kafka_DescribeCluster_result_t> result,
  ) {
    return _rd_kafka_DescribeCluster_result_cluster_id(
      result,
    );
  }

  late final _rd_kafka_DescribeCluster_result_cluster_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_DescribeCluster_result_t>)>>(
      'rd_kafka_DescribeCluster_result_cluster_id');
  late final _rd_kafka_DescribeCluster_result_cluster_id =
      _rd_kafka_DescribeCluster_result_cluster_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_DescribeCluster_result_t>)>();

  /// @brief List the consumer groups available in the cluster.
  ///
  /// @param rk Client instance.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_LISTCONSUMERGROUPS_RESULT
  void rd_kafka_ListConsumerGroups(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_ListConsumerGroups(
      rk,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_ListConsumerGroupsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_ListConsumerGroups');
  late final _rd_kafka_ListConsumerGroups =
      _rd_kafka_ListConsumerGroupsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Gets the group id for the \p grplist group.
  ///
  /// @param grplist The group listing.
  ///
  /// @return The group id.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grplist object.
  ffi.Pointer<ffi.Char> rd_kafka_ConsumerGroupListing_group_id(
    ffi.Pointer<rd_kafka_ConsumerGroupListing_t> grplist,
  ) {
    return _rd_kafka_ConsumerGroupListing_group_id(
      grplist,
    );
  }

  late final _rd_kafka_ConsumerGroupListing_group_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>>(
      'rd_kafka_ConsumerGroupListing_group_id');
  late final _rd_kafka_ConsumerGroupListing_group_id =
      _rd_kafka_ConsumerGroupListing_group_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>();

  /// @brief Is the \p grplist group a simple consumer group.
  ///
  /// @param grplist The group listing.
  ///
  /// @return 1 if the group is a simple consumer group,
  /// else 0.
  int rd_kafka_ConsumerGroupListing_is_simple_consumer_group(
    ffi.Pointer<rd_kafka_ConsumerGroupListing_t> grplist,
  ) {
    return _rd_kafka_ConsumerGroupListing_is_simple_consumer_group(
      grplist,
    );
  }

  late final _rd_kafka_ConsumerGroupListing_is_simple_consumer_groupPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>>(
          'rd_kafka_ConsumerGroupListing_is_simple_consumer_group');
  late final _rd_kafka_ConsumerGroupListing_is_simple_consumer_group =
      _rd_kafka_ConsumerGroupListing_is_simple_consumer_groupPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>();

  /// @brief Gets state for the \p grplist group.
  ///
  /// @param grplist The group listing.
  ///
  /// @return A group state.
  int rd_kafka_ConsumerGroupListing_state(
    ffi.Pointer<rd_kafka_ConsumerGroupListing_t> grplist,
  ) {
    return _rd_kafka_ConsumerGroupListing_state(
      grplist,
    );
  }

  late final _rd_kafka_ConsumerGroupListing_statePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>>(
      'rd_kafka_ConsumerGroupListing_state');
  late final _rd_kafka_ConsumerGroupListing_state =
      _rd_kafka_ConsumerGroupListing_statePtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConsumerGroupListing_t>)>();

  /// @brief Get an array of valid list groups from a ListConsumerGroups result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupListing_t>>
      rd_kafka_ListConsumerGroups_result_valid(
    ffi.Pointer<rd_kafka_ListConsumerGroups_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ListConsumerGroups_result_valid(
      result,
      cntp,
    );
  }

  late final _rd_kafka_ListConsumerGroups_result_validPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupListing_t>> Function(
              ffi.Pointer<rd_kafka_ListConsumerGroups_result_t>,
              ffi.Pointer<
                  ffi.Size>)>>('rd_kafka_ListConsumerGroups_result_valid');
  late final _rd_kafka_ListConsumerGroups_result_valid =
      _rd_kafka_ListConsumerGroups_result_validPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupListing_t>> Function(
              ffi.Pointer<rd_kafka_ListConsumerGroups_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Get an array of errors from a ListConsumerGroups call result.
  ///
  /// The returned errors life-time is the same as the \p result object.
  ///
  /// @param result ListConsumerGroups result.
  /// @param cntp Is updated to the number of elements in the array.
  ///
  /// @return Array of errors in \p result.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_error_t>>
      rd_kafka_ListConsumerGroups_result_errors(
    ffi.Pointer<rd_kafka_ListConsumerGroups_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ListConsumerGroups_result_errors(
      result,
      cntp,
    );
  }

  late final _rd_kafka_ListConsumerGroups_result_errorsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_error_t>> Function(
                  ffi.Pointer<rd_kafka_ListConsumerGroups_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_ListConsumerGroups_result_errors');
  late final _rd_kafka_ListConsumerGroups_result_errors =
      _rd_kafka_ListConsumerGroups_result_errorsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_error_t>> Function(
              ffi.Pointer<rd_kafka_ListConsumerGroups_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Describe groups from cluster as specified by the \p groups
  /// array of size \p groups_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param groups Array of groups to describe.
  /// @param groups_cnt Number of elements in \p groups array.
  /// @param options Optional admin options, or NULL for defaults.
  /// Valid options:
  /// - include_authorized_operations
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DESCRIBECONSUMERGROUPS_RESULT
  void rd_kafka_DescribeConsumerGroups(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<ffi.Char>> groups,
    int groups_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeConsumerGroups(
      rk,
      groups,
      groups_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeConsumerGroupsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<ffi.Char>>,
                  ffi.Size,
                  ffi.Pointer<rd_kafka_AdminOptions_t>,
                  ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_DescribeConsumerGroups');
  late final _rd_kafka_DescribeConsumerGroups =
      _rd_kafka_DescribeConsumerGroupsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of group results from a DescribeConsumerGroups result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>>
      rd_kafka_DescribeConsumerGroups_result_groups(
    ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeConsumerGroups_result_groups(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeConsumerGroups_result_groupsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>> Function(
              ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t>,
              ffi.Pointer<
                  ffi.Size>)>>('rd_kafka_DescribeConsumerGroups_result_groups');
  late final _rd_kafka_DescribeConsumerGroups_result_groups =
      _rd_kafka_DescribeConsumerGroups_result_groupsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>> Function(
              ffi.Pointer<rd_kafka_DescribeConsumerGroups_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets the group id for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return The group id.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<ffi.Char> rd_kafka_ConsumerGroupDescription_group_id(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_group_id(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_group_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_group_id');
  late final _rd_kafka_ConsumerGroupDescription_group_id =
      _rd_kafka_ConsumerGroupDescription_group_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets the error for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return The group description error.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_ConsumerGroupDescription_error(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_error(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_error');
  late final _rd_kafka_ConsumerGroupDescription_error =
      _rd_kafka_ConsumerGroupDescription_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Is the \p grpdesc group a simple consumer group.
  ///
  /// @param grpdesc The group description.
  /// @return 1 if the group is a simple consumer group,
  /// else 0.
  int rd_kafka_ConsumerGroupDescription_is_simple_consumer_group(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_is_simple_consumer_group(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_is_simple_consumer_groupPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
          'rd_kafka_ConsumerGroupDescription_is_simple_consumer_group');
  late final _rd_kafka_ConsumerGroupDescription_is_simple_consumer_group =
      _rd_kafka_ConsumerGroupDescription_is_simple_consumer_groupPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets the partition assignor for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return The partition assignor.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<ffi.Char> rd_kafka_ConsumerGroupDescription_partition_assignor(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_partition_assignor(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_partition_assignorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_partition_assignor');
  late final _rd_kafka_ConsumerGroupDescription_partition_assignor =
      _rd_kafka_ConsumerGroupDescription_partition_assignorPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets the authorized ACL operations for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  /// @param cntp is updated with authorized ACL operations count.
  ///
  /// @return The group authorized operations. Is NULL if operations were not
  /// requested.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<ffi.Int32>
      rd_kafka_ConsumerGroupDescription_authorized_operations(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ConsumerGroupDescription_authorized_operations(
      grpdesc,
      cntp,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_authorized_operationsPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<ffi.Int32> Function(
                      ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>,
                      ffi.Pointer<ffi.Size>)>>(
          'rd_kafka_ConsumerGroupDescription_authorized_operations');
  late final _rd_kafka_ConsumerGroupDescription_authorized_operations =
      _rd_kafka_ConsumerGroupDescription_authorized_operationsPtr.asFunction<
          ffi.Pointer<ffi.Int32> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Gets state for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return A group state.
  int rd_kafka_ConsumerGroupDescription_state(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_state(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_statePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_state');
  late final _rd_kafka_ConsumerGroupDescription_state =
      _rd_kafka_ConsumerGroupDescription_statePtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets the coordinator for the \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return The group coordinator.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<rd_kafka_Node_t> rd_kafka_ConsumerGroupDescription_coordinator(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_coordinator(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_coordinatorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_Node_t> Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_coordinator');
  late final _rd_kafka_ConsumerGroupDescription_coordinator =
      _rd_kafka_ConsumerGroupDescription_coordinatorPtr.asFunction<
          ffi.Pointer<rd_kafka_Node_t> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets the members count of \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  ///
  /// @return The member count.
  int rd_kafka_ConsumerGroupDescription_member_count(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
  ) {
    return _rd_kafka_ConsumerGroupDescription_member_count(
      grpdesc,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_member_countPtr = _lookup<
          ffi.NativeFunction<
              ffi.Size Function(
                  ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>>(
      'rd_kafka_ConsumerGroupDescription_member_count');
  late final _rd_kafka_ConsumerGroupDescription_member_count =
      _rd_kafka_ConsumerGroupDescription_member_countPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>)>();

  /// @brief Gets a member of \p grpdesc group.
  ///
  /// @param grpdesc The group description.
  /// @param idx The member idx.
  ///
  /// @return A member at index \p idx, or NULL if
  /// \p idx is out of range.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p grpdesc object.
  ffi.Pointer<rd_kafka_MemberDescription_t>
      rd_kafka_ConsumerGroupDescription_member(
    ffi.Pointer<rd_kafka_ConsumerGroupDescription_t> grpdesc,
    int idx,
  ) {
    return _rd_kafka_ConsumerGroupDescription_member(
      grpdesc,
      idx,
    );
  }

  late final _rd_kafka_ConsumerGroupDescription_memberPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_MemberDescription_t> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>,
              ffi.Size)>>('rd_kafka_ConsumerGroupDescription_member');
  late final _rd_kafka_ConsumerGroupDescription_member =
      _rd_kafka_ConsumerGroupDescription_memberPtr.asFunction<
          ffi.Pointer<rd_kafka_MemberDescription_t> Function(
              ffi.Pointer<rd_kafka_ConsumerGroupDescription_t>, int)>();

  /// @brief Gets client id of \p member.
  ///
  /// @param member The group member.
  ///
  /// @return The client id.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p member object.
  ffi.Pointer<ffi.Char> rd_kafka_MemberDescription_client_id(
    ffi.Pointer<rd_kafka_MemberDescription_t> member,
  ) {
    return _rd_kafka_MemberDescription_client_id(
      member,
    );
  }

  late final _rd_kafka_MemberDescription_client_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_MemberDescription_t>)>>(
      'rd_kafka_MemberDescription_client_id');
  late final _rd_kafka_MemberDescription_client_id =
      _rd_kafka_MemberDescription_client_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_MemberDescription_t>)>();

  /// @brief Gets group instance id of \p member.
  ///
  /// @param member The group member.
  ///
  /// @return The group instance id, or NULL if not available.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p member object.
  ffi.Pointer<ffi.Char> rd_kafka_MemberDescription_group_instance_id(
    ffi.Pointer<rd_kafka_MemberDescription_t> member,
  ) {
    return _rd_kafka_MemberDescription_group_instance_id(
      member,
    );
  }

  late final _rd_kafka_MemberDescription_group_instance_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_MemberDescription_t>)>>(
      'rd_kafka_MemberDescription_group_instance_id');
  late final _rd_kafka_MemberDescription_group_instance_id =
      _rd_kafka_MemberDescription_group_instance_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_MemberDescription_t>)>();

  /// @brief Gets consumer id of \p member.
  ///
  /// @param member The group member.
  ///
  /// @return The consumer id.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p member object.
  ffi.Pointer<ffi.Char> rd_kafka_MemberDescription_consumer_id(
    ffi.Pointer<rd_kafka_MemberDescription_t> member,
  ) {
    return _rd_kafka_MemberDescription_consumer_id(
      member,
    );
  }

  late final _rd_kafka_MemberDescription_consumer_idPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_MemberDescription_t>)>>(
      'rd_kafka_MemberDescription_consumer_id');
  late final _rd_kafka_MemberDescription_consumer_id =
      _rd_kafka_MemberDescription_consumer_idPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_MemberDescription_t>)>();

  /// @brief Gets host of \p member.
  ///
  /// @param member The group member.
  ///
  /// @return The host.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p member object.
  ffi.Pointer<ffi.Char> rd_kafka_MemberDescription_host(
    ffi.Pointer<rd_kafka_MemberDescription_t> member,
  ) {
    return _rd_kafka_MemberDescription_host(
      member,
    );
  }

  late final _rd_kafka_MemberDescription_hostPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_MemberDescription_t>)>>(
      'rd_kafka_MemberDescription_host');
  late final _rd_kafka_MemberDescription_host =
      _rd_kafka_MemberDescription_hostPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_MemberDescription_t>)>();

  /// @brief Gets assignment of \p member.
  ///
  /// @param member The group member.
  ///
  /// @return The member assignment.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p member object.
  ffi.Pointer<rd_kafka_MemberAssignment_t>
      rd_kafka_MemberDescription_assignment(
    ffi.Pointer<rd_kafka_MemberDescription_t> member,
  ) {
    return _rd_kafka_MemberDescription_assignment(
      member,
    );
  }

  late final _rd_kafka_MemberDescription_assignmentPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_MemberAssignment_t> Function(
                  ffi.Pointer<rd_kafka_MemberDescription_t>)>>(
      'rd_kafka_MemberDescription_assignment');
  late final _rd_kafka_MemberDescription_assignment =
      _rd_kafka_MemberDescription_assignmentPtr.asFunction<
          ffi.Pointer<rd_kafka_MemberAssignment_t> Function(
              ffi.Pointer<rd_kafka_MemberDescription_t>)>();

  /// @brief Gets assigned partitions of a member \p assignment.
  ///
  /// @param assignment The group member assignment.
  ///
  /// @return The assigned partitions.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p assignment object.
  ffi.Pointer<rd_kafka_topic_partition_list_t>
      rd_kafka_MemberAssignment_partitions(
    ffi.Pointer<rd_kafka_MemberAssignment_t> assignment,
  ) {
    return _rd_kafka_MemberAssignment_partitions(
      assignment,
    );
  }

  late final _rd_kafka_MemberAssignment_partitionsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
                  ffi.Pointer<rd_kafka_MemberAssignment_t>)>>(
      'rd_kafka_MemberAssignment_partitions');
  late final _rd_kafka_MemberAssignment_partitions =
      _rd_kafka_MemberAssignment_partitionsPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_list_t> Function(
              ffi.Pointer<rd_kafka_MemberAssignment_t>)>();

  /// @brief Create a new DeleteGroup object. This object is later passed to
  /// rd_kafka_DeleteGroups().
  ///
  /// @param group Name of group to delete.
  ///
  /// @returns a new allocated DeleteGroup object.
  /// Use rd_kafka_DeleteGroup_destroy() to free object when done.
  ffi.Pointer<rd_kafka_DeleteGroup_t> rd_kafka_DeleteGroup_new(
    ffi.Pointer<ffi.Char> group,
  ) {
    return _rd_kafka_DeleteGroup_new(
      group,
    );
  }

  late final _rd_kafka_DeleteGroup_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_DeleteGroup_t> Function(
              ffi.Pointer<ffi.Char>)>>('rd_kafka_DeleteGroup_new');
  late final _rd_kafka_DeleteGroup_new =
      _rd_kafka_DeleteGroup_newPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteGroup_t> Function(
              ffi.Pointer<ffi.Char>)>();

  /// @brief Destroy and free a DeleteGroup object previously created with
  /// rd_kafka_DeleteGroup_new()
  void rd_kafka_DeleteGroup_destroy(
    ffi.Pointer<rd_kafka_DeleteGroup_t> del_group,
  ) {
    return _rd_kafka_DeleteGroup_destroy(
      del_group,
    );
  }

  late final _rd_kafka_DeleteGroup_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_DeleteGroup_t>)>>(
      'rd_kafka_DeleteGroup_destroy');
  late final _rd_kafka_DeleteGroup_destroy = _rd_kafka_DeleteGroup_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_DeleteGroup_t>)>();

  /// @brief Helper function to destroy all DeleteGroup objects in
  /// the \p del_groups array (of \p del_group_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_DeleteGroup_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>> del_groups,
    int del_group_cnt,
  ) {
    return _rd_kafka_DeleteGroup_destroy_array(
      del_groups,
      del_group_cnt,
    );
  }

  late final _rd_kafka_DeleteGroup_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>>,
              ffi.Size)>>('rd_kafka_DeleteGroup_destroy_array');
  late final _rd_kafka_DeleteGroup_destroy_array =
      _rd_kafka_DeleteGroup_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>>, int)>();

  /// @brief Delete groups from cluster as specified by the \p del_groups
  /// array of size \p del_group_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param del_groups Array of groups to delete.
  /// @param del_group_cnt Number of elements in \p del_groups array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DELETEGROUPS_RESULT
  ///
  /// @remark This function in called deleteConsumerGroups in the Java client.
  void rd_kafka_DeleteGroups(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>> del_groups,
    int del_group_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DeleteGroups(
      rk,
      del_groups,
      del_group_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DeleteGroupsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DeleteGroups');
  late final _rd_kafka_DeleteGroups = _rd_kafka_DeleteGroupsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_DeleteGroup_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of group results from a DeleteGroups result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>>
      rd_kafka_DeleteGroups_result_groups(
    ffi.Pointer<rd_kafka_DeleteGroups_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DeleteGroups_result_groups(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DeleteGroups_result_groupsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
              ffi.Pointer<rd_kafka_DeleteGroups_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DeleteGroups_result_groups');
  late final _rd_kafka_DeleteGroups_result_groups =
      _rd_kafka_DeleteGroups_result_groupsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
              ffi.Pointer<rd_kafka_DeleteGroups_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new ListConsumerGroupOffsets object.
  /// This object is later passed to rd_kafka_ListConsumerGroupOffsets().
  ///
  /// @param group_id Consumer group id.
  /// @param partitions Partitions to list committed offsets for.
  /// Only the topic and partition fields are used.
  ///
  /// @returns a new allocated ListConsumerGroupOffsets object.
  /// Use rd_kafka_ListConsumerGroupOffsets_destroy() to free
  /// object when done.
  ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>
      rd_kafka_ListConsumerGroupOffsets_new(
    ffi.Pointer<ffi.Char> group_id,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_ListConsumerGroupOffsets_new(
      group_id,
      partitions,
    );
  }

  late final _rd_kafka_ListConsumerGroupOffsets_newPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t> Function(
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_ListConsumerGroupOffsets_new');
  late final _rd_kafka_ListConsumerGroupOffsets_new =
      _rd_kafka_ListConsumerGroupOffsets_newPtr.asFunction<
          ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Destroy and free a ListConsumerGroupOffsets object previously
  /// created with rd_kafka_ListConsumerGroupOffsets_new()
  void rd_kafka_ListConsumerGroupOffsets_destroy(
    ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t> list_grpoffsets,
  ) {
    return _rd_kafka_ListConsumerGroupOffsets_destroy(
      list_grpoffsets,
    );
  }

  late final _rd_kafka_ListConsumerGroupOffsets_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>)>>(
      'rd_kafka_ListConsumerGroupOffsets_destroy');
  late final _rd_kafka_ListConsumerGroupOffsets_destroy =
      _rd_kafka_ListConsumerGroupOffsets_destroyPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>)>();

  /// @brief Helper function to destroy all ListConsumerGroupOffsets objects in
  /// the \p list_grpoffsets array (of \p list_grpoffsets_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_ListConsumerGroupOffsets_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>
        list_grpoffsets,
    int list_grpoffset_cnt,
  ) {
    return _rd_kafka_ListConsumerGroupOffsets_destroy_array(
      list_grpoffsets,
      list_grpoffset_cnt,
    );
  }

  late final _rd_kafka_ListConsumerGroupOffsets_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>,
              ffi.Size)>>('rd_kafka_ListConsumerGroupOffsets_destroy_array');
  late final _rd_kafka_ListConsumerGroupOffsets_destroy_array =
      _rd_kafka_ListConsumerGroupOffsets_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>,
              int)>();

  /// @brief List committed offsets for a set of partitions in a consumer
  /// group.
  ///
  /// @param rk Client instance.
  /// @param list_grpoffsets Array of group committed offsets to list.
  /// MUST only be one single element.
  /// @param list_grpoffsets_cnt Number of elements in \p list_grpoffsets array.
  /// MUST always be 1.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_LISTCONSUMERGROUPOFFSETS_RESULT
  ///
  /// @remark The current implementation only supports one group per invocation.
  void rd_kafka_ListConsumerGroupOffsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>
        list_grpoffsets,
    int list_grpoffsets_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_ListConsumerGroupOffsets(
      rk,
      list_grpoffsets,
      list_grpoffsets_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_ListConsumerGroupOffsetsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>,
                  ffi.Size,
                  ffi.Pointer<rd_kafka_AdminOptions_t>,
                  ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_ListConsumerGroupOffsets');
  late final _rd_kafka_ListConsumerGroupOffsets =
      _rd_kafka_ListConsumerGroupOffsetsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of results from a ListConsumerGroupOffsets result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>>
      rd_kafka_ListConsumerGroupOffsets_result_groups(
    ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ListConsumerGroupOffsets_result_groups(
      result,
      cntp,
    );
  }

  late final _rd_kafka_ListConsumerGroupOffsets_result_groupsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
                  ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_ListConsumerGroupOffsets_result_groups');
  late final _rd_kafka_ListConsumerGroupOffsets_result_groups =
      _rd_kafka_ListConsumerGroupOffsets_result_groupsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
              ffi.Pointer<rd_kafka_ListConsumerGroupOffsets_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new AlterConsumerGroupOffsets object.
  /// This object is later passed to rd_kafka_AlterConsumerGroupOffsets().
  ///
  /// @param group_id Consumer group id.
  /// @param partitions Partitions to alter committed offsets for.
  /// Only the topic and partition fields are used.
  ///
  /// @returns a new allocated AlterConsumerGroupOffsets object.
  /// Use rd_kafka_AlterConsumerGroupOffsets_destroy() to free
  /// object when done.
  ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>
      rd_kafka_AlterConsumerGroupOffsets_new(
    ffi.Pointer<ffi.Char> group_id,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_AlterConsumerGroupOffsets_new(
      group_id,
      partitions,
    );
  }

  late final _rd_kafka_AlterConsumerGroupOffsets_newPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t> Function(
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_AlterConsumerGroupOffsets_new');
  late final _rd_kafka_AlterConsumerGroupOffsets_new =
      _rd_kafka_AlterConsumerGroupOffsets_newPtr.asFunction<
          ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Destroy and free a AlterConsumerGroupOffsets object previously
  /// created with rd_kafka_AlterConsumerGroupOffsets_new()
  void rd_kafka_AlterConsumerGroupOffsets_destroy(
    ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t> alter_grpoffsets,
  ) {
    return _rd_kafka_AlterConsumerGroupOffsets_destroy(
      alter_grpoffsets,
    );
  }

  late final _rd_kafka_AlterConsumerGroupOffsets_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>)>>(
      'rd_kafka_AlterConsumerGroupOffsets_destroy');
  late final _rd_kafka_AlterConsumerGroupOffsets_destroy =
      _rd_kafka_AlterConsumerGroupOffsets_destroyPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>)>();

  /// @brief Helper function to destroy all AlterConsumerGroupOffsets objects in
  /// the \p alter_grpoffsets array (of \p alter_grpoffsets_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_AlterConsumerGroupOffsets_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>
        alter_grpoffsets,
    int alter_grpoffset_cnt,
  ) {
    return _rd_kafka_AlterConsumerGroupOffsets_destroy_array(
      alter_grpoffsets,
      alter_grpoffset_cnt,
    );
  }

  late final _rd_kafka_AlterConsumerGroupOffsets_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>,
              ffi.Size)>>('rd_kafka_AlterConsumerGroupOffsets_destroy_array');
  late final _rd_kafka_AlterConsumerGroupOffsets_destroy_array =
      _rd_kafka_AlterConsumerGroupOffsets_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>,
              int)>();

  /// @brief Alter committed offsets for a set of partitions in a consumer
  /// group. This will succeed at the partition level only if the group
  /// is not actively subscribed to the corresponding topic.
  ///
  /// @param rk Client instance.
  /// @param alter_grpoffsets Array of group committed offsets to alter.
  /// MUST only be one single element.
  /// @param alter_grpoffsets_cnt Number of elements in \p alter_grpoffsets array.
  /// MUST always be 1.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_ALTERCONSUMERGROUPOFFSETS_RESULT
  ///
  /// @remark The current implementation only supports one group per invocation.
  void rd_kafka_AlterConsumerGroupOffsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>
        alter_grpoffsets,
    int alter_grpoffsets_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_AlterConsumerGroupOffsets(
      rk,
      alter_grpoffsets,
      alter_grpoffsets_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_AlterConsumerGroupOffsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<
                  rd_kafka_queue_t>)>>('rd_kafka_AlterConsumerGroupOffsets');
  late final _rd_kafka_AlterConsumerGroupOffsets =
      _rd_kafka_AlterConsumerGroupOffsetsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of results from a AlterConsumerGroupOffsets result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ///
  /// @remark The lifetime of the returned memory is the same
  /// as the lifetime of the \p result object.
  ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>>
      rd_kafka_AlterConsumerGroupOffsets_result_groups(
    ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_AlterConsumerGroupOffsets_result_groups(
      result,
      cntp,
    );
  }

  late final _rd_kafka_AlterConsumerGroupOffsets_result_groupsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
                  ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_AlterConsumerGroupOffsets_result_groups');
  late final _rd_kafka_AlterConsumerGroupOffsets_result_groups =
      _rd_kafka_AlterConsumerGroupOffsets_result_groupsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
              ffi.Pointer<rd_kafka_AlterConsumerGroupOffsets_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create a new DeleteConsumerGroupOffsets object.
  /// This object is later passed to rd_kafka_DeleteConsumerGroupOffsets().
  ///
  /// @param group Consumer group id.
  /// @param partitions Partitions to delete committed offsets for.
  /// Only the topic and partition fields are used.
  ///
  /// @returns a new allocated DeleteConsumerGroupOffsets object.
  /// Use rd_kafka_DeleteConsumerGroupOffsets_destroy() to free
  /// object when done.
  ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>
      rd_kafka_DeleteConsumerGroupOffsets_new(
    ffi.Pointer<ffi.Char> group,
    ffi.Pointer<rd_kafka_topic_partition_list_t> partitions,
  ) {
    return _rd_kafka_DeleteConsumerGroupOffsets_new(
      group,
      partitions,
    );
  }

  late final _rd_kafka_DeleteConsumerGroupOffsets_newPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t> Function(
                  ffi.Pointer<ffi.Char>,
                  ffi.Pointer<rd_kafka_topic_partition_list_t>)>>(
      'rd_kafka_DeleteConsumerGroupOffsets_new');
  late final _rd_kafka_DeleteConsumerGroupOffsets_new =
      _rd_kafka_DeleteConsumerGroupOffsets_newPtr.asFunction<
          ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>)>();

  /// @brief Destroy and free a DeleteConsumerGroupOffsets object previously
  /// created with rd_kafka_DeleteConsumerGroupOffsets_new()
  void rd_kafka_DeleteConsumerGroupOffsets_destroy(
    ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t> del_grpoffsets,
  ) {
    return _rd_kafka_DeleteConsumerGroupOffsets_destroy(
      del_grpoffsets,
    );
  }

  late final _rd_kafka_DeleteConsumerGroupOffsets_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>)>>(
      'rd_kafka_DeleteConsumerGroupOffsets_destroy');
  late final _rd_kafka_DeleteConsumerGroupOffsets_destroy =
      _rd_kafka_DeleteConsumerGroupOffsets_destroyPtr.asFunction<
          void Function(ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>)>();

  /// @brief Helper function to destroy all DeleteConsumerGroupOffsets objects in
  /// the \p del_grpoffsets array (of \p del_grpoffsets_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_DeleteConsumerGroupOffsets_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>
        del_grpoffsets,
    int del_grpoffset_cnt,
  ) {
    return _rd_kafka_DeleteConsumerGroupOffsets_destroy_array(
      del_grpoffsets,
      del_grpoffset_cnt,
    );
  }

  late final _rd_kafka_DeleteConsumerGroupOffsets_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>,
              ffi.Size)>>('rd_kafka_DeleteConsumerGroupOffsets_destroy_array');
  late final _rd_kafka_DeleteConsumerGroupOffsets_destroy_array =
      _rd_kafka_DeleteConsumerGroupOffsets_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>,
              int)>();

  /// @brief Delete committed offsets for a set of partitions in a consumer
  /// group. This will succeed at the partition level only if the group
  /// is not actively subscribed to the corresponding topic.
  ///
  /// @param rk Client instance.
  /// @param del_grpoffsets Array of group committed offsets to delete.
  /// MUST only be one single element.
  /// @param del_grpoffsets_cnt Number of elements in \p del_grpoffsets array.
  /// MUST always be 1.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DELETECONSUMERGROUPOFFSETS_RESULT
  ///
  /// @remark The current implementation only supports one group per invocation.
  void rd_kafka_DeleteConsumerGroupOffsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>
        del_grpoffsets,
    int del_grpoffsets_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DeleteConsumerGroupOffsets(
      rk,
      del_grpoffsets,
      del_grpoffsets_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DeleteConsumerGroupOffsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<
                  rd_kafka_queue_t>)>>('rd_kafka_DeleteConsumerGroupOffsets');
  late final _rd_kafka_DeleteConsumerGroupOffsets =
      _rd_kafka_DeleteConsumerGroupOffsetsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of results from a DeleteConsumerGroupOffsets result.
  ///
  /// The returned groups life-time is the same as the \p result object.
  ///
  /// @param result Result to get group results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>>
      rd_kafka_DeleteConsumerGroupOffsets_result_groups(
    ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DeleteConsumerGroupOffsets_result_groups(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DeleteConsumerGroupOffsets_result_groupsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
                  ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_DeleteConsumerGroupOffsets_result_groups');
  late final _rd_kafka_DeleteConsumerGroupOffsets_result_groups =
      _rd_kafka_DeleteConsumerGroupOffsets_result_groupsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_group_result_t>> Function(
              ffi.Pointer<rd_kafka_DeleteConsumerGroupOffsets_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Returns the topic partition of the passed \p result_info.
  ffi.Pointer<rd_kafka_topic_partition_t>
      rd_kafka_ListOffsetsResultInfo_topic_partition(
    ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t> result_info,
  ) {
    return _rd_kafka_ListOffsetsResultInfo_topic_partition(
      result_info,
    );
  }

  late final _rd_kafka_ListOffsetsResultInfo_topic_partitionPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_topic_partition_t> Function(
                  ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>)>>(
      'rd_kafka_ListOffsetsResultInfo_topic_partition');
  late final _rd_kafka_ListOffsetsResultInfo_topic_partition =
      _rd_kafka_ListOffsetsResultInfo_topic_partitionPtr.asFunction<
          ffi.Pointer<rd_kafka_topic_partition_t> Function(
              ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>)>();

  /// @brief Returns the timestamp corresponding to the offset in \p result_info.
  int rd_kafka_ListOffsetsResultInfo_timestamp(
    ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t> result_info,
  ) {
    return _rd_kafka_ListOffsetsResultInfo_timestamp(
      result_info,
    );
  }

  late final _rd_kafka_ListOffsetsResultInfo_timestampPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int64 Function(
                  ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>)>>(
      'rd_kafka_ListOffsetsResultInfo_timestamp');
  late final _rd_kafka_ListOffsetsResultInfo_timestamp =
      _rd_kafka_ListOffsetsResultInfo_timestampPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>)>();

  /// @brief Returns the array of ListOffsetsResultInfo in \p result
  /// and populates the size of the array in \p cntp.
  ffi.Pointer<ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>>
      rd_kafka_ListOffsets_result_infos(
    ffi.Pointer<rd_kafka_ListOffsets_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_ListOffsets_result_infos(
      result,
      cntp,
    );
  }

  late final _rd_kafka_ListOffsets_result_infosPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>> Function(
              ffi.Pointer<rd_kafka_ListOffsets_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_ListOffsets_result_infos');
  late final _rd_kafka_ListOffsets_result_infos =
      _rd_kafka_ListOffsets_result_infosPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_ListOffsetsResultInfo_t>> Function(
              ffi.Pointer<rd_kafka_ListOffsets_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief List offsets for the specified \p topic_partitions.
  /// This operation enables to find the beginning offset,
  /// end offset as well as the offset matching a timestamp in partitions
  /// or the offset with max timestamp.
  ///
  /// @param rk Client instance.
  /// @param topic_partitions topic_partition_list_t with the partitions and
  /// offsets to list. Each topic partition offset can be
  /// a value of the `rd_kafka_OffsetSpec_t` enum or
  /// a non-negative value, representing a timestamp,
  /// to query for the first offset after the
  /// given timestamp.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_isolation_level() - default  \c
  /// RD_KAFKA_ISOLATION_LEVEL_READ_UNCOMMITTED
  /// - rd_kafka_AdminOptions_set_request_timeout() - default socket.timeout.ms
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_LISTOFFSETS_RESULT
  void rd_kafka_ListOffsets(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> topic_partitions,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_ListOffsets(
      rk,
      topic_partitions,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_ListOffsetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_ListOffsets');
  late final _rd_kafka_ListOffsets = _rd_kafka_ListOffsetsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_topic_partition_list_t>,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Returns the mechanism of a given ScramCredentialInfo.
  int rd_kafka_ScramCredentialInfo_mechanism(
    ffi.Pointer<rd_kafka_ScramCredentialInfo_t> scram_credential_info,
  ) {
    return _rd_kafka_ScramCredentialInfo_mechanism(
      scram_credential_info,
    );
  }

  late final _rd_kafka_ScramCredentialInfo_mechanismPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_ScramCredentialInfo_t>)>>(
      'rd_kafka_ScramCredentialInfo_mechanism');
  late final _rd_kafka_ScramCredentialInfo_mechanism =
      _rd_kafka_ScramCredentialInfo_mechanismPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ScramCredentialInfo_t>)>();

  /// @brief Returns the iterations of a given ScramCredentialInfo.
  int rd_kafka_ScramCredentialInfo_iterations(
    ffi.Pointer<rd_kafka_ScramCredentialInfo_t> scram_credential_info,
  ) {
    return _rd_kafka_ScramCredentialInfo_iterations(
      scram_credential_info,
    );
  }

  late final _rd_kafka_ScramCredentialInfo_iterationsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_ScramCredentialInfo_t>)>>(
      'rd_kafka_ScramCredentialInfo_iterations');
  late final _rd_kafka_ScramCredentialInfo_iterations =
      _rd_kafka_ScramCredentialInfo_iterationsPtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_ScramCredentialInfo_t>)>();

  /// @brief Returns the username of a UserScramCredentialsDescription.
  ffi.Pointer<ffi.Char> rd_kafka_UserScramCredentialsDescription_user(
    ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t> description,
  ) {
    return _rd_kafka_UserScramCredentialsDescription_user(
      description,
    );
  }

  late final _rd_kafka_UserScramCredentialsDescription_userPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>)>>(
      'rd_kafka_UserScramCredentialsDescription_user');
  late final _rd_kafka_UserScramCredentialsDescription_user =
      _rd_kafka_UserScramCredentialsDescription_userPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>)>();

  /// @brief Returns the error associated with a UserScramCredentialsDescription.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_UserScramCredentialsDescription_error(
    ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t> description,
  ) {
    return _rd_kafka_UserScramCredentialsDescription_error(
      description,
    );
  }

  late final _rd_kafka_UserScramCredentialsDescription_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>)>>(
      'rd_kafka_UserScramCredentialsDescription_error');
  late final _rd_kafka_UserScramCredentialsDescription_error =
      _rd_kafka_UserScramCredentialsDescription_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>)>();

  /// @brief Returns the count of ScramCredentialInfos of a
  /// UserScramCredentialsDescription.
  int rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_count(
    ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t> description,
  ) {
    return _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_count(
      description,
    );
  }

  late final _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_countPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Size Function(
                      ffi.Pointer<
                          rd_kafka_UserScramCredentialsDescription_t>)>>(
          'rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_count');
  late final _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_count =
      _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo_countPtr
          .asFunction<
              int Function(
                  ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>)>();

  /// @brief Returns the ScramCredentialInfo at index idx of
  /// UserScramCredentialsDescription.
  ffi.Pointer<rd_kafka_ScramCredentialInfo_t>
      rd_kafka_UserScramCredentialsDescription_scramcredentialinfo(
    ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t> description,
    int idx,
  ) {
    return _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo(
      description,
      idx,
    );
  }

  late final _rd_kafka_UserScramCredentialsDescription_scramcredentialinfoPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<rd_kafka_ScramCredentialInfo_t> Function(
                      ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>,
                      ffi.Size)>>(
          'rd_kafka_UserScramCredentialsDescription_scramcredentialinfo');
  late final _rd_kafka_UserScramCredentialsDescription_scramcredentialinfo =
      _rd_kafka_UserScramCredentialsDescription_scramcredentialinfoPtr
          .asFunction<
              ffi.Pointer<rd_kafka_ScramCredentialInfo_t> Function(
                  ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>,
                  int)>();

  /// @brief Get an array of descriptions from a DescribeUserScramCredentials
  /// result.
  ///
  /// The returned value life-time is the same as the \p result object.
  ///
  /// @param result Result to get descriptions from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>>
      rd_kafka_DescribeUserScramCredentials_result_descriptions(
    ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeUserScramCredentials_result_descriptions(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeUserScramCredentials_result_descriptionsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>> Function(
                  ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_DescribeUserScramCredentials_result_descriptions');
  late final _rd_kafka_DescribeUserScramCredentials_result_descriptions =
      _rd_kafka_DescribeUserScramCredentials_result_descriptionsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_UserScramCredentialsDescription_t>> Function(
              ffi.Pointer<rd_kafka_DescribeUserScramCredentials_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Describe SASL/SCRAM credentials.
  /// This operation is supported by brokers with version 2.7.0 or higher.
  ///
  /// @param rk Client instance.
  /// @param users The users for which credentials are to be described.
  /// All users' credentials are described if NULL.
  /// @param user_cnt Number of elements in \p users array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  void rd_kafka_DescribeUserScramCredentials(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<ffi.Char>> users,
    int user_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeUserScramCredentials(
      rk,
      users,
      user_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeUserScramCredentialsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<ffi.Pointer<ffi.Char>>,
                  ffi.Size,
                  ffi.Pointer<rd_kafka_AdminOptions_t>,
                  ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_DescribeUserScramCredentials');
  late final _rd_kafka_DescribeUserScramCredentials =
      _rd_kafka_DescribeUserScramCredentialsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Allocates a new UserScramCredentialUpsertion given its fields.
  /// If salt isn't given a 64 B salt is generated using OpenSSL
  /// RAND_priv_bytes, if available.
  ///
  /// @param username The username (not empty).
  /// @param mechanism SASL/SCRAM mechanism.
  /// @param iterations SASL/SCRAM iterations.
  /// @param password Password bytes (not empty).
  /// @param password_size Size of \p password (greater than 0).
  /// @param salt Salt bytes (optional).
  /// @param salt_size Size of \p salt (optional).
  ///
  /// @remark A random salt is generated, when NULL, only if OpenSSL >= 1.1.1.
  /// Otherwise it's a required param.
  ///
  /// @return A newly created instance of rd_kafka_UserScramCredentialAlteration_t.
  /// Ownership belongs to the caller, use
  /// rd_kafka_UserScramCredentialAlteration_destroy to destroy.
  ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>
      rd_kafka_UserScramCredentialUpsertion_new(
    ffi.Pointer<ffi.Char> username,
    int mechanism,
    int iterations,
    ffi.Pointer<ffi.UnsignedChar> password,
    int password_size,
    ffi.Pointer<ffi.UnsignedChar> salt,
    int salt_size,
  ) {
    return _rd_kafka_UserScramCredentialUpsertion_new(
      username,
      mechanism,
      iterations,
      password,
      password_size,
      salt,
      salt_size,
    );
  }

  late final _rd_kafka_UserScramCredentialUpsertion_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.UnsignedChar>,
              ffi.Size,
              ffi.Pointer<ffi.UnsignedChar>,
              ffi.Size)>>('rd_kafka_UserScramCredentialUpsertion_new');
  late final _rd_kafka_UserScramCredentialUpsertion_new =
      _rd_kafka_UserScramCredentialUpsertion_newPtr.asFunction<
          ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t> Function(
              ffi.Pointer<ffi.Char>,
              int,
              int,
              ffi.Pointer<ffi.UnsignedChar>,
              int,
              ffi.Pointer<ffi.UnsignedChar>,
              int)>();

  /// @brief Allocates a new UserScramCredentialDeletion given its fields.
  ///
  /// @param username The username (not empty).
  /// @param mechanism SASL/SCRAM mechanism.
  /// @return A newly created instance of rd_kafka_UserScramCredentialAlteration_t.
  /// Ownership belongs to the caller, use
  /// rd_kafka_UserScramCredentialAlteration_destroy to destroy.
  ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>
      rd_kafka_UserScramCredentialDeletion_new(
    ffi.Pointer<ffi.Char> username,
    int mechanism,
  ) {
    return _rd_kafka_UserScramCredentialDeletion_new(
      username,
      mechanism,
    );
  }

  late final _rd_kafka_UserScramCredentialDeletion_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t> Function(
              ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('rd_kafka_UserScramCredentialDeletion_new');
  late final _rd_kafka_UserScramCredentialDeletion_new =
      _rd_kafka_UserScramCredentialDeletion_newPtr.asFunction<
          ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t> Function(
              ffi.Pointer<ffi.Char>, int)>();

  /// @brief Destroys a UserScramCredentialAlteration given its pointer
  void rd_kafka_UserScramCredentialAlteration_destroy(
    ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t> alteration,
  ) {
    return _rd_kafka_UserScramCredentialAlteration_destroy(
      alteration,
    );
  }

  late final _rd_kafka_UserScramCredentialAlteration_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>)>>(
      'rd_kafka_UserScramCredentialAlteration_destroy');
  late final _rd_kafka_UserScramCredentialAlteration_destroy =
      _rd_kafka_UserScramCredentialAlteration_destroyPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>)>();

  /// @brief Destroys an array of UserScramCredentialAlteration
  void rd_kafka_UserScramCredentialAlteration_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>
        alterations,
    int alteration_cnt,
  ) {
    return _rd_kafka_UserScramCredentialAlteration_destroy_array(
      alterations,
      alteration_cnt,
    );
  }

  late final _rd_kafka_UserScramCredentialAlteration_destroy_arrayPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<
                      ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>,
                  ffi.Size)>>(
      'rd_kafka_UserScramCredentialAlteration_destroy_array');
  late final _rd_kafka_UserScramCredentialAlteration_destroy_array =
      _rd_kafka_UserScramCredentialAlteration_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<
                  ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>,
              int)>();

  /// @brief Returns the username for a
  /// rd_kafka_AlterUserScramCredentials_result_response.
  ffi.Pointer<ffi.Char> rd_kafka_AlterUserScramCredentials_result_response_user(
    ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_response_t> response,
  ) {
    return _rd_kafka_AlterUserScramCredentials_result_response_user(
      response,
    );
  }

  late final _rd_kafka_AlterUserScramCredentials_result_response_userPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<
                      rd_kafka_AlterUserScramCredentials_result_response_t>)>>(
      'rd_kafka_AlterUserScramCredentials_result_response_user');
  late final _rd_kafka_AlterUserScramCredentials_result_response_user =
      _rd_kafka_AlterUserScramCredentials_result_response_userPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<
                  rd_kafka_AlterUserScramCredentials_result_response_t>)>();

  /// @brief Returns the error of a
  /// rd_kafka_AlterUserScramCredentials_result_response.
  ffi.Pointer<rd_kafka_error_t>
      rd_kafka_AlterUserScramCredentials_result_response_error(
    ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_response_t> response,
  ) {
    return _rd_kafka_AlterUserScramCredentials_result_response_error(
      response,
    );
  }

  late final _rd_kafka_AlterUserScramCredentials_result_response_errorPtr =
      _lookup<
              ffi.NativeFunction<
                  ffi.Pointer<rd_kafka_error_t> Function(
                      ffi.Pointer<
                          rd_kafka_AlterUserScramCredentials_result_response_t>)>>(
          'rd_kafka_AlterUserScramCredentials_result_response_error');
  late final _rd_kafka_AlterUserScramCredentials_result_response_error =
      _rd_kafka_AlterUserScramCredentials_result_response_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<
                  rd_kafka_AlterUserScramCredentials_result_response_t>)>();

  /// @brief Get an array of responses from a AlterUserScramCredentials result.
  ///
  /// The returned value life-time is the same as the \p result object.
  ///
  /// @param result Result to get responses from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_response_t>>
      rd_kafka_AlterUserScramCredentials_result_responses(
    ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_AlterUserScramCredentials_result_responses(
      result,
      cntp,
    );
  }

  late final _rd_kafka_AlterUserScramCredentials_result_responsesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_response_t>> Function(
              ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t>,
              ffi.Pointer<
                  ffi
                  .Size>)>>('rd_kafka_AlterUserScramCredentials_result_responses');
  late final _rd_kafka_AlterUserScramCredentials_result_responses =
      _rd_kafka_AlterUserScramCredentials_result_responsesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_response_t>> Function(
              ffi.Pointer<rd_kafka_AlterUserScramCredentials_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Alter SASL/SCRAM credentials.
  /// This operation is supported by brokers with version 2.7.0 or higher.
  ///
  /// @remark For upsertions to be processed, librdkfka must be build with
  /// OpenSSL support. It's needed to calculate the HMAC.
  ///
  /// @param rk Client instance.
  /// @param alterations The alterations to be applied.
  /// @param alteration_cnt Number of elements in \p alterations array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  void rd_kafka_AlterUserScramCredentials(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>
        alterations,
    int alteration_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_AlterUserScramCredentials(
      rk,
      alterations,
      alteration_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_AlterUserScramCredentialsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(
                  ffi.Pointer<rd_kafka_t>,
                  ffi.Pointer<
                      ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>,
                  ffi.Size,
                  ffi.Pointer<rd_kafka_AdminOptions_t>,
                  ffi.Pointer<rd_kafka_queue_t>)>>(
      'rd_kafka_AlterUserScramCredentials');
  late final _rd_kafka_AlterUserScramCredentials =
      _rd_kafka_AlterUserScramCredentialsPtr.asFunction<
          void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<
                  ffi.Pointer<rd_kafka_UserScramCredentialAlteration_t>>,
              int,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>();

  /// @returns the error object for the given acl result, or NULL on success.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_acl_result_error(
    ffi.Pointer<rd_kafka_acl_result_t> aclres,
  ) {
    return _rd_kafka_acl_result_error(
      aclres,
    );
  }

  late final _rd_kafka_acl_result_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_acl_result_t>)>>(
      'rd_kafka_acl_result_error');
  late final _rd_kafka_acl_result_error =
      _rd_kafka_acl_result_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_acl_result_t>)>();

  /// @returns a string representation of the \p acl_operation
  ffi.Pointer<ffi.Char> rd_kafka_AclOperation_name(
    int acl_operation,
  ) {
    return _rd_kafka_AclOperation_name(
      acl_operation,
    );
  }

  late final _rd_kafka_AclOperation_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_AclOperation_name');
  late final _rd_kafka_AclOperation_name = _rd_kafka_AclOperation_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @returns a string representation of the \p acl_permission_type
  ffi.Pointer<ffi.Char> rd_kafka_AclPermissionType_name(
    int acl_permission_type,
  ) {
    return _rd_kafka_AclPermissionType_name(
      acl_permission_type,
    );
  }

  late final _rd_kafka_AclPermissionType_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'rd_kafka_AclPermissionType_name');
  late final _rd_kafka_AclPermissionType_name =
      _rd_kafka_AclPermissionType_namePtr
          .asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// @brief Create a new AclBinding object. This object is later passed to
  /// rd_kafka_CreateAcls().
  ///
  /// @param restype The ResourceType.
  /// @param name The resource name.
  /// @param resource_pattern_type The pattern type.
  /// @param principal A principal, following the kafka specification.
  /// @param host An hostname or ip.
  /// @param operation A Kafka operation.
  /// @param permission_type A Kafka permission type.
  /// @param errstr An error string for returning errors or NULL to not use it.
  /// @param errstr_size The \p errstr size or 0 to not use it.
  ///
  /// @returns a new allocated AclBinding object, or NULL if the input parameters
  /// are invalid.
  /// Use rd_kafka_AclBinding_destroy() to free object when done.
  ffi.Pointer<rd_kafka_AclBinding_t> rd_kafka_AclBinding_new(
    int restype,
    ffi.Pointer<ffi.Char> name,
    int resource_pattern_type,
    ffi.Pointer<ffi.Char> principal,
    ffi.Pointer<ffi.Char> host,
    int operation,
    int permission_type,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AclBinding_new(
      restype,
      name,
      resource_pattern_type,
      principal,
      host,
      operation,
      permission_type,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AclBinding_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_AclBinding_t> Function(
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AclBinding_new');
  late final _rd_kafka_AclBinding_new = _rd_kafka_AclBinding_newPtr.asFunction<
      ffi.Pointer<rd_kafka_AclBinding_t> Function(
          int,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>,
          int,
          int,
          ffi.Pointer<ffi.Char>,
          int)>();

  /// @brief Create a new AclBindingFilter object. This object is later passed to
  /// rd_kafka_DescribeAcls() or
  /// rd_kafka_DeletesAcls() in order to filter
  /// the acls to retrieve or to delete.
  /// Use the same rd_kafka_AclBinding functions to query or destroy it.
  ///
  /// @param restype The ResourceType or \c RD_KAFKA_RESOURCE_ANY if
  /// not filtering by this field.
  /// @param name The resource name or NULL if not filtering by this field.
  /// @param resource_pattern_type The pattern type or \c
  /// RD_KAFKA_RESOURCE_PATTERN_ANY if not filtering by this field.
  /// @param principal A principal or NULL if not filtering by this field.
  /// @param host An hostname or ip or NULL if not filtering by this field.
  /// @param operation A Kafka operation or \c RD_KAFKA_ACL_OPERATION_ANY if not
  /// filtering by this field.
  /// @param permission_type A Kafka permission type or \c
  /// RD_KAFKA_ACL_PERMISSION_TYPE_ANY if not filtering by this field.
  /// @param errstr An error string for returning errors or NULL to not use it.
  /// @param errstr_size The \p errstr size or 0 to not use it.
  ///
  /// @returns a new allocated AclBindingFilter object, or NULL if the input
  /// parameters are invalid. Use rd_kafka_AclBinding_destroy() to free object when
  /// done.
  ffi.Pointer<rd_kafka_AclBindingFilter_t> rd_kafka_AclBindingFilter_new(
    int restype,
    ffi.Pointer<ffi.Char> name,
    int resource_pattern_type,
    ffi.Pointer<ffi.Char> principal,
    ffi.Pointer<ffi.Char> host,
    int operation,
    int permission_type,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_AclBindingFilter_new(
      restype,
      name,
      resource_pattern_type,
      principal,
      host,
      operation,
      permission_type,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_AclBindingFilter_newPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_AclBindingFilter_t> Function(
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_AclBindingFilter_new');
  late final _rd_kafka_AclBindingFilter_new =
      _rd_kafka_AclBindingFilter_newPtr.asFunction<
          ffi.Pointer<rd_kafka_AclBindingFilter_t> Function(
              int,
              ffi.Pointer<ffi.Char>,
              int,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              int,
              int,
              ffi.Pointer<ffi.Char>,
              int)>();

  /// @returns the resource type for the given acl binding.
  int rd_kafka_AclBinding_restype(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_restype(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_restypePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_restype');
  late final _rd_kafka_AclBinding_restype = _rd_kafka_AclBinding_restypePtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the resource name for the given acl binding.
  ///
  /// @remark lifetime of the returned string is the same as the \p acl.
  ffi.Pointer<ffi.Char> rd_kafka_AclBinding_name(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_name(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_AclBinding_t>)>>('rd_kafka_AclBinding_name');
  late final _rd_kafka_AclBinding_name =
      _rd_kafka_AclBinding_namePtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the principal for the given acl binding.
  ///
  /// @remark lifetime of the returned string is the same as the \p acl.
  ffi.Pointer<ffi.Char> rd_kafka_AclBinding_principal(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_principal(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_principalPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Char> Function(
                  ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_principal');
  late final _rd_kafka_AclBinding_principal =
      _rd_kafka_AclBinding_principalPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the host for the given acl binding.
  ///
  /// @remark lifetime of the returned string is the same as the \p acl.
  ffi.Pointer<ffi.Char> rd_kafka_AclBinding_host(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_host(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_hostPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<rd_kafka_AclBinding_t>)>>('rd_kafka_AclBinding_host');
  late final _rd_kafka_AclBinding_host =
      _rd_kafka_AclBinding_hostPtr.asFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the acl operation for the given acl binding.
  int rd_kafka_AclBinding_operation(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_operation(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_operationPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_operation');
  late final _rd_kafka_AclBinding_operation = _rd_kafka_AclBinding_operationPtr
      .asFunction<int Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the permission type for the given acl binding.
  int rd_kafka_AclBinding_permission_type(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_permission_type(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_permission_typePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_permission_type');
  late final _rd_kafka_AclBinding_permission_type =
      _rd_kafka_AclBinding_permission_typePtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the resource pattern type for the given acl binding.
  int rd_kafka_AclBinding_resource_pattern_type(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_resource_pattern_type(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_resource_pattern_typePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_resource_pattern_type');
  late final _rd_kafka_AclBinding_resource_pattern_type =
      _rd_kafka_AclBinding_resource_pattern_typePtr
          .asFunction<int Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @returns the error object for the given acl binding, or NULL on success.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_AclBinding_error(
    ffi.Pointer<rd_kafka_AclBinding_t> acl,
  ) {
    return _rd_kafka_AclBinding_error(
      acl,
    );
  }

  late final _rd_kafka_AclBinding_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_error');
  late final _rd_kafka_AclBinding_error =
      _rd_kafka_AclBinding_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @brief Destroy and free an AclBinding object previously created with
  /// rd_kafka_AclBinding_new()
  void rd_kafka_AclBinding_destroy(
    ffi.Pointer<rd_kafka_AclBinding_t> acl_binding,
  ) {
    return _rd_kafka_AclBinding_destroy(
      acl_binding,
    );
  }

  late final _rd_kafka_AclBinding_destroyPtr = _lookup<
          ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<rd_kafka_AclBinding_t>)>>(
      'rd_kafka_AclBinding_destroy');
  late final _rd_kafka_AclBinding_destroy = _rd_kafka_AclBinding_destroyPtr
      .asFunction<void Function(ffi.Pointer<rd_kafka_AclBinding_t>)>();

  /// @brief Helper function to destroy all AclBinding objects in
  /// the \p acl_bindings array (of \p acl_bindings_cnt elements).
  /// The array itself is not freed.
  void rd_kafka_AclBinding_destroy_array(
    ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> acl_bindings,
    int acl_bindings_cnt,
  ) {
    return _rd_kafka_AclBinding_destroy_array(
      acl_bindings,
      acl_bindings_cnt,
    );
  }

  late final _rd_kafka_AclBinding_destroy_arrayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>,
              ffi.Size)>>('rd_kafka_AclBinding_destroy_array');
  late final _rd_kafka_AclBinding_destroy_array =
      _rd_kafka_AclBinding_destroy_arrayPtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>, int)>();

  /// @brief Get an array of acl results from a CreateAcls result.
  ///
  /// The returned \p acl result life-time is the same as the \p result object.
  /// @param result CreateAcls result to get acl results from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_acl_result_t>>
      rd_kafka_CreateAcls_result_acls(
    ffi.Pointer<rd_kafka_CreateAcls_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_CreateAcls_result_acls(
      result,
      cntp,
    );
  }

  late final _rd_kafka_CreateAcls_result_aclsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_acl_result_t>> Function(
              ffi.Pointer<rd_kafka_CreateAcls_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_CreateAcls_result_acls');
  late final _rd_kafka_CreateAcls_result_acls =
      _rd_kafka_CreateAcls_result_aclsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_acl_result_t>> Function(
              ffi.Pointer<rd_kafka_CreateAcls_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Create acls as specified by the \p new_acls
  /// array of size \p new_topic_cnt elements.
  ///
  /// @param rk Client instance.
  /// @param new_acls Array of new acls to create.
  /// @param new_acls_cnt Number of elements in \p new_acls array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_request_timeout() - default socket.timeout.ms
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_CREATEACLS_RESULT
  void rd_kafka_CreateAcls(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> new_acls,
    int new_acls_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_CreateAcls(
      rk,
      new_acls,
      new_acls_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_CreateAclsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_CreateAcls');
  late final _rd_kafka_CreateAcls = _rd_kafka_CreateAclsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of resource results from a DescribeAcls result.
  ///
  /// The returned \p resources life-time is the same as the \p result object.
  /// @param result DescribeAcls result to get acls from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>
      rd_kafka_DescribeAcls_result_acls(
    ffi.Pointer<rd_kafka_DescribeAcls_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DescribeAcls_result_acls(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DescribeAcls_result_aclsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> Function(
              ffi.Pointer<rd_kafka_DescribeAcls_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DescribeAcls_result_acls');
  late final _rd_kafka_DescribeAcls_result_acls =
      _rd_kafka_DescribeAcls_result_aclsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> Function(
              ffi.Pointer<rd_kafka_DescribeAcls_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Describe acls matching the filter provided in \p acl_filter
  ///
  /// @param rk Client instance.
  /// @param acl_filter Filter for the returned acls.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_operation_timeout() - default 0
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DESCRIBEACLS_RESULT
  void rd_kafka_DescribeAcls(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_AclBindingFilter_t> acl_filter,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DescribeAcls(
      rk,
      acl_filter,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DescribeAclsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_AclBindingFilter_t>,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DescribeAcls');
  late final _rd_kafka_DescribeAcls = _rd_kafka_DescribeAclsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<rd_kafka_AclBindingFilter_t>,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Get an array of DeleteAcls result responses from a DeleteAcls result.
  ///
  /// The returned \p responses life-time is the same as the \p result object.
  /// @param result DeleteAcls result to get responses from.
  /// @param cntp is updated to the number of elements in the array.
  ffi.Pointer<ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>>
      rd_kafka_DeleteAcls_result_responses(
    ffi.Pointer<rd_kafka_DeleteAcls_result_t> result,
    ffi.Pointer<ffi.Size> cntp,
  ) {
    return _rd_kafka_DeleteAcls_result_responses(
      result,
      cntp,
    );
  }

  late final _rd_kafka_DeleteAcls_result_responsesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>> Function(
              ffi.Pointer<rd_kafka_DeleteAcls_result_t>,
              ffi.Pointer<ffi.Size>)>>('rd_kafka_DeleteAcls_result_responses');
  late final _rd_kafka_DeleteAcls_result_responses =
      _rd_kafka_DeleteAcls_result_responsesPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>> Function(
              ffi.Pointer<rd_kafka_DeleteAcls_result_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @returns the error object for the given DeleteAcls result response,
  /// or NULL on success.
  ffi.Pointer<rd_kafka_error_t> rd_kafka_DeleteAcls_result_response_error(
    ffi.Pointer<rd_kafka_DeleteAcls_result_response_t> result_response,
  ) {
    return _rd_kafka_DeleteAcls_result_response_error(
      result_response,
    );
  }

  late final _rd_kafka_DeleteAcls_result_response_errorPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<rd_kafka_error_t> Function(
                  ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>)>>(
      'rd_kafka_DeleteAcls_result_response_error');
  late final _rd_kafka_DeleteAcls_result_response_error =
      _rd_kafka_DeleteAcls_result_response_errorPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>)>();

  /// @returns the matching acls array for the given DeleteAcls result response.
  ///
  /// @remark lifetime of the returned acl bindings is the same as the \p
  /// result_response.
  ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>>
      rd_kafka_DeleteAcls_result_response_matching_acls(
    ffi.Pointer<rd_kafka_DeleteAcls_result_response_t> result_response,
    ffi.Pointer<ffi.Size> matching_acls_cntp,
  ) {
    return _rd_kafka_DeleteAcls_result_response_matching_acls(
      result_response,
      matching_acls_cntp,
    );
  }

  late final _rd_kafka_DeleteAcls_result_response_matching_aclsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> Function(
                  ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>,
                  ffi.Pointer<ffi.Size>)>>(
      'rd_kafka_DeleteAcls_result_response_matching_acls');
  late final _rd_kafka_DeleteAcls_result_response_matching_acls =
      _rd_kafka_DeleteAcls_result_response_matching_aclsPtr.asFunction<
          ffi.Pointer<ffi.Pointer<rd_kafka_AclBinding_t>> Function(
              ffi.Pointer<rd_kafka_DeleteAcls_result_response_t>,
              ffi.Pointer<ffi.Size>)>();

  /// @brief Delete acls matching the filteres provided in \p del_acls
  /// array of size \p del_acls_cnt.
  ///
  /// @param rk Client instance.
  /// @param del_acls Filters for the acls to delete.
  /// @param del_acls_cnt Number of elements in \p del_acls array.
  /// @param options Optional admin options, or NULL for defaults.
  /// @param rkqu Queue to emit result on.
  ///
  /// Supported admin options:
  /// - rd_kafka_AdminOptions_set_operation_timeout() - default 0
  ///
  /// @remark The result event type emitted on the supplied queue is of type
  /// \c RD_KAFKA_EVENT_DELETEACLS_RESULT
  void rd_kafka_DeleteAcls(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Pointer<rd_kafka_AclBindingFilter_t>> del_acls,
    int del_acls_cnt,
    ffi.Pointer<rd_kafka_AdminOptions_t> options,
    ffi.Pointer<rd_kafka_queue_t> rkqu,
  ) {
    return _rd_kafka_DeleteAcls(
      rk,
      del_acls,
      del_acls_cnt,
      options,
      rkqu,
    );
  }

  late final _rd_kafka_DeleteAclsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Pointer<rd_kafka_AclBindingFilter_t>>,
              ffi.Size,
              ffi.Pointer<rd_kafka_AdminOptions_t>,
              ffi.Pointer<rd_kafka_queue_t>)>>('rd_kafka_DeleteAcls');
  late final _rd_kafka_DeleteAcls = _rd_kafka_DeleteAclsPtr.asFunction<
      void Function(
          ffi.Pointer<rd_kafka_t>,
          ffi.Pointer<ffi.Pointer<rd_kafka_AclBindingFilter_t>>,
          int,
          ffi.Pointer<rd_kafka_AdminOptions_t>,
          ffi.Pointer<rd_kafka_queue_t>)>();

  /// @brief Set SASL/OAUTHBEARER token and metadata
  ///
  /// @param rk Client instance.
  /// @param token_value the mandatory token value to set, often (but not
  /// necessarily) a JWS compact serialization as per
  /// https://tools.ietf.org/html/rfc7515#section-3.1.
  /// @param md_lifetime_ms when the token expires, in terms of the number of
  /// milliseconds since the epoch.
  /// @param md_principal_name the mandatory Kafka principal name associated
  /// with the token.
  /// @param extensions optional SASL extensions key-value array with
  /// \p extensions_size elements (number of keys * 2), where [i] is the key and
  /// [i+1] is the key's value, to be communicated to the broker
  /// as additional key-value pairs during the initial client response as per
  /// https://tools.ietf.org/html/rfc7628#section-3.1. The key-value pairs are
  /// copied.
  /// @param extension_size the number of SASL extension keys plus values,
  /// which must be a non-negative multiple of 2.
  /// @param errstr A human readable error string (nul-terminated) is written to
  /// this location that must be of at least \p errstr_size bytes.
  /// The \p errstr is only written in case of error.
  /// @param errstr_size Writable size in \p errstr.
  ///
  /// The SASL/OAUTHBEARER token refresh callback or event handler should invoke
  /// this method upon success. The extension keys must not include the reserved
  /// key "`auth`", and all extension keys and values must conform to the required
  /// format as per https://tools.ietf.org/html/rfc7628#section-3.1:
  ///
  /// key            = 1*(ALPHA)
  /// value          = *(VCHAR / SP / HTAB / CR / LF )
  ///
  /// @returns \c RD_KAFKA_RESP_ERR_NO_ERROR on success, otherwise \p errstr set
  /// and:<br>
  /// \c RD_KAFKA_RESP_ERR__INVALID_ARG if any of the arguments are
  /// invalid;<br>
  /// \c RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED if SASL/OAUTHBEARER is not
  /// supported by this build;<br>
  /// \c RD_KAFKA_RESP_ERR__STATE if SASL/OAUTHBEARER is supported but is
  /// not configured as the client's authentication mechanism.<br>
  ///
  /// @sa rd_kafka_oauthbearer_set_token_failure
  /// @sa rd_kafka_conf_set_oauthbearer_token_refresh_cb
  int rd_kafka_oauthbearer_set_token(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> token_value,
    int md_lifetime_ms,
    ffi.Pointer<ffi.Char> md_principal_name,
    ffi.Pointer<ffi.Pointer<ffi.Char>> extensions,
    int extension_size,
    ffi.Pointer<ffi.Char> errstr,
    int errstr_size,
  ) {
    return _rd_kafka_oauthbearer_set_token(
      rk,
      token_value,
      md_lifetime_ms,
      md_principal_name,
      extensions,
      extension_size,
      errstr,
      errstr_size,
    );
  }

  late final _rd_kafka_oauthbearer_set_tokenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              ffi.Int64,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Size,
              ffi.Pointer<ffi.Char>,
              ffi.Size)>>('rd_kafka_oauthbearer_set_token');
  late final _rd_kafka_oauthbearer_set_token =
      _rd_kafka_oauthbearer_set_tokenPtr.asFunction<
          int Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<ffi.Char>,
              int,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              int,
              ffi.Pointer<ffi.Char>,
              int)>();

  /// @brief SASL/OAUTHBEARER token refresh failure indicator.
  ///
  /// @param rk Client instance.
  /// @param errstr mandatory human readable error reason for failing to acquire
  /// a token.
  ///
  /// The SASL/OAUTHBEARER token refresh callback or event handler should invoke
  /// this method upon failure.
  ///
  /// @returns \c RD_KAFKA_RESP_ERR_NO_ERROR on success, otherwise:<br>
  /// \c RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED if SASL/OAUTHBEARER is not
  /// supported by this build;<br>
  /// \c RD_KAFKA_RESP_ERR__STATE if SASL/OAUTHBEARER is supported but is
  /// not configured as the client's authentication mechanism,<br>
  /// \c RD_KAFKA_RESP_ERR__INVALID_ARG if no error string is supplied.
  ///
  /// @sa rd_kafka_oauthbearer_set_token
  /// @sa rd_kafka_conf_set_oauthbearer_token_refresh_cb
  int rd_kafka_oauthbearer_set_token_failure(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<ffi.Char> errstr,
  ) {
    return _rd_kafka_oauthbearer_set_token_failure(
      rk,
      errstr,
    );
  }

  late final _rd_kafka_oauthbearer_set_token_failurePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>)>>(
      'rd_kafka_oauthbearer_set_token_failure');
  late final _rd_kafka_oauthbearer_set_token_failure =
      _rd_kafka_oauthbearer_set_token_failurePtr.asFunction<
          int Function(ffi.Pointer<rd_kafka_t>, ffi.Pointer<ffi.Char>)>();

  /// @brief Initialize transactions for the producer instance.
  ///
  /// This function ensures any transactions initiated by previous instances
  /// of the producer with the same \c transactional.id are completed.
  /// If the previous instance failed with a transaction in progress the
  /// previous transaction will be aborted.
  /// This function needs to be called before any other transactional or
  /// produce functions are called when the \c transactional.id is configured.
  ///
  /// If the last transaction had begun completion (following transaction commit)
  /// but not yet finished, this function will await the previous transaction's
  /// completion.
  ///
  /// When any previous transactions have been fenced this function
  /// will acquire the internal producer id and epoch, used in all future
  /// transactional messages issued by this producer instance.
  ///
  /// @param rk Producer instance.
  /// @param timeout_ms The maximum time to block. On timeout the operation
  /// may continue in the background, depending on state,
  /// and it is okay to call init_transactions() again.
  /// If an infinite timeout (-1) is passed, the timeout will
  /// be adjusted to 2 * \c transaction.timeout.ms.
  ///
  /// @remark This function may block up to \p timeout_ms milliseconds.
  ///
  /// @remark This call is resumable when a retriable timeout error is returned.
  /// Calling the function again will resume the operation that is
  /// progressing in the background.
  ///
  /// @returns NULL on success or an error object on failure.
  /// Check whether the returned error object permits retrying
  /// by calling rd_kafka_error_is_retriable(), or whether a fatal
  /// error has been raised by calling rd_kafka_error_is_fatal().
  /// Error codes:
  /// RD_KAFKA_RESP_ERR__TIMED_OUT if the transaction coordinator
  /// could be not be contacted within \p timeout_ms (retriable),
  /// RD_KAFKA_RESP_ERR_COORDINATOR_NOT_AVAILABLE if the transaction
  /// coordinator is not available (retriable),
  /// RD_KAFKA_RESP_ERR_CONCURRENT_TRANSACTIONS if a previous transaction
  /// would not complete within \p timeout_ms (retriable),
  /// RD_KAFKA_RESP_ERR__STATE if transactions have already been started
  /// or upon fatal error,
  /// RD_KAFKA_RESP_ERR__UNSUPPORTED_FEATURE if the broker(s) do not
  /// support transactions (<Apache Kafka 0.11), this also raises a
  /// fatal error,
  /// RD_KAFKA_RESP_ERR_INVALID_TRANSACTION_TIMEOUT if the configured
  /// \c transaction.timeout.ms is outside the broker-configured range,
  /// this also raises a fatal error,
  /// RD_KAFKA_RESP_ERR__NOT_CONFIGURED if transactions have not been
  /// configured for the producer instance,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \p rk is not a producer instance,
  /// or \p timeout_ms is out of range.
  /// Other error codes not listed here may be returned, depending on
  /// broker version.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_init_transactions(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_init_transactions(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_init_transactionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_init_transactions');
  late final _rd_kafka_init_transactions =
      _rd_kafka_init_transactionsPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Begin a new transaction.
  ///
  /// rd_kafka_init_transactions() must have been called successfully (once)
  /// before this function is called.
  ///
  /// Upon successful return from this function the application has to perform at
  /// least one of the following operations within \c transaction.timeout.ms to
  /// avoid timing out the transaction on the broker:
  /// * rd_kafka_produce() (et.al)
  /// * rd_kafka_send_offsets_to_transaction()
  /// * rd_kafka_commit_transaction()
  /// * rd_kafka_abort_transaction()
  ///
  /// Any messages produced, offsets sent (rd_kafka_send_offsets_to_transaction()),
  /// etc, after the successful return of this function will be part of
  /// the transaction and committed or aborted atomatically.
  ///
  /// Finish the transaction by calling rd_kafka_commit_transaction() or
  /// abort the transaction by calling rd_kafka_abort_transaction().
  ///
  /// @param rk Producer instance.
  ///
  /// @returns NULL on success or an error object on failure.
  /// Check whether a fatal error has been raised by
  /// calling rd_kafka_error_is_fatal().
  /// Error codes:
  /// RD_KAFKA_RESP_ERR__STATE if a transaction is already in progress
  /// or upon fatal error,
  /// RD_KAFKA_RESP_ERR__NOT_CONFIGURED if transactions have not been
  /// configured for the producer instance,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \p rk is not a producer instance.
  /// Other error codes not listed here may be returned, depending on
  /// broker version.
  ///
  /// @remark With the transactional producer, rd_kafka_produce(),
  /// rd_kafka_producev(), et.al, are only allowed during an on-going
  /// transaction, as started with this function.
  /// Any produce call outside an on-going transaction, or for a failed
  /// transaction, will fail.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_begin_transaction(
    ffi.Pointer<rd_kafka_t> rk,
  ) {
    return _rd_kafka_begin_transaction(
      rk,
    );
  }

  late final _rd_kafka_begin_transactionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>)>>('rd_kafka_begin_transaction');
  late final _rd_kafka_begin_transaction =
      _rd_kafka_begin_transactionPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>)>();

  /// @brief Sends a list of topic partition offsets to the consumer group
  /// coordinator for \p cgmetadata, and marks the offsets as part
  /// part of the current transaction.
  /// These offsets will be considered committed only if the transaction is
  /// committed successfully.
  ///
  /// The offsets should be the next message your application will consume,
  /// i.e., the last processed message's offset + 1 for each partition.
  /// Either track the offsets manually during processing or use
  /// rd_kafka_position() (on the consumer) to get the current offsets for
  /// the partitions assigned to the consumer.
  ///
  /// Use this method at the end of a consume-transform-produce loop prior
  /// to committing the transaction with rd_kafka_commit_transaction().
  ///
  /// @param rk Producer instance.
  /// @param offsets List of offsets to commit to the consumer group upon
  /// successful commit of the transaction. Offsets should be
  /// the next message to consume, e.g., last processed message + 1.
  /// @param cgmetadata The current consumer group metadata as returned by
  /// rd_kafka_consumer_group_metadata() on the consumer
  /// instance the provided offsets were consumed from.
  /// @param timeout_ms Maximum time allowed to register the offsets on the broker.
  ///
  /// @remark This function must be called on the transactional producer instance,
  /// not the consumer.
  ///
  /// @remark The consumer must disable auto commits
  /// (set \c enable.auto.commit to false on the consumer).
  ///
  /// @remark Logical and invalid offsets (such as RD_KAFKA_OFFSET_INVALID) in
  /// \p offsets will be ignored, if there are no valid offsets in
  /// \p offsets the function will return NULL and no action will be taken.
  ///
  /// @remark This call is retriable but not resumable, which means a new request
  /// with a new set of provided offsets and group metadata will be
  /// sent to the transaction coordinator if the call is retried.
  ///
  /// @remark It is highly recommended to retry the call (upon retriable error)
  /// with identical \p offsets and \p cgmetadata parameters.
  /// Failure to do so risks inconsistent state between what is actually
  /// included in the transaction and what the application thinks is
  /// included in the transaction.
  ///
  /// @returns NULL on success or an error object on failure.
  /// Check whether the returned error object permits retrying
  /// by calling rd_kafka_error_is_retriable(), or whether an abortable
  /// or fatal error has been raised by calling
  /// rd_kafka_error_txn_requires_abort() or rd_kafka_error_is_fatal()
  /// respectively.
  /// Error codes:
  /// RD_KAFKA_RESP_ERR__STATE if not currently in a transaction,
  /// RD_KAFKA_RESP_ERR_INVALID_PRODUCER_EPOCH if the current producer
  /// transaction has been fenced by a newer producer instance,
  /// RD_KAFKA_RESP_ERR_TRANSACTIONAL_ID_AUTHORIZATION_FAILED if the
  /// producer is no longer authorized to perform transactional
  /// operations,
  /// RD_KAFKA_RESP_ERR_GROUP_AUTHORIZATION_FAILED if the producer is
  /// not authorized to write the consumer offsets to the group
  /// coordinator,
  /// RD_KAFKA_RESP_ERR__NOT_CONFIGURED if transactions have not been
  /// configured for the producer instance,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \p rk is not a producer instance,
  /// or if the \p consumer_group_id or \p offsets are empty.
  /// Other error codes not listed here may be returned, depending on
  /// broker version.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_send_offsets_to_transaction(
    ffi.Pointer<rd_kafka_t> rk,
    ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
    ffi.Pointer<rd_kafka_consumer_group_metadata_t> cgmetadata,
    int timeout_ms,
  ) {
    return _rd_kafka_send_offsets_to_transaction(
      rk,
      offsets,
      cgmetadata,
      timeout_ms,
    );
  }

  late final _rd_kafka_send_offsets_to_transactionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<rd_kafka_consumer_group_metadata_t>,
              ffi.Int)>>('rd_kafka_send_offsets_to_transaction');
  late final _rd_kafka_send_offsets_to_transaction =
      _rd_kafka_send_offsets_to_transactionPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>,
              ffi.Pointer<rd_kafka_topic_partition_list_t>,
              ffi.Pointer<rd_kafka_consumer_group_metadata_t>,
              int)>();

  /// @brief Commit the current transaction (as started with
  /// rd_kafka_begin_transaction()).
  ///
  /// Any outstanding messages will be flushed (delivered) before actually
  /// committing the transaction.
  ///
  /// If any of the outstanding messages fail permanently the current
  /// transaction will enter the abortable error state and this
  /// function will return an abortable error, in this case the application
  /// must call rd_kafka_abort_transaction() before attempting a new
  /// transaction with rd_kafka_begin_transaction().
  ///
  /// @param rk Producer instance.
  /// @param timeout_ms The maximum time to block. On timeout the operation
  /// may continue in the background, depending on state,
  /// and it is okay to call this function again.
  /// Pass -1 to use the remaining transaction timeout,
  /// this is the recommended use.
  ///
  /// @remark It is strongly recommended to always pass -1 (remaining transaction
  /// time) as the \p timeout_ms. Using other values risk internal
  /// state desynchronization in case any of the underlying protocol
  /// requests fail.
  ///
  /// @remark This function will block until all outstanding messages are
  /// delivered and the transaction commit request has been successfully
  /// handled by the transaction coordinator, or until \p timeout_ms
  /// expires, which ever comes first. On timeout the application may
  /// call the function again.
  ///
  /// @remark Will automatically call rd_kafka_flush() to ensure all queued
  /// messages are delivered before attempting to commit the
  /// transaction.
  /// If the application has enabled RD_KAFKA_EVENT_DR it must
  /// serve the event queue in a separate thread since rd_kafka_flush()
  /// will not serve delivery reports in this mode.
  ///
  /// @remark This call is resumable when a retriable timeout error is returned.
  /// Calling the function again will resume the operation that is
  /// progressing in the background.
  ///
  /// @returns NULL on success or an error object on failure.
  /// Check whether the returned error object permits retrying
  /// by calling rd_kafka_error_is_retriable(), or whether an abortable
  /// or fatal error has been raised by calling
  /// rd_kafka_error_txn_requires_abort() or rd_kafka_error_is_fatal()
  /// respectively.
  /// Error codes:
  /// RD_KAFKA_RESP_ERR__STATE if not currently in a transaction,
  /// RD_KAFKA_RESP_ERR__TIMED_OUT if the transaction could not be
  /// complete commmitted within \p timeout_ms, this is a retriable
  /// error as the commit continues in the background,
  /// RD_KAFKA_RESP_ERR_INVALID_PRODUCER_EPOCH if the current producer
  /// transaction has been fenced by a newer producer instance,
  /// RD_KAFKA_RESP_ERR_TRANSACTIONAL_ID_AUTHORIZATION_FAILED if the
  /// producer is no longer authorized to perform transactional
  /// operations,
  /// RD_KAFKA_RESP_ERR__NOT_CONFIGURED if transactions have not been
  /// configured for the producer instance,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \p rk is not a producer instance,
  /// Other error codes not listed here may be returned, depending on
  /// broker version.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_commit_transaction(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_commit_transaction(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_commit_transactionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(ffi.Pointer<rd_kafka_t>,
              ffi.Int)>>('rd_kafka_commit_transaction');
  late final _rd_kafka_commit_transaction =
      _rd_kafka_commit_transactionPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, int)>();

  /// @brief Aborts the ongoing transaction.
  ///
  /// This function should also be used to recover from non-fatal abortable
  /// transaction errors.
  ///
  /// Any outstanding messages will be purged and fail with
  /// RD_KAFKA_RESP_ERR__PURGE_INFLIGHT or RD_KAFKA_RESP_ERR__PURGE_QUEUE.
  /// See rd_kafka_purge() for details.
  ///
  /// @param rk Producer instance.
  /// @param timeout_ms The maximum time to block. On timeout the operation
  /// may continue in the background, depending on state,
  /// and it is okay to call this function again.
  /// Pass -1 to use the remaining transaction timeout,
  /// this is the recommended use.
  ///
  /// @remark It is strongly recommended to always pass -1 (remaining transaction
  /// time) as the \p timeout_ms. Using other values risk internal
  /// state desynchronization in case any of the underlying protocol
  /// requests fail.
  ///
  /// @remark This function will block until all outstanding messages are purged
  /// and the transaction abort request has been successfully
  /// handled by the transaction coordinator, or until \p timeout_ms
  /// expires, which ever comes first. On timeout the application may
  /// call the function again.
  /// If the application has enabled RD_KAFKA_EVENT_DR it must
  /// serve the event queue in a separate thread since rd_kafka_flush()
  /// will not serve delivery reports in this mode.
  ///
  /// @remark This call is resumable when a retriable timeout error is returned.
  /// Calling the function again will resume the operation that is
  /// progressing in the background.
  ///
  /// @returns NULL on success or an error object on failure.
  /// Check whether the returned error object permits retrying
  /// by calling rd_kafka_error_is_retriable(), or whether a fatal error
  /// has been raised by calling rd_kafka_error_is_fatal().
  /// Error codes:
  /// RD_KAFKA_RESP_ERR__STATE if not currently in a transaction,
  /// RD_KAFKA_RESP_ERR__TIMED_OUT if the transaction could not be
  /// complete commmitted within \p timeout_ms, this is a retriable
  /// error as the commit continues in the background,
  /// RD_KAFKA_RESP_ERR_INVALID_PRODUCER_EPOCH if the current producer
  /// transaction has been fenced by a newer producer instance,
  /// RD_KAFKA_RESP_ERR_TRANSACTIONAL_ID_AUTHORIZATION_FAILED if the
  /// producer is no longer authorized to perform transactional
  /// operations,
  /// RD_KAFKA_RESP_ERR__NOT_CONFIGURED if transactions have not been
  /// configured for the producer instance,
  /// RD_KAFKA_RESP_ERR__INVALID_ARG if \p rk is not a producer instance,
  /// Other error codes not listed here may be returned, depending on
  /// broker version.
  ///
  /// @remark The returned error object (if not NULL) must be destroyed with
  /// rd_kafka_error_destroy().
  ffi.Pointer<rd_kafka_error_t> rd_kafka_abort_transaction(
    ffi.Pointer<rd_kafka_t> rk,
    int timeout_ms,
  ) {
    return _rd_kafka_abort_transaction(
      rk,
      timeout_ms,
    );
  }

  late final _rd_kafka_abort_transactionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, ffi.Int)>>('rd_kafka_abort_transaction');
  late final _rd_kafka_abort_transaction =
      _rd_kafka_abort_transactionPtr.asFunction<
          ffi.Pointer<rd_kafka_error_t> Function(
              ffi.Pointer<rd_kafka_t>, int)>();
}

final class __mbstate_t extends ffi.Union {
  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> __mbstate8;

  @ffi.LongLong()
  external int _mbstateL;
}

final class __darwin_pthread_handler_rec extends ffi.Struct {
  external ffi
      .Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>
      __routine;

  external ffi.Pointer<ffi.Void> __arg;

  external ffi.Pointer<__darwin_pthread_handler_rec> __next;
}

final class _opaque_pthread_attr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_cond_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([40])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_condattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_mutex_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_mutexattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_once_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_rwlock_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([192])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_rwlockattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  external ffi.Pointer<__darwin_pthread_handler_rec> __cleanup_stack;

  @ffi.Array.multi([8176])
  external ffi.Array<ffi.Char> __opaque;
}

final class __sbuf extends ffi.Struct {
  external ffi.Pointer<ffi.UnsignedChar> _base;

  @ffi.Int()
  external int _size;
}

final class __sFILEX extends ffi.Opaque {}

final class __sFILE extends ffi.Struct {
  external ffi.Pointer<ffi.UnsignedChar> _p;

  @ffi.Int()
  external int _r;

  @ffi.Int()
  external int _w;

  @ffi.Short()
  external int _flags;

  @ffi.Short()
  external int _file;

  external __sbuf _bf;

  @ffi.Int()
  external int _lbfsize;

  external ffi.Pointer<ffi.Void> _cookie;

  external ffi
      .Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
      _close;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _read;

  external ffi.Pointer<
      ffi.NativeFunction<
          fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>> _seek;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _write;

  external __sbuf _ub;

  external ffi.Pointer<__sFILEX> _extra;

  @ffi.Int()
  external int _ur;

  @ffi.Array.multi([3])
  external ffi.Array<ffi.UnsignedChar> _ubuf;

  @ffi.Array.multi([1])
  external ffi.Array<ffi.UnsignedChar> _nbuf;

  external __sbuf _lb;

  @ffi.Int()
  external int _blksize;

  @fpos_t()
  external int _offset;
}

typedef fpos_t = __darwin_off_t;
typedef __darwin_off_t = __int64_t;
typedef __int64_t = ffi.LongLong;
typedef Dart__int64_t = int;
typedef FILE = __sFILE;
typedef va_list = __darwin_va_list;
typedef __darwin_va_list = __builtin_va_list;
typedef __builtin_va_list = ffi.Pointer<ffi.Char>;
typedef off_t = __darwin_off_t;
typedef ssize_t = __darwin_ssize_t;
typedef __darwin_ssize_t = ffi.Long;
typedef Dart__darwin_ssize_t = int;
typedef intmax_t = ffi.Long;
typedef Dartintmax_t = int;

final class imaxdiv_t extends ffi.Struct {
  @intmax_t()
  external int quot;

  @intmax_t()
  external int rem;
}

typedef uintmax_t = ffi.UnsignedLong;
typedef Dartuintmax_t = int;

@ffi.Packed(1)
final class _OSUnalignedU16 extends ffi.Struct {
  @ffi.Uint16()
  external int __val;
}

@ffi.Packed(1)
final class _OSUnalignedU32 extends ffi.Struct {
  @ffi.Uint32()
  external int __val;
}

@ffi.Packed(1)
final class _OSUnalignedU64 extends ffi.Struct {
  @ffi.Uint64()
  external int __val;
}

final class fd_set extends ffi.Struct {
  @ffi.Array.multi([32])
  external ffi.Array<__int32_t> fds_bits;
}

typedef __int32_t = ffi.Int;
typedef Dart__int32_t = int;

final class iovec extends ffi.Struct {
  external ffi.Pointer<ffi.Void> iov_base;

  @ffi.Size()
  external int iov_len;
}

final class sa_endpoints extends ffi.Struct {
  @ffi.UnsignedInt()
  external int sae_srcif;

  external ffi.Pointer<sockaddr> sae_srcaddr;

  @socklen_t()
  external int sae_srcaddrlen;

  external ffi.Pointer<sockaddr> sae_dstaddr;

  @socklen_t()
  external int sae_dstaddrlen;
}

final class sockaddr extends ffi.Struct {
  @__uint8_t()
  external int sa_len;

  @sa_family_t()
  external int sa_family;

  @ffi.Array.multi([14])
  external ffi.Array<ffi.Char> sa_data;
}

typedef __uint8_t = ffi.UnsignedChar;
typedef Dart__uint8_t = int;
typedef sa_family_t = __uint8_t;
typedef socklen_t = __darwin_socklen_t;
typedef __darwin_socklen_t = __uint32_t;
typedef __uint32_t = ffi.UnsignedInt;
typedef Dart__uint32_t = int;

final class linger extends ffi.Struct {
  @ffi.Int()
  external int l_onoff;

  @ffi.Int()
  external int l_linger;
}

final class so_np_extensions extends ffi.Struct {
  @u_int32_t()
  external int npx_flags;

  @u_int32_t()
  external int npx_mask;
}

typedef u_int32_t = ffi.UnsignedInt;
typedef Dartu_int32_t = int;

final class __sockaddr_header extends ffi.Struct {
  @__uint8_t()
  external int sa_len;

  @sa_family_t()
  external int sa_family;
}

final class sockproto extends ffi.Struct {
  @__uint16_t()
  external int sp_family;

  @__uint16_t()
  external int sp_protocol;
}

typedef __uint16_t = ffi.UnsignedShort;
typedef Dart__uint16_t = int;

final class sockaddr_storage extends ffi.Struct {
  @__uint8_t()
  external int ss_len;

  @sa_family_t()
  external int ss_family;

  @ffi.Array.multi([6])
  external ffi.Array<ffi.Char> __ss_pad1;

  @__int64_t()
  external int __ss_align;

  @ffi.Array.multi([112])
  external ffi.Array<ffi.Char> __ss_pad2;
}

final class msghdr extends ffi.Struct {
  external ffi.Pointer<ffi.Void> msg_name;

  @socklen_t()
  external int msg_namelen;

  external ffi.Pointer<iovec> msg_iov;

  @ffi.Int()
  external int msg_iovlen;

  external ffi.Pointer<ffi.Void> msg_control;

  @socklen_t()
  external int msg_controllen;

  @ffi.Int()
  external int msg_flags;
}

final class cmsghdr extends ffi.Struct {
  @socklen_t()
  external int cmsg_len;

  @ffi.Int()
  external int cmsg_level;

  @ffi.Int()
  external int cmsg_type;
}

final class sf_hdtr extends ffi.Struct {
  external ffi.Pointer<iovec> headers;

  @ffi.Int()
  external int hdr_cnt;

  external ffi.Pointer<iovec> trailers;

  @ffi.Int()
  external int trl_cnt;
}

typedef sa_endpoints_t = sa_endpoints;
typedef sae_associd_t = __uint32_t;
typedef sae_connid_t = __uint32_t;

/// @enum rd_kafka_type_t
///
/// @brief rd_kafka_t handle type.
///
/// @sa rd_kafka_new()
abstract class rd_kafka_type_t {
  /// < Producer client
  static const int RD_KAFKA_PRODUCER = 0;

  /// < Consumer client
  static const int RD_KAFKA_CONSUMER = 1;
}

/// !
/// Timestamp types
///
/// @sa rd_kafka_message_timestamp()
abstract class rd_kafka_timestamp_type_t {
  /// < Timestamp not available
  static const int RD_KAFKA_TIMESTAMP_NOT_AVAILABLE = 0;

  /// < Message creation time
  static const int RD_KAFKA_TIMESTAMP_CREATE_TIME = 1;

  /// < Log append time
  static const int RD_KAFKA_TIMESTAMP_LOG_APPEND_TIME = 2;
}

final class rd_kafka_s extends ffi.Opaque {}

final class rd_kafka_topic_s extends ffi.Opaque {}

final class rd_kafka_conf_s extends ffi.Opaque {}

final class rd_kafka_topic_conf_s extends ffi.Opaque {}

final class rd_kafka_queue_s extends ffi.Opaque {}

final class rd_kafka_op_s extends ffi.Opaque {}

final class rd_kafka_topic_result_s extends ffi.Opaque {}

final class rd_kafka_consumer_group_metadata_s extends ffi.Opaque {}

final class rd_kafka_error_s extends ffi.Opaque {}

final class rd_kafka_headers_s extends ffi.Opaque {}

final class rd_kafka_group_result_s extends ffi.Opaque {}

final class rd_kafka_acl_result_s extends ffi.Opaque {}

final class rd_kafka_Uuid_s extends ffi.Opaque {}

/// @enum rd_kafka_resp_err_t
/// @brief Error codes.
///
/// The negative error codes delimited by two underscores
/// (\c RD_KAFKA_RESP_ERR__..) denotes errors internal to librdkafka and are
/// displayed as \c \"Local: \<error string..\>\", while the error codes
/// delimited by a single underscore (\c RD_KAFKA_RESP_ERR_..) denote broker
/// errors and are displayed as \c \"Broker: \<error string..\>\".
///
/// @sa Use rd_kafka_err2str() to translate an error code a human readable string
abstract class rd_kafka_resp_err_t {
  /// Begin internal error codes
  static const int RD_KAFKA_RESP_ERR__BEGIN = -200;

  /// Received message is incorrect
  static const int RD_KAFKA_RESP_ERR__BAD_MSG = -199;

  /// Bad/unknown compression
  static const int RD_KAFKA_RESP_ERR__BAD_COMPRESSION = -198;

  /// Broker is going away
  static const int RD_KAFKA_RESP_ERR__DESTROY = -197;

  /// Generic failure
  static const int RD_KAFKA_RESP_ERR__FAIL = -196;

  /// Broker transport failure
  static const int RD_KAFKA_RESP_ERR__TRANSPORT = -195;

  /// Critical system resource
  static const int RD_KAFKA_RESP_ERR__CRIT_SYS_RESOURCE = -194;

  /// Failed to resolve broker
  static const int RD_KAFKA_RESP_ERR__RESOLVE = -193;

  /// Produced message timed out
  static const int RD_KAFKA_RESP_ERR__MSG_TIMED_OUT = -192;

  /// Reached the end of the topic+partition queue on
  /// the broker. Not really an error.
  /// This event is disabled by default,
  /// see the `enable.partition.eof` configuration property.
  static const int RD_KAFKA_RESP_ERR__PARTITION_EOF = -191;

  /// Permanent: Partition does not exist in cluster.
  static const int RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION = -190;

  /// File or filesystem error
  static const int RD_KAFKA_RESP_ERR__FS = -189;

  /// Permanent: Topic does not exist in cluster.
  static const int RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC = -188;

  /// All broker connections are down.
  static const int RD_KAFKA_RESP_ERR__ALL_BROKERS_DOWN = -187;

  /// Invalid argument, or invalid configuration
  static const int RD_KAFKA_RESP_ERR__INVALID_ARG = -186;

  /// Operation timed out
  static const int RD_KAFKA_RESP_ERR__TIMED_OUT = -185;

  /// Queue is full
  static const int RD_KAFKA_RESP_ERR__QUEUE_FULL = -184;

  /// ISR count < required.acks
  static const int RD_KAFKA_RESP_ERR__ISR_INSUFF = -183;

  /// Broker node update
  static const int RD_KAFKA_RESP_ERR__NODE_UPDATE = -182;

  /// SSL error
  static const int RD_KAFKA_RESP_ERR__SSL = -181;

  /// Waiting for coordinator to become available.
  static const int RD_KAFKA_RESP_ERR__WAIT_COORD = -180;

  /// Unknown client group
  static const int RD_KAFKA_RESP_ERR__UNKNOWN_GROUP = -179;

  /// Operation in progress
  static const int RD_KAFKA_RESP_ERR__IN_PROGRESS = -178;

  /// Previous operation in progress, wait for it to finish.
  static const int RD_KAFKA_RESP_ERR__PREV_IN_PROGRESS = -177;

  /// This operation would interfere with an existing subscription
  static const int RD_KAFKA_RESP_ERR__EXISTING_SUBSCRIPTION = -176;

  /// Assigned partitions (rebalance_cb)
  static const int RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS = -175;

  /// Revoked partitions (rebalance_cb)
  static const int RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS = -174;

  /// Conflicting use
  static const int RD_KAFKA_RESP_ERR__CONFLICT = -173;

  /// Wrong state
  static const int RD_KAFKA_RESP_ERR__STATE = -172;

  /// Unknown protocol
  static const int RD_KAFKA_RESP_ERR__UNKNOWN_PROTOCOL = -171;

  /// Not implemented
  static const int RD_KAFKA_RESP_ERR__NOT_IMPLEMENTED = -170;

  /// Authentication failure
  static const int RD_KAFKA_RESP_ERR__AUTHENTICATION = -169;

  /// No stored offset
  static const int RD_KAFKA_RESP_ERR__NO_OFFSET = -168;

  /// Outdated
  static const int RD_KAFKA_RESP_ERR__OUTDATED = -167;

  /// Timed out in queue
  static const int RD_KAFKA_RESP_ERR__TIMED_OUT_QUEUE = -166;

  /// Feature not supported by broker
  static const int RD_KAFKA_RESP_ERR__UNSUPPORTED_FEATURE = -165;

  /// Awaiting cache update
  static const int RD_KAFKA_RESP_ERR__WAIT_CACHE = -164;

  /// Operation interrupted (e.g., due to yield))
  static const int RD_KAFKA_RESP_ERR__INTR = -163;

  /// Key serialization error
  static const int RD_KAFKA_RESP_ERR__KEY_SERIALIZATION = -162;

  /// Value serialization error
  static const int RD_KAFKA_RESP_ERR__VALUE_SERIALIZATION = -161;

  /// Key deserialization error
  static const int RD_KAFKA_RESP_ERR__KEY_DESERIALIZATION = -160;

  /// Value deserialization error
  static const int RD_KAFKA_RESP_ERR__VALUE_DESERIALIZATION = -159;

  /// Partial response
  static const int RD_KAFKA_RESP_ERR__PARTIAL = -158;

  /// Modification attempted on read-only object
  static const int RD_KAFKA_RESP_ERR__READ_ONLY = -157;

  /// No such entry / item not found
  static const int RD_KAFKA_RESP_ERR__NOENT = -156;

  /// Read underflow
  static const int RD_KAFKA_RESP_ERR__UNDERFLOW = -155;

  /// Invalid type
  static const int RD_KAFKA_RESP_ERR__INVALID_TYPE = -154;

  /// Retry operation
  static const int RD_KAFKA_RESP_ERR__RETRY = -153;

  /// Purged in queue
  static const int RD_KAFKA_RESP_ERR__PURGE_QUEUE = -152;

  /// Purged in flight
  static const int RD_KAFKA_RESP_ERR__PURGE_INFLIGHT = -151;

  /// Fatal error: see rd_kafka_fatal_error()
  static const int RD_KAFKA_RESP_ERR__FATAL = -150;

  /// Inconsistent state
  static const int RD_KAFKA_RESP_ERR__INCONSISTENT = -149;

  /// Gap-less ordering would not be guaranteed if proceeding
  static const int RD_KAFKA_RESP_ERR__GAPLESS_GUARANTEE = -148;

  /// Maximum poll interval exceeded
  static const int RD_KAFKA_RESP_ERR__MAX_POLL_EXCEEDED = -147;

  /// Unknown broker
  static const int RD_KAFKA_RESP_ERR__UNKNOWN_BROKER = -146;

  /// Functionality not configured
  static const int RD_KAFKA_RESP_ERR__NOT_CONFIGURED = -145;

  /// Instance has been fenced
  static const int RD_KAFKA_RESP_ERR__FENCED = -144;

  /// Application generated error
  static const int RD_KAFKA_RESP_ERR__APPLICATION = -143;

  /// Assignment lost
  static const int RD_KAFKA_RESP_ERR__ASSIGNMENT_LOST = -142;

  /// No operation performed
  static const int RD_KAFKA_RESP_ERR__NOOP = -141;

  /// No offset to automatically reset to
  static const int RD_KAFKA_RESP_ERR__AUTO_OFFSET_RESET = -140;

  /// Partition log truncation detected
  static const int RD_KAFKA_RESP_ERR__LOG_TRUNCATION = -139;

  /// A different record in the batch was invalid
  /// and this message failed persisting.
  static const int RD_KAFKA_RESP_ERR__INVALID_DIFFERENT_RECORD = -138;

  /// End internal error codes
  static const int RD_KAFKA_RESP_ERR__END = -100;

  /// Unknown broker error
  static const int RD_KAFKA_RESP_ERR_UNKNOWN = -1;

  /// Success
  static const int RD_KAFKA_RESP_ERR_NO_ERROR = 0;

  /// Offset out of range
  static const int RD_KAFKA_RESP_ERR_OFFSET_OUT_OF_RANGE = 1;

  /// Invalid message
  static const int RD_KAFKA_RESP_ERR_INVALID_MSG = 2;

  /// Unknown topic or partition
  static const int RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_OR_PART = 3;

  /// Invalid message size
  static const int RD_KAFKA_RESP_ERR_INVALID_MSG_SIZE = 4;

  /// Leader not available
  static const int RD_KAFKA_RESP_ERR_LEADER_NOT_AVAILABLE = 5;
  static const int RD_KAFKA_RESP_ERR_NOT_LEADER_FOR_PARTITION = 6;

  /// Request timed out
  static const int RD_KAFKA_RESP_ERR_REQUEST_TIMED_OUT = 7;

  /// Broker not available
  static const int RD_KAFKA_RESP_ERR_BROKER_NOT_AVAILABLE = 8;

  /// Replica not available
  static const int RD_KAFKA_RESP_ERR_REPLICA_NOT_AVAILABLE = 9;

  /// Message size too large
  static const int RD_KAFKA_RESP_ERR_MSG_SIZE_TOO_LARGE = 10;

  /// StaleControllerEpochCode
  static const int RD_KAFKA_RESP_ERR_STALE_CTRL_EPOCH = 11;

  /// Offset metadata string too large
  static const int RD_KAFKA_RESP_ERR_OFFSET_METADATA_TOO_LARGE = 12;

  /// Broker disconnected before response received
  static const int RD_KAFKA_RESP_ERR_NETWORK_EXCEPTION = 13;

  /// Coordinator load in progress
  static const int RD_KAFKA_RESP_ERR_COORDINATOR_LOAD_IN_PROGRESS = 14;

  /// Coordinator not available
  static const int RD_KAFKA_RESP_ERR_COORDINATOR_NOT_AVAILABLE = 15;

  /// Not coordinator
  static const int RD_KAFKA_RESP_ERR_NOT_COORDINATOR = 16;

  /// Invalid topic
  static const int RD_KAFKA_RESP_ERR_TOPIC_EXCEPTION = 17;

  /// Message batch larger than configured server segment size
  static const int RD_KAFKA_RESP_ERR_RECORD_LIST_TOO_LARGE = 18;

  /// Not enough in-sync replicas
  static const int RD_KAFKA_RESP_ERR_NOT_ENOUGH_REPLICAS = 19;

  /// Message(s) written to insufficient number of in-sync replicas
  static const int RD_KAFKA_RESP_ERR_NOT_ENOUGH_REPLICAS_AFTER_APPEND = 20;

  /// Invalid required acks value
  static const int RD_KAFKA_RESP_ERR_INVALID_REQUIRED_ACKS = 21;

  /// Specified group generation id is not valid
  static const int RD_KAFKA_RESP_ERR_ILLEGAL_GENERATION = 22;

  /// Inconsistent group protocol
  static const int RD_KAFKA_RESP_ERR_INCONSISTENT_GROUP_PROTOCOL = 23;

  /// Invalid group.id
  static const int RD_KAFKA_RESP_ERR_INVALID_GROUP_ID = 24;

  /// Unknown member
  static const int RD_KAFKA_RESP_ERR_UNKNOWN_MEMBER_ID = 25;

  /// Invalid session timeout
  static const int RD_KAFKA_RESP_ERR_INVALID_SESSION_TIMEOUT = 26;

  /// Group rebalance in progress
  static const int RD_KAFKA_RESP_ERR_REBALANCE_IN_PROGRESS = 27;

  /// Commit offset data size is not valid
  static const int RD_KAFKA_RESP_ERR_INVALID_COMMIT_OFFSET_SIZE = 28;

  /// Topic authorization failed
  static const int RD_KAFKA_RESP_ERR_TOPIC_AUTHORIZATION_FAILED = 29;

  /// Group authorization failed
  static const int RD_KAFKA_RESP_ERR_GROUP_AUTHORIZATION_FAILED = 30;

  /// Cluster authorization failed
  static const int RD_KAFKA_RESP_ERR_CLUSTER_AUTHORIZATION_FAILED = 31;

  /// Invalid timestamp
  static const int RD_KAFKA_RESP_ERR_INVALID_TIMESTAMP = 32;

  /// Unsupported SASL mechanism
  static const int RD_KAFKA_RESP_ERR_UNSUPPORTED_SASL_MECHANISM = 33;

  /// Illegal SASL state
  static const int RD_KAFKA_RESP_ERR_ILLEGAL_SASL_STATE = 34;

  /// Unuspported version
  static const int RD_KAFKA_RESP_ERR_UNSUPPORTED_VERSION = 35;

  /// Topic already exists
  static const int RD_KAFKA_RESP_ERR_TOPIC_ALREADY_EXISTS = 36;

  /// Invalid number of partitions
  static const int RD_KAFKA_RESP_ERR_INVALID_PARTITIONS = 37;

  /// Invalid replication factor
  static const int RD_KAFKA_RESP_ERR_INVALID_REPLICATION_FACTOR = 38;

  /// Invalid replica assignment
  static const int RD_KAFKA_RESP_ERR_INVALID_REPLICA_ASSIGNMENT = 39;

  /// Invalid config
  static const int RD_KAFKA_RESP_ERR_INVALID_CONFIG = 40;

  /// Not controller for cluster
  static const int RD_KAFKA_RESP_ERR_NOT_CONTROLLER = 41;

  /// Invalid request
  static const int RD_KAFKA_RESP_ERR_INVALID_REQUEST = 42;

  /// Message format on broker does not support request
  static const int RD_KAFKA_RESP_ERR_UNSUPPORTED_FOR_MESSAGE_FORMAT = 43;

  /// Policy violation
  static const int RD_KAFKA_RESP_ERR_POLICY_VIOLATION = 44;

  /// Broker received an out of order sequence number
  static const int RD_KAFKA_RESP_ERR_OUT_OF_ORDER_SEQUENCE_NUMBER = 45;

  /// Broker received a duplicate sequence number
  static const int RD_KAFKA_RESP_ERR_DUPLICATE_SEQUENCE_NUMBER = 46;

  /// Producer attempted an operation with an old epoch
  static const int RD_KAFKA_RESP_ERR_INVALID_PRODUCER_EPOCH = 47;

  /// Producer attempted a transactional operation in an invalid state
  static const int RD_KAFKA_RESP_ERR_INVALID_TXN_STATE = 48;

  /// Producer attempted to use a producer id which is not
  /// currently assigned to its transactional id
  static const int RD_KAFKA_RESP_ERR_INVALID_PRODUCER_ID_MAPPING = 49;

  /// Transaction timeout is larger than the maximum
  /// value allowed by the broker's max.transaction.timeout.ms
  static const int RD_KAFKA_RESP_ERR_INVALID_TRANSACTION_TIMEOUT = 50;

  /// Producer attempted to update a transaction while another
  /// concurrent operation on the same transaction was ongoing
  static const int RD_KAFKA_RESP_ERR_CONCURRENT_TRANSACTIONS = 51;

  /// Indicates that the transaction coordinator sending a
  /// WriteTxnMarker is no longer the current coordinator for a
  /// given producer
  static const int RD_KAFKA_RESP_ERR_TRANSACTION_COORDINATOR_FENCED = 52;

  /// Transactional Id authorization failed
  static const int RD_KAFKA_RESP_ERR_TRANSACTIONAL_ID_AUTHORIZATION_FAILED = 53;

  /// Security features are disabled
  static const int RD_KAFKA_RESP_ERR_SECURITY_DISABLED = 54;

  /// Operation not attempted
  static const int RD_KAFKA_RESP_ERR_OPERATION_NOT_ATTEMPTED = 55;

  /// Disk error when trying to access log file on the disk
  static const int RD_KAFKA_RESP_ERR_KAFKA_STORAGE_ERROR = 56;

  /// The user-specified log directory is not found in the broker config
  static const int RD_KAFKA_RESP_ERR_LOG_DIR_NOT_FOUND = 57;

  /// SASL Authentication failed
  static const int RD_KAFKA_RESP_ERR_SASL_AUTHENTICATION_FAILED = 58;

  /// Unknown Producer Id
  static const int RD_KAFKA_RESP_ERR_UNKNOWN_PRODUCER_ID = 59;

  /// Partition reassignment is in progress
  static const int RD_KAFKA_RESP_ERR_REASSIGNMENT_IN_PROGRESS = 60;

  /// Delegation Token feature is not enabled
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_AUTH_DISABLED = 61;

  /// Delegation Token is not found on server
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_NOT_FOUND = 62;

  /// Specified Principal is not valid Owner/Renewer
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_OWNER_MISMATCH = 63;

  /// Delegation Token requests are not allowed on this connection
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_REQUEST_NOT_ALLOWED = 64;

  /// Delegation Token authorization failed
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_AUTHORIZATION_FAILED = 65;

  /// Delegation Token is expired
  static const int RD_KAFKA_RESP_ERR_DELEGATION_TOKEN_EXPIRED = 66;

  /// Supplied principalType is not supported
  static const int RD_KAFKA_RESP_ERR_INVALID_PRINCIPAL_TYPE = 67;

  /// The group is not empty
  static const int RD_KAFKA_RESP_ERR_NON_EMPTY_GROUP = 68;

  /// The group id does not exist
  static const int RD_KAFKA_RESP_ERR_GROUP_ID_NOT_FOUND = 69;

  /// The fetch session ID was not found
  static const int RD_KAFKA_RESP_ERR_FETCH_SESSION_ID_NOT_FOUND = 70;

  /// The fetch session epoch is invalid
  static const int RD_KAFKA_RESP_ERR_INVALID_FETCH_SESSION_EPOCH = 71;

  /// No matching listener
  static const int RD_KAFKA_RESP_ERR_LISTENER_NOT_FOUND = 72;

  /// Topic deletion is disabled
  static const int RD_KAFKA_RESP_ERR_TOPIC_DELETION_DISABLED = 73;

  /// Leader epoch is older than broker epoch
  static const int RD_KAFKA_RESP_ERR_FENCED_LEADER_EPOCH = 74;

  /// Leader epoch is newer than broker epoch
  static const int RD_KAFKA_RESP_ERR_UNKNOWN_LEADER_EPOCH = 75;

  /// Unsupported compression type
  static const int RD_KAFKA_RESP_ERR_UNSUPPORTED_COMPRESSION_TYPE = 76;

  /// Broker epoch has changed
  static const int RD_KAFKA_RESP_ERR_STALE_BROKER_EPOCH = 77;

  /// Leader high watermark is not caught up
  static const int RD_KAFKA_RESP_ERR_OFFSET_NOT_AVAILABLE = 78;

  /// Group member needs a valid member ID
  static const int RD_KAFKA_RESP_ERR_MEMBER_ID_REQUIRED = 79;

  /// Preferred leader was not available
  static const int RD_KAFKA_RESP_ERR_PREFERRED_LEADER_NOT_AVAILABLE = 80;

  /// Consumer group has reached maximum size
  static const int RD_KAFKA_RESP_ERR_GROUP_MAX_SIZE_REACHED = 81;

  /// Static consumer fenced by other consumer with same
  /// group.instance.id.
  static const int RD_KAFKA_RESP_ERR_FENCED_INSTANCE_ID = 82;

  /// Eligible partition leaders are not available
  static const int RD_KAFKA_RESP_ERR_ELIGIBLE_LEADERS_NOT_AVAILABLE = 83;

  /// Leader election not needed for topic partition
  static const int RD_KAFKA_RESP_ERR_ELECTION_NOT_NEEDED = 84;

  /// No partition reassignment is in progress
  static const int RD_KAFKA_RESP_ERR_NO_REASSIGNMENT_IN_PROGRESS = 85;

  /// Deleting offsets of a topic while the consumer group is
  /// subscribed to it
  static const int RD_KAFKA_RESP_ERR_GROUP_SUBSCRIBED_TO_TOPIC = 86;

  /// Broker failed to validate record
  static const int RD_KAFKA_RESP_ERR_INVALID_RECORD = 87;

  /// There are unstable offsets that need to be cleared
  static const int RD_KAFKA_RESP_ERR_UNSTABLE_OFFSET_COMMIT = 88;

  /// Throttling quota has been exceeded
  static const int RD_KAFKA_RESP_ERR_THROTTLING_QUOTA_EXCEEDED = 89;

  /// There is a newer producer with the same transactionalId
  /// which fences the current one
  static const int RD_KAFKA_RESP_ERR_PRODUCER_FENCED = 90;

  /// Request illegally referred to resource that does not exist
  static const int RD_KAFKA_RESP_ERR_RESOURCE_NOT_FOUND = 91;

  /// Request illegally referred to the same resource twice
  static const int RD_KAFKA_RESP_ERR_DUPLICATE_RESOURCE = 92;

  /// Requested credential would not meet criteria for acceptability
  static const int RD_KAFKA_RESP_ERR_UNACCEPTABLE_CREDENTIAL = 93;

  /// Indicates that the either the sender or recipient of a
  /// voter-only request is not one of the expected voters
  static const int RD_KAFKA_RESP_ERR_INCONSISTENT_VOTER_SET = 94;

  /// Invalid update version
  static const int RD_KAFKA_RESP_ERR_INVALID_UPDATE_VERSION = 95;

  /// Unable to update finalized features due to server error
  static const int RD_KAFKA_RESP_ERR_FEATURE_UPDATE_FAILED = 96;

  /// Request principal deserialization failed during forwarding
  static const int RD_KAFKA_RESP_ERR_PRINCIPAL_DESERIALIZATION_FAILURE = 97;

  /// Unknown Topic Id
  static const int RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_ID = 100;

  /// The member epoch is fenced by the group coordinator
  static const int RD_KAFKA_RESP_ERR_FENCED_MEMBER_EPOCH = 110;

  /// The instance ID is still used by another member in the
  /// consumer group
  static const int RD_KAFKA_RESP_ERR_UNRELEASED_INSTANCE_ID = 111;

  /// The assignor or its version range is not supported by the consumer
  /// group
  static const int RD_KAFKA_RESP_ERR_UNSUPPORTED_ASSIGNOR = 112;

  /// The member epoch is stale
  static const int RD_KAFKA_RESP_ERR_STALE_MEMBER_EPOCH = 113;
  static const int RD_KAFKA_RESP_ERR_END_ALL = 114;
}

/// @brief Error code value, name and description.
/// Typically for use with language bindings to automatically expose
/// the full set of librdkafka error codes.
final class rd_kafka_err_desc extends ffi.Struct {
  /// < Error code
  @ffi.Int32()
  external int code;

  /// < Error name, same as code enum sans prefix
  external ffi.Pointer<ffi.Char> name;

  /// < Human readable error description.
  external ffi.Pointer<ffi.Char> desc;
}

typedef rd_kafka_t = rd_kafka_s;
typedef rd_kafka_error_t = rd_kafka_error_s;

/// @brief Generic place holder for a specific Topic+Partition.
///
/// @sa rd_kafka_topic_partition_list_new()
final class rd_kafka_topic_partition_s extends ffi.Struct {
  /// < Topic name
  external ffi.Pointer<ffi.Char> topic;

  /// < Partition
  @ffi.Int32()
  external int partition;

  /// < Offset
  @ffi.Int64()
  external int offset;

  /// < Metadata
  external ffi.Pointer<ffi.Void> metadata;

  /// < Metadata size
  @ffi.Size()
  external int metadata_size;

  /// < Opaque value for application use
  external ffi.Pointer<ffi.Void> opaque;

  /// < Error code, depending on use.
  @ffi.Int32()
  external int err;

  /// < INTERNAL USE ONLY,
  /// INITIALIZE TO ZERO, DO NOT TOUCH,
  /// DO NOT COPY, DO NOT SHARE WITH OTHER
  /// rd_kafka_t INSTANCES.
  external ffi.Pointer<ffi.Void> _private;
}

/// @brief Generic place holder for a specific Topic+Partition.
///
/// @sa rd_kafka_topic_partition_list_new()
typedef rd_kafka_topic_partition_t = rd_kafka_topic_partition_s;

/// @brief A growable list of Topic+Partitions.
final class rd_kafka_topic_partition_list_s extends ffi.Struct {
  /// < Current number of elements
  @ffi.Int()
  external int cnt;

  /// < Current allocated size
  @ffi.Int()
  external int size;

  /// < Element array[]
  external ffi.Pointer<rd_kafka_topic_partition_t> elems;
}

/// @brief A growable list of Topic+Partitions.
typedef rd_kafka_topic_partition_list_t = rd_kafka_topic_partition_list_s;

/// @enum rd_kafka_vtype_t
///
/// @brief Var-arg tag types
///
/// @sa rd_kafka_producev()
abstract class rd_kafka_vtype_t {
  /// < va-arg sentinel
  static const int RD_KAFKA_VTYPE_END = 0;

  /// < (const char *) Topic name
  static const int RD_KAFKA_VTYPE_TOPIC = 1;

  /// < (rd_kafka_topic_t *) Topic handle
  static const int RD_KAFKA_VTYPE_RKT = 2;

  /// < (int32_t) Partition
  static const int RD_KAFKA_VTYPE_PARTITION = 3;

  /// < (void *, size_t) Message value (payload)
  static const int RD_KAFKA_VTYPE_VALUE = 4;

  /// < (void *, size_t) Message key
  static const int RD_KAFKA_VTYPE_KEY = 5;

  /// < (void *) Per-message application opaque
  /// value. This is the same as
  /// the _private field in
  /// rd_kafka_message_t, also known
  /// as the msg_opaque.
  static const int RD_KAFKA_VTYPE_OPAQUE = 6;

  /// < (int) RD_KAFKA_MSG_F_.. flags
  static const int RD_KAFKA_VTYPE_MSGFLAGS = 7;

  /// < (int64_t) Milliseconds since epoch UTC
  static const int RD_KAFKA_VTYPE_TIMESTAMP = 8;

  /// < (const char *, const void *, ssize_t)
  /// Message Header
  static const int RD_KAFKA_VTYPE_HEADER = 9;

  /// < (rd_kafka_headers_t *) Headers list
  static const int RD_KAFKA_VTYPE_HEADERS = 10;
}

/// @brief VTYPE + argument container for use with rd_kafka_produce_va()
///
/// See RD_KAFKA_V_..() macros below for which union field corresponds
/// to which RD_KAFKA_VTYPE_...
final class rd_kafka_vu_s extends ffi.Struct {
  /// < RD_KAFKA_VTYPE_..
  @ffi.Int32()
  external int vtype;

  external UnnamedUnion1 u;
}

/// Value union, see RD_KAFKA_V_.. macros for which field to use.
final class UnnamedUnion1 extends ffi.Union {
  external ffi.Pointer<ffi.Char> cstr;

  external ffi.Pointer<rd_kafka_topic_t> rkt;

  @ffi.Int()
  external int i;

  @ffi.Int32()
  external int i32;

  @ffi.Int64()
  external int i64;

  external UnnamedStruct1 mem;

  external UnnamedStruct2 header;

  external ffi.Pointer<rd_kafka_headers_t> headers;

  external ffi.Pointer<ffi.Void> ptr;

  /// < Padding size for future-proofness
  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> _pad;
}

typedef rd_kafka_topic_t = rd_kafka_topic_s;

final class UnnamedStruct1 extends ffi.Struct {
  external ffi.Pointer<ffi.Void> ptr;

  @ffi.Size()
  external int size;
}

final class UnnamedStruct2 extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  external ffi.Pointer<ffi.Void> val;

  @ssize_t()
  external int size;
}

typedef rd_kafka_headers_t = rd_kafka_headers_s;

/// @brief A Kafka message as returned by the \c rd_kafka_consume*() family
/// of functions as well as provided to the Producer \c dr_msg_cb().
///
/// For the consumer this object has two purposes:
/// - provide the application with a consumed message. (\c err == 0)
/// - report per-topic+partition consumer errors (\c err != 0)
///
/// The application must check \c err to decide what action to take.
///
/// When the application is finished with a message it must call
/// rd_kafka_message_destroy() unless otherwise noted.
final class rd_kafka_message_s extends ffi.Struct {
  /// < Non-zero for error signaling.
  @ffi.Int32()
  external int err;

  /// < Topic
  external ffi.Pointer<rd_kafka_topic_t> rkt;

  /// < Partition
  @ffi.Int32()
  external int partition;

  /// < Producer: original message payload.
  /// Consumer: Depends on the value of \c err :
  /// - \c err==0: Message payload.
  /// - \c err!=0: Error string
  external ffi.Pointer<ffi.Void> payload;

  /// < Depends on the value of \c err :
  /// - \c err==0: Message payload length
  /// - \c err!=0: Error string length
  @ffi.Size()
  external int len;

  /// < Depends on the value of \c err :
  /// - \c err==0: Optional message key
  external ffi.Pointer<ffi.Void> key;

  /// < Depends on the value of \c err :
  /// - \c err==0: Optional message key length
  @ffi.Size()
  external int key_len;

  /// < Consumer:
  /// - Message offset (or offset for error
  /// if \c err!=0 if applicable).
  /// Producer, dr_msg_cb:
  /// Message offset assigned by broker.
  /// May be RD_KAFKA_OFFSET_INVALID
  /// for retried messages when
  /// idempotence is enabled.
  @ffi.Int64()
  external int offset;

  /// < Consumer:
  /// - rdkafka private pointer:
  /// DO NOT MODIFY, DO NOT COPY.
  /// Producer:
  /// - dr_msg_cb:
  /// msg_opaque from produce() call or
  /// RD_KAFKA_V_OPAQUE from producev().
  external ffi.Pointer<ffi.Void> _private;
}

/// @brief A Kafka message as returned by the \c rd_kafka_consume*() family
/// of functions as well as provided to the Producer \c dr_msg_cb().
///
/// For the consumer this object has two purposes:
/// - provide the application with a consumed message. (\c err == 0)
/// - report per-topic+partition consumer errors (\c err != 0)
///
/// The application must check \c err to decide what action to take.
///
/// When the application is finished with a message it must call
/// rd_kafka_message_destroy() unless otherwise noted.
typedef rd_kafka_message_t = rd_kafka_message_s;

/// @enum rd_kafka_msg_status_t
/// @brief Message persistence status can be used by the application to
/// find out if a produced message was persisted in the topic log.
abstract class rd_kafka_msg_status_t {
  /// Message was never transmitted to the broker, or failed with
  /// an error indicating it was not written to the log.
  /// Application retry risks ordering, but not duplication.
  static const int RD_KAFKA_MSG_STATUS_NOT_PERSISTED = 0;

  /// Message was transmitted to broker, but no acknowledgement was
  /// received.
  /// Application retry risks ordering and duplication.
  static const int RD_KAFKA_MSG_STATUS_POSSIBLY_PERSISTED = 1;

  /// Message was written to the log and acknowledged by the broker.
  /// No reason for application to retry.
  /// Note: this value should only be trusted with \c acks=all.
  static const int RD_KAFKA_MSG_STATUS_PERSISTED = 2;
}

typedef rd_kafka_Uuid_t = rd_kafka_Uuid_s;

/// @enum rd_kafka_conf_res_t
/// @brief Configuration result type
abstract class rd_kafka_conf_res_t {
  /// < Unknown configuration name.
  static const int RD_KAFKA_CONF_UNKNOWN = -2;

  /// < Invalid configuration value or
  /// property or value not supported in
  /// this build.
  static const int RD_KAFKA_CONF_INVALID = -1;

  /// < Configuration okay
  static const int RD_KAFKA_CONF_OK = 0;
}

typedef rd_kafka_conf_t = rd_kafka_conf_s;
typedef rd_kafka_event_t = rd_kafka_op_s;
typedef mode_t = __darwin_mode_t;
typedef __darwin_mode_t = __uint16_t;

/// Forward declaration to avoid netdb.h or winsock includes
final class addrinfo extends ffi.Opaque {}

/// @enum rd_kafka_cert_type_t
///
/// @brief SSL certificate type
///
/// @sa rd_kafka_conf_set_ssl_cert
abstract class rd_kafka_cert_type_t {
  /// < Client's public key
  static const int RD_KAFKA_CERT_PUBLIC_KEY = 0;

  /// < Client's private key
  static const int RD_KAFKA_CERT_PRIVATE_KEY = 1;

  /// < CA certificate
  static const int RD_KAFKA_CERT_CA = 2;
  static const int RD_KAFKA_CERT__CNT = 3;
}

/// @enum rd_kafka_cert_enc_t
///
/// @brief SSL certificate encoding
///
/// @sa rd_kafka_conf_set_ssl_cert
abstract class rd_kafka_cert_enc_t {
  /// < PKCS#12
  static const int RD_KAFKA_CERT_ENC_PKCS12 = 0;

  /// < DER / binary X.509 ASN1
  static const int RD_KAFKA_CERT_ENC_DER = 1;

  /// < PEM
  static const int RD_KAFKA_CERT_ENC_PEM = 2;
  static const int RD_KAFKA_CERT_ENC__CNT = 3;
}

typedef rd_kafka_topic_conf_t = rd_kafka_topic_conf_s;
typedef rd_kafka_queue_t = rd_kafka_queue_s;
typedef rd_kafka_consumer_group_metadata_t = rd_kafka_consumer_group_metadata_s;

/// @brief VTYPE + argument container for use with rd_kafka_produce_va()
///
/// See RD_KAFKA_V_..() macros below for which union field corresponds
/// to which RD_KAFKA_VTYPE_...
typedef rd_kafka_vu_t = rd_kafka_vu_s;

/// @brief Broker information
final class rd_kafka_metadata_broker extends ffi.Struct {
  /// < Broker Id
  @ffi.Int32()
  external int id;

  /// < Broker hostname
  external ffi.Pointer<ffi.Char> host;

  /// < Broker listening port
  @ffi.Int()
  external int port;
}

/// @brief Partition information
final class rd_kafka_metadata_partition extends ffi.Struct {
  /// < Partition Id
  @ffi.Int32()
  external int id;

  /// < Partition error reported by broker
  @ffi.Int32()
  external int err;

  /// < Leader broker
  @ffi.Int32()
  external int leader;

  /// < Number of brokers in \p replicas
  @ffi.Int()
  external int replica_cnt;

  /// < Replica brokers
  external ffi.Pointer<ffi.Int32> replicas;

  /// < Number of ISR brokers in \p isrs
  @ffi.Int()
  external int isr_cnt;

  /// < In-Sync-Replica brokers
  external ffi.Pointer<ffi.Int32> isrs;
}

/// @brief Topic information
final class rd_kafka_metadata_topic extends ffi.Struct {
  /// < Topic name
  external ffi.Pointer<ffi.Char> topic;

  /// < Number of partitions in \p partitions
  @ffi.Int()
  external int partition_cnt;

  /// < Partitions
  external ffi.Pointer<rd_kafka_metadata_partition> partitions;

  /// < Topic error reported by broker
  @ffi.Int32()
  external int err;
}

/// @brief Metadata container
final class rd_kafka_metadata extends ffi.Struct {
  /// < Number of brokers in \p brokers
  @ffi.Int()
  external int broker_cnt;

  /// < Brokers
  external ffi.Pointer<rd_kafka_metadata_broker> brokers;

  /// < Number of topics in \p topics
  @ffi.Int()
  external int topic_cnt;

  /// < Topics
  external ffi.Pointer<rd_kafka_metadata_topic> topics;

  /// < Broker originating this metadata
  @ffi.Int32()
  external int orig_broker_id;

  /// < Name of originating broker
  external ffi.Pointer<ffi.Char> orig_broker_name;
}

final class rd_kafka_Node_s extends ffi.Opaque {}

/// @brief Node (broker) information.
typedef rd_kafka_Node_t = rd_kafka_Node_s;

/// @brief Group member information
///
/// For more information on \p member_metadata format, see
/// https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-GroupMembershipAPI
final class rd_kafka_group_member_info extends ffi.Struct {
  /// < Member id (generated by broker)
  external ffi.Pointer<ffi.Char> member_id;

  /// < Client's \p client.id
  external ffi.Pointer<ffi.Char> client_id;

  /// < Client's hostname
  external ffi.Pointer<ffi.Char> client_host;

  /// < Member metadata (binary),
  /// format depends on \p protocol_type.
  external ffi.Pointer<ffi.Void> member_metadata;

  /// < Member metadata size in bytes
  @ffi.Int()
  external int member_metadata_size;

  /// < Member assignment (binary),
  /// format depends on \p protocol_type.
  external ffi.Pointer<ffi.Void> member_assignment;

  /// < Member assignment size in bytes
  @ffi.Int()
  external int member_assignment_size;
}

/// @enum rd_kafka_consumer_group_state_t
///
/// @brief Consumer group state.
abstract class rd_kafka_consumer_group_state_t {
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_UNKNOWN = 0;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_PREPARING_REBALANCE = 1;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_COMPLETING_REBALANCE = 2;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_STABLE = 3;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_DEAD = 4;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE_EMPTY = 5;
  static const int RD_KAFKA_CONSUMER_GROUP_STATE__CNT = 6;
}

/// @brief Group information
final class rd_kafka_group_info extends ffi.Struct {
  /// < Originating broker info
  external rd_kafka_metadata_broker broker;

  /// < Group name
  external ffi.Pointer<ffi.Char> group;

  /// < Broker-originated error
  @ffi.Int32()
  external int err;

  /// < Group state
  external ffi.Pointer<ffi.Char> state;

  /// < Group protocol type
  external ffi.Pointer<ffi.Char> protocol_type;

  /// < Group protocol
  external ffi.Pointer<ffi.Char> protocol;

  /// < Group members
  external ffi.Pointer<rd_kafka_group_member_info> members;

  /// < Group member count
  @ffi.Int()
  external int member_cnt;
}

/// @brief List of groups
///
/// @sa rd_kafka_group_list_destroy() to release list memory.
final class rd_kafka_group_list extends ffi.Struct {
  /// < Groups
  external ffi.Pointer<rd_kafka_group_info> groups;

  /// < Group count
  @ffi.Int()
  external int group_cnt;
}

/// @enum rd_kafka_thread_type_t
///
/// @brief librdkafka internal thread type.
///
/// @sa rd_kafka_interceptor_add_on_thread_start()
abstract class rd_kafka_thread_type_t {
  /// < librdkafka's internal main thread
  static const int RD_KAFKA_THREAD_MAIN = 0;

  /// < Background thread (if enabled)
  static const int RD_KAFKA_THREAD_BACKGROUND = 1;

  /// < Per-broker thread
  static const int RD_KAFKA_THREAD_BROKER = 2;
}

/// @brief Event types
typedef rd_kafka_event_type_t = ffi.Int;
typedef Dartrd_kafka_event_type_t = int;

/// ! CreateTopics result type
typedef rd_kafka_CreateTopics_result_t = rd_kafka_event_t;

/// ! DeleteTopics result type
typedef rd_kafka_DeleteTopics_result_t = rd_kafka_event_t;

/// ! CreatePartitions result type
typedef rd_kafka_CreatePartitions_result_t = rd_kafka_event_t;

/// ! AlterConfigs result type
typedef rd_kafka_AlterConfigs_result_t = rd_kafka_event_t;

/// ! IncrementalAlterConfigs result type
typedef rd_kafka_IncrementalAlterConfigs_result_t = rd_kafka_event_t;

/// ! CreateTopics result type
typedef rd_kafka_DescribeConfigs_result_t = rd_kafka_event_t;

/// ! DeleteRecords result type
typedef rd_kafka_DeleteRecords_result_t = rd_kafka_event_t;

/// ! ListConsumerGroups result type
typedef rd_kafka_ListConsumerGroups_result_t = rd_kafka_event_t;

/// ! DescribeConsumerGroups result type
typedef rd_kafka_DescribeConsumerGroups_result_t = rd_kafka_event_t;

/// ! DescribeTopics result type
typedef rd_kafka_DescribeTopics_result_t = rd_kafka_event_t;

/// ! DescribeCluster result type
typedef rd_kafka_DescribeCluster_result_t = rd_kafka_event_t;

/// ! DeleteGroups result type
typedef rd_kafka_DeleteGroups_result_t = rd_kafka_event_t;

/// ! DeleteConsumerGroupOffsets result type
typedef rd_kafka_DeleteConsumerGroupOffsets_result_t = rd_kafka_event_t;

/// ! CreateAcls result type
typedef rd_kafka_CreateAcls_result_t = rd_kafka_event_t;

/// ! DescribeAcls result type
typedef rd_kafka_DescribeAcls_result_t = rd_kafka_event_t;

/// ! DeleteAcls result type
typedef rd_kafka_DeleteAcls_result_t = rd_kafka_event_t;

/// ! ListConsumerGroupOffsets result type
typedef rd_kafka_ListConsumerGroupOffsets_result_t = rd_kafka_event_t;

/// ! AlterConsumerGroupOffsets result type
typedef rd_kafka_AlterConsumerGroupOffsets_result_t = rd_kafka_event_t;

/// ! ListOffsets result type
typedef rd_kafka_ListOffsets_result_t = rd_kafka_event_t;

/// ! DescribeUserScramCredentials result type
typedef rd_kafka_DescribeUserScramCredentials_result_t = rd_kafka_event_t;

/// ! AlterUserScramCredentials result type
typedef rd_kafka_AlterUserScramCredentials_result_t = rd_kafka_event_t;

/// @brief on_conf_set() is called from rd_kafka_*_conf_set() in the order
/// the interceptors were added.
///
/// @param conf Configuration object.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
/// @param name The configuration property to set.
/// @param val The configuration value to set, or NULL for reverting to default
/// in which case the previous value should be freed.
/// @param errstr A human readable error string in case the interceptor fails.
/// @param errstr_size Maximum space (including \0) in \p errstr.
///
/// @returns RD_KAFKA_CONF_OK if the property was known and successfully
/// handled by the interceptor, RD_KAFKA_CONF_INVALID if the
/// property was handled by the interceptor but the value was invalid,
/// or RD_KAFKA_CONF_UNKNOWN if the interceptor did not handle
/// this property, in which case the property is passed on on the
/// interceptor in the chain, finally ending up at the built-in
/// configuration handler.
typedef rd_kafka_interceptor_f_on_conf_set_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_conf_t> conf,
        ffi.Pointer<ffi.Char> name,
        ffi.Pointer<ffi.Char> val,
        ffi.Pointer<ffi.Char> errstr,
        ffi.Size errstr_size,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_conf_dup() is called from rd_kafka_conf_dup() in the
/// order the interceptors were added and is used to let
/// an interceptor re-register its conf interecptors with a new
/// opaque value.
/// The on_conf_dup() method is called prior to the configuration from
/// \p old_conf being copied to \p new_conf.
///
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
/// @param new_conf New configuration object.
/// @param old_conf Old configuration object to copy properties from.
/// @param filter_cnt Number of property names to filter in \p filter.
/// @param filter Property names to filter out (ignore) when setting up
/// \p new_conf.
///
/// @returns RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code
/// on failure (which is logged but otherwise ignored).
///
/// @remark No on_conf_* interceptors are copied to the new configuration
/// object on rd_kafka_conf_dup().
typedef rd_kafka_interceptor_f_on_conf_dup_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_conf_t> new_conf,
        ffi.Pointer<rd_kafka_conf_t> old_conf,
        ffi.Size filter_cnt,
        ffi.Pointer<ffi.Pointer<ffi.Char>> filter,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_conf_destroy() is called from rd_kafka_*_conf_destroy() in the
/// order the interceptors were added.
///
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
typedef rd_kafka_interceptor_f_on_conf_destroy_t
    = ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_new() is called from rd_kafka_new() prior toreturning
/// the newly created client instance to the application.
///
/// @param rk The client instance.
/// @param conf The client instance's final configuration.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
/// @param errstr A human readable error string in case the interceptor fails.
/// @param errstr_size Maximum space (including \0) in \p errstr.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
///
/// @warning The \p rk client instance will not be fully set up when this
/// interceptor is called and the interceptor MUST NOT call any
/// other rk-specific APIs than rd_kafka_interceptor_add..().
typedef rd_kafka_interceptor_f_on_new_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Pointer<rd_kafka_conf_t> conf,
        ffi.Pointer<ffi.Void> ic_opaque,
        ffi.Pointer<ffi.Char> errstr,
        ffi.Size errstr_size)>;

/// @brief on_destroy() is called from rd_kafka_destroy() or (rd_kafka_new()
/// if rd_kafka_new() fails during initialization).
///
/// @param rk The client instance.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
typedef rd_kafka_interceptor_f_on_destroy_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk, ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_send() is called from rd_kafka_produce*() (et.al) prior to
/// the partitioner being called.
///
/// @param rk The client instance.
/// @param rkmessage The message being produced. Immutable.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @remark This interceptor is only used by producer instances.
///
/// @remark The \p rkmessage object is NOT mutable and MUST NOT be modified
/// by the interceptor.
///
/// @remark If the partitioner fails or an unknown partition was specified,
/// the on_acknowledgement() interceptor chain will be called from
/// within the rd_kafka_produce*() call to maintain send-acknowledgement
/// symmetry.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_send_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Pointer<rd_kafka_message_t> rkmessage,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_acknowledgement() is called to inform interceptors that a message
/// was succesfully delivered or permanently failed delivery.
/// The interceptor chain is called from internal librdkafka background
/// threads, or rd_kafka_produce*() if the partitioner failed.
///
/// @param rk The client instance.
/// @param rkmessage The message being produced. Immutable.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @remark This interceptor is only used by producer instances.
///
/// @remark The \p rkmessage object is NOT mutable and MUST NOT be modified
/// by the interceptor.
///
/// @warning The on_acknowledgement() method may be called from internal
/// librdkafka threads. An on_acknowledgement() interceptor MUST NOT
/// call any librdkafka API's associated with the \p rk, or perform
/// any blocking or prolonged work.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_acknowledgement_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Pointer<rd_kafka_message_t> rkmessage,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_consume() is called just prior to passing the message to the
/// application in rd_kafka_consumer_poll(), rd_kafka_consume*(),
/// the event interface, etc.
///
/// @param rk The client instance.
/// @param rkmessage The message being consumed. Immutable.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @remark This interceptor is only used by consumer instances.
///
/// @remark The \p rkmessage object is NOT mutable and MUST NOT be modified
/// by the interceptor.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_consume_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Pointer<rd_kafka_message_t> rkmessage,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_commit() is called on completed or failed offset commit.
/// It is called from internal librdkafka threads.
///
/// @param rk The client instance.
/// @param offsets List of topic+partition+offset+error that were committed.
/// The error message of each partition should be checked for
/// error.
/// @param err The commit error, if any.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @remark This interceptor is only used by consumer instances.
///
/// @warning The on_commit() interceptor is called from internal
/// librdkafka threads. An on_commit() interceptor MUST NOT
/// call any librdkafka API's associated with the \p rk, or perform
/// any blocking or prolonged work.
///
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_commit_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Pointer<rd_kafka_topic_partition_list_t> offsets,
        ffi.Int32 err,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_request_sent() is called when a request has been fully written
/// to a broker TCP connections socket.
///
/// @param rk The client instance.
/// @param sockfd Socket file descriptor.
/// @param brokername Broker request is being sent to.
/// @param brokerid Broker request is being sent to.
/// @param ApiKey Kafka protocol request type.
/// @param ApiVersion Kafka protocol request type version.
/// @param CorrId Kafka protocol request correlation id.
/// @param size Size of request.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @warning The on_request_sent() interceptor is called from internal
/// librdkafka broker threads. An on_request_sent() interceptor MUST NOT
/// call any librdkafka API's associated with the \p rk, or perform
/// any blocking or prolonged work.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_request_sent_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Int sockfd,
        ffi.Pointer<ffi.Char> brokername,
        ffi.Int32 brokerid,
        ffi.Int16 ApiKey,
        ffi.Int16 ApiVersion,
        ffi.Int32 CorrId,
        ffi.Size size,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_response_received() is called when a protocol response has been
/// fully received from a broker TCP connection socket but before the
/// response payload is parsed.
///
/// @param rk The client instance.
/// @param sockfd Socket file descriptor (always -1).
/// @param brokername Broker response was received from, possibly empty string
/// on error.
/// @param brokerid Broker response was received from.
/// @param ApiKey Kafka protocol request type or -1 on error.
/// @param ApiVersion Kafka protocol request type version or -1 on error.
/// @param CorrId Kafka protocol request correlation id, possibly -1 on error.
/// @param size Size of response, possibly 0 on error.
/// @param rtt Request round-trip-time in microseconds, possibly -1 on error.
/// @param err Receive error.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @warning The on_response_received() interceptor is called from internal
/// librdkafka broker threads. An on_response_received() interceptor
/// MUST NOT call any librdkafka API's associated with the \p rk, or
/// perform any blocking or prolonged work.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_response_received_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Int sockfd,
        ffi.Pointer<ffi.Char> brokername,
        ffi.Int32 brokerid,
        ffi.Int16 ApiKey,
        ffi.Int16 ApiVersion,
        ffi.Int32 CorrId,
        ffi.Size size,
        ffi.Int64 rtt,
        ffi.Int32 err,
        ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_thread_start() is called from a newly created librdkafka-managed
/// thread.
///
/// @param rk The client instance.
/// @param thread_type Thread type.
/// @param thread_name Human-readable thread name, may not be unique.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @warning The on_thread_start() interceptor is called from internal
/// librdkafka threads. An on_thread_start() interceptor MUST NOT
/// call any librdkafka API's associated with the \p rk, or perform
/// any blocking or prolonged work.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_thread_start_t = ffi.NativeFunction<
    ffi.Int32 Function(ffi.Pointer<rd_kafka_t> rk, ffi.Int32 thread_type,
        ffi.Pointer<ffi.Char> thread_name, ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_thread_exit() is called just prior to a librdkafka-managed
/// thread exiting from the exiting thread itself.
///
/// @param rk The client instance.
/// @param thread_type Thread type.n
/// @param thread_name Human-readable thread name, may not be unique.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @remark Depending on the thread type, librdkafka may execute additional
/// code on the thread after on_thread_exit() returns.
///
/// @warning The on_thread_exit() interceptor is called from internal
/// librdkafka threads. An on_thread_exit() interceptor MUST NOT
/// call any librdkafka API's associated with the \p rk, or perform
/// any blocking or prolonged work.
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_thread_exit_t = ffi.NativeFunction<
    ffi.Int32 Function(ffi.Pointer<rd_kafka_t> rk, ffi.Int32 thread_type,
        ffi.Pointer<ffi.Char> thread_name, ffi.Pointer<ffi.Void> ic_opaque)>;

/// @brief on_broker_state_change() is called just after a broker
/// has been created or its state has been changed.
///
/// @param rk The client instance.
/// @param broker_id The broker id (-1 is used for bootstrap brokers).
/// @param secproto The security protocol.
/// @param name The original name of the broker.
/// @param port The port of the broker.
/// @param state Broker state name.
/// @param ic_opaque The interceptor's opaque pointer specified in ..add..().
///
/// @returns an error code on failure, the error is logged but otherwise ignored.
typedef rd_kafka_interceptor_f_on_broker_state_change_t = ffi.NativeFunction<
    ffi.Int32 Function(
        ffi.Pointer<rd_kafka_t> rk,
        ffi.Int32 broker_id,
        ffi.Pointer<ffi.Char> secproto,
        ffi.Pointer<ffi.Char> name,
        ffi.Int port,
        ffi.Pointer<ffi.Char> state,
        ffi.Pointer<ffi.Void> ic_opaque)>;
typedef rd_kafka_topic_result_t = rd_kafka_topic_result_s;
typedef rd_kafka_group_result_t = rd_kafka_group_result_s;

/// @enum rd_kafka_admin_op_t
///
/// @brief Admin operation enum name for use with rd_kafka_AdminOptions_new()
///
/// @sa rd_kafka_AdminOptions_new()
abstract class rd_kafka_admin_op_t {
  /// < Default value
  static const int RD_KAFKA_ADMIN_OP_ANY = 0;

  /// < CreateTopics
  static const int RD_KAFKA_ADMIN_OP_CREATETOPICS = 1;

  /// < DeleteTopics
  static const int RD_KAFKA_ADMIN_OP_DELETETOPICS = 2;

  /// < CreatePartitions
  static const int RD_KAFKA_ADMIN_OP_CREATEPARTITIONS = 3;

  /// < AlterConfigs
  static const int RD_KAFKA_ADMIN_OP_ALTERCONFIGS = 4;

  /// < DescribeConfigs
  static const int RD_KAFKA_ADMIN_OP_DESCRIBECONFIGS = 5;

  /// < DeleteRecords
  static const int RD_KAFKA_ADMIN_OP_DELETERECORDS = 6;

  /// < DeleteGroups
  static const int RD_KAFKA_ADMIN_OP_DELETEGROUPS = 7;

  /// DeleteConsumerGroupOffsets
  static const int RD_KAFKA_ADMIN_OP_DELETECONSUMERGROUPOFFSETS = 8;

  /// < CreateAcls
  static const int RD_KAFKA_ADMIN_OP_CREATEACLS = 9;

  /// < DescribeAcls
  static const int RD_KAFKA_ADMIN_OP_DESCRIBEACLS = 10;

  /// < DeleteAcls
  static const int RD_KAFKA_ADMIN_OP_DELETEACLS = 11;

  /// < ListConsumerGroups
  static const int RD_KAFKA_ADMIN_OP_LISTCONSUMERGROUPS = 12;

  /// < DescribeConsumerGroups
  static const int RD_KAFKA_ADMIN_OP_DESCRIBECONSUMERGROUPS = 13;

  /// ListConsumerGroupOffsets
  static const int RD_KAFKA_ADMIN_OP_LISTCONSUMERGROUPOFFSETS = 14;

  /// AlterConsumerGroupOffsets
  static const int RD_KAFKA_ADMIN_OP_ALTERCONSUMERGROUPOFFSETS = 15;

  /// IncrementalAlterConfigs
  static const int RD_KAFKA_ADMIN_OP_INCREMENTALALTERCONFIGS = 16;

  /// DescribeUserScramCredentials
  static const int RD_KAFKA_ADMIN_OP_DESCRIBEUSERSCRAMCREDENTIALS = 17;

  /// AlterUserScramCredentials
  static const int RD_KAFKA_ADMIN_OP_ALTERUSERSCRAMCREDENTIALS = 18;

  /// < DescribeTopics
  static const int RD_KAFKA_ADMIN_OP_DESCRIBETOPICS = 19;

  /// < DescribeCluster
  static const int RD_KAFKA_ADMIN_OP_DESCRIBECLUSTER = 20;

  /// < ListOffsets
  static const int RD_KAFKA_ADMIN_OP_LISTOFFSETS = 21;

  /// < Number of ops defined
  static const int RD_KAFKA_ADMIN_OP__CNT = 22;
}

final class rd_kafka_AdminOptions_s extends ffi.Opaque {}

/// @enum rd_kafka_IsolationLevel_t
///
/// @brief IsolationLevel enum name for use with rd_kafka_AdminOptions_new()
///
/// @sa rd_kafka_AdminOptions_new()
abstract class rd_kafka_IsolationLevel_t {
  static const int RD_KAFKA_ISOLATION_LEVEL_READ_UNCOMMITTED = 0;
  static const int RD_KAFKA_ISOLATION_LEVEL_READ_COMMITTED = 1;
}

/// @brief AdminOptions provides a generic mechanism for setting optional
/// parameters for the Admin API requests.
///
/// @remark Since AdminOptions is decoupled from the actual request type
/// there is no enforcement to prevent setting unrelated properties,
/// e.g. setting validate_only on a DescribeConfigs request is allowed
/// but is silently ignored by DescribeConfigs.
/// Future versions may introduce such enforcement.
typedef rd_kafka_AdminOptions_t = rd_kafka_AdminOptions_s;

/// @enum rd_kafka_AclOperation_t
/// @brief Apache Kafka ACL operation types. Common type for multiple Admin API
/// functions.
abstract class rd_kafka_AclOperation_t {
  /// < Unknown
  static const int RD_KAFKA_ACL_OPERATION_UNKNOWN = 0;
  static const int RD_KAFKA_ACL_OPERATION_ANY = 1;

  /// < ALL operation
  static const int RD_KAFKA_ACL_OPERATION_ALL = 2;

  /// < READ operation
  static const int RD_KAFKA_ACL_OPERATION_READ = 3;

  /// < WRITE operation
  static const int RD_KAFKA_ACL_OPERATION_WRITE = 4;

  /// < CREATE operation
  static const int RD_KAFKA_ACL_OPERATION_CREATE = 5;

  /// < DELETE operation
  static const int RD_KAFKA_ACL_OPERATION_DELETE = 6;

  /// < ALTER operation
  static const int RD_KAFKA_ACL_OPERATION_ALTER = 7;

  /// < DESCRIBE operation
  static const int RD_KAFKA_ACL_OPERATION_DESCRIBE = 8;
  static const int RD_KAFKA_ACL_OPERATION_CLUSTER_ACTION = 9;
  static const int RD_KAFKA_ACL_OPERATION_DESCRIBE_CONFIGS = 10;
  static const int RD_KAFKA_ACL_OPERATION_ALTER_CONFIGS = 11;
  static const int RD_KAFKA_ACL_OPERATION_IDEMPOTENT_WRITE = 12;
  static const int RD_KAFKA_ACL_OPERATION__CNT = 13;
}

final class rd_kafka_NewTopic_s extends ffi.Opaque {}

/// ! Defines a new topic to be created.
typedef rd_kafka_NewTopic_t = rd_kafka_NewTopic_s;

final class rd_kafka_DeleteTopic_s extends ffi.Opaque {}

/// ! Represents a topic to be deleted.
typedef rd_kafka_DeleteTopic_t = rd_kafka_DeleteTopic_s;

final class rd_kafka_NewPartitions_s extends ffi.Opaque {}

/// ! Defines a new partition to be created.
typedef rd_kafka_NewPartitions_t = rd_kafka_NewPartitions_s;

/// @enum rd_kafka_ConfigSource_t
///
/// @brief Apache Kafka config sources.
///
/// @remark These entities relate to the cluster, not the local client.
///
/// @sa rd_kafka_conf_set(), et.al. for local client configuration.
abstract class rd_kafka_ConfigSource_t {
  /// Source unknown, e.g., in the ConfigEntry used for alter requests
  /// where source is not set
  static const int RD_KAFKA_CONFIG_SOURCE_UNKNOWN_CONFIG = 0;

  /// Dynamic topic config that is configured for a specific topic
  static const int RD_KAFKA_CONFIG_SOURCE_DYNAMIC_TOPIC_CONFIG = 1;

  /// Dynamic broker config that is configured for a specific broker
  static const int RD_KAFKA_CONFIG_SOURCE_DYNAMIC_BROKER_CONFIG = 2;

  /// Dynamic broker config that is configured as default for all
  /// brokers in the cluster
  static const int RD_KAFKA_CONFIG_SOURCE_DYNAMIC_DEFAULT_BROKER_CONFIG = 3;

  /// Static broker config provided as broker properties at startup
  /// (e.g. from server.properties file)
  static const int RD_KAFKA_CONFIG_SOURCE_STATIC_BROKER_CONFIG = 4;

  /// Built-in default configuration for configs that have a
  /// default value
  static const int RD_KAFKA_CONFIG_SOURCE_DEFAULT_CONFIG = 5;

  /// Number of source types defined
  static const int RD_KAFKA_CONFIG_SOURCE__CNT = 6;
}

final class rd_kafka_ConfigEntry_s extends ffi.Opaque {}

/// ! Apache Kafka configuration entry.
typedef rd_kafka_ConfigEntry_t = rd_kafka_ConfigEntry_s;

/// @enum rd_kafka_ResourceType_t
/// @brief Apache Kafka resource types
abstract class rd_kafka_ResourceType_t {
  /// < Unknown
  static const int RD_KAFKA_RESOURCE_UNKNOWN = 0;

  /// < Any (used for lookups)
  static const int RD_KAFKA_RESOURCE_ANY = 1;

  /// < Topic
  static const int RD_KAFKA_RESOURCE_TOPIC = 2;

  /// < Group
  static const int RD_KAFKA_RESOURCE_GROUP = 3;

  /// < Broker
  static const int RD_KAFKA_RESOURCE_BROKER = 4;

  /// < Number of resource types defined
  static const int RD_KAFKA_RESOURCE__CNT = 5;
}

/// @enum rd_kafka_ResourcePatternType_t
/// @brief Apache Kafka pattern types
abstract class rd_kafka_ResourcePatternType_t {
  /// Unknown
  static const int RD_KAFKA_RESOURCE_PATTERN_UNKNOWN = 0;

  /// Any (used for lookups)
  static const int RD_KAFKA_RESOURCE_PATTERN_ANY = 1;

  /// Match: will perform pattern matching
  static const int RD_KAFKA_RESOURCE_PATTERN_MATCH = 2;

  /// Literal: A literal resource name
  static const int RD_KAFKA_RESOURCE_PATTERN_LITERAL = 3;

  /// Prefixed: A prefixed resource name
  static const int RD_KAFKA_RESOURCE_PATTERN_PREFIXED = 4;
  static const int RD_KAFKA_RESOURCE_PATTERN_TYPE__CNT = 5;
}

/// @enum rd_kafka_AlterConfigOpType_t
/// @brief Incremental alter configs operations.
abstract class rd_kafka_AlterConfigOpType_t {
  static const int RD_KAFKA_ALTER_CONFIG_OP_TYPE_SET = 0;
  static const int RD_KAFKA_ALTER_CONFIG_OP_TYPE_DELETE = 1;
  static const int RD_KAFKA_ALTER_CONFIG_OP_TYPE_APPEND = 2;
  static const int RD_KAFKA_ALTER_CONFIG_OP_TYPE_SUBTRACT = 3;
  static const int RD_KAFKA_ALTER_CONFIG_OP_TYPE__CNT = 4;
}

final class rd_kafka_ConfigResource_s extends ffi.Opaque {}

/// ! Apache Kafka configuration resource.
typedef rd_kafka_ConfigResource_t = rd_kafka_ConfigResource_s;

final class rd_kafka_DeleteRecords_s extends ffi.Opaque {}

/// ! Represents records to be deleted
typedef rd_kafka_DeleteRecords_t = rd_kafka_DeleteRecords_s;

final class rd_kafka_TopicCollection_s extends ffi.Opaque {}

final class rd_kafka_TopicPartitionInfo_s extends ffi.Opaque {}

final class rd_kafka_TopicDescription_s extends ffi.Opaque {}

/// @brief Represents a collection of topics, to be passed to DescribeTopics.
typedef rd_kafka_TopicCollection_t = rd_kafka_TopicCollection_s;

/// @brief DescribeTopics result type.
typedef rd_kafka_TopicDescription_t = rd_kafka_TopicDescription_s;

/// @brief TopicPartition represents a partition in the DescribeTopics result.
typedef rd_kafka_TopicPartitionInfo_t = rd_kafka_TopicPartitionInfo_s;

final class rd_kafka_ConsumerGroupListing_s extends ffi.Opaque {}

final class rd_kafka_ListConsumerGroupsResult_s extends ffi.Opaque {}

/// ! ListConsumerGroups result for a single group
typedef rd_kafka_ConsumerGroupListing_t = rd_kafka_ConsumerGroupListing_s;

final class rd_kafka_ConsumerGroupDescription_s extends ffi.Opaque {}

final class rd_kafka_MemberDescription_s extends ffi.Opaque {}

final class rd_kafka_MemberAssignment_s extends ffi.Opaque {}

/// @brief DescribeConsumerGroups result type.
typedef rd_kafka_ConsumerGroupDescription_t
    = rd_kafka_ConsumerGroupDescription_s;

/// @brief Member description included in ConsumerGroupDescription.
typedef rd_kafka_MemberDescription_t = rd_kafka_MemberDescription_s;

/// @brief Member assignment included in MemberDescription.
typedef rd_kafka_MemberAssignment_t = rd_kafka_MemberAssignment_s;

final class rd_kafka_DeleteGroup_s extends ffi.Opaque {}

/// ! Represents a group to be deleted.
typedef rd_kafka_DeleteGroup_t = rd_kafka_DeleteGroup_s;

final class rd_kafka_ListConsumerGroupOffsets_s extends ffi.Opaque {}

/// ! Represents consumer group committed offsets to be listed.
typedef rd_kafka_ListConsumerGroupOffsets_t
    = rd_kafka_ListConsumerGroupOffsets_s;

final class rd_kafka_AlterConsumerGroupOffsets_s extends ffi.Opaque {}

/// ! Represents consumer group committed offsets to be altered.
typedef rd_kafka_AlterConsumerGroupOffsets_t
    = rd_kafka_AlterConsumerGroupOffsets_s;

final class rd_kafka_DeleteConsumerGroupOffsets_s extends ffi.Opaque {}

/// ! Represents consumer group committed offsets to be deleted.
typedef rd_kafka_DeleteConsumerGroupOffsets_t
    = rd_kafka_DeleteConsumerGroupOffsets_s;

/// @enum rd_kafka_OffsetSpec_t
/// @brief Allows to specify the desired offsets when using ListOffsets.
abstract class rd_kafka_OffsetSpec_t {
  static const int RD_KAFKA_OFFSET_SPEC_MAX_TIMESTAMP = -3;
  static const int RD_KAFKA_OFFSET_SPEC_EARLIEST = -2;
  static const int RD_KAFKA_OFFSET_SPEC_LATEST = -1;
}

final class rd_kafka_ListOffsetsResultInfo_s extends ffi.Opaque {}

/// @brief Information returned from a ListOffsets call for a specific
/// `rd_kafka_topic_partition_t`.
typedef rd_kafka_ListOffsetsResultInfo_t = rd_kafka_ListOffsetsResultInfo_s;

/// @enum rd_kafka_ScramMechanism_t
/// @brief Apache Kafka ScramMechanism values.
abstract class rd_kafka_ScramMechanism_t {
  static const int RD_KAFKA_SCRAM_MECHANISM_UNKNOWN = 0;
  static const int RD_KAFKA_SCRAM_MECHANISM_SHA_256 = 1;
  static const int RD_KAFKA_SCRAM_MECHANISM_SHA_512 = 2;
  static const int RD_KAFKA_SCRAM_MECHANISM__CNT = 3;
}

final class rd_kafka_ScramCredentialInfo_s extends ffi.Opaque {}

/// @brief Scram credential info.
/// Mechanism and iterations for a SASL/SCRAM
/// credential associated with a user.
typedef rd_kafka_ScramCredentialInfo_t = rd_kafka_ScramCredentialInfo_s;

final class rd_kafka_UserScramCredentialsDescription_s extends ffi.Opaque {}

/// @brief Representation of all SASL/SCRAM credentials associated
/// with a user that can be retrieved,
/// or an error indicating why credentials
/// could not be retrieved.
typedef rd_kafka_UserScramCredentialsDescription_t
    = rd_kafka_UserScramCredentialsDescription_s;

final class rd_kafka_UserScramCredentialAlteration_s extends ffi.Opaque {}

/// @brief A request to alter a user's SASL/SCRAM credentials.
typedef rd_kafka_UserScramCredentialAlteration_t
    = rd_kafka_UserScramCredentialAlteration_s;

final class rd_kafka_AlterUserScramCredentials_result_response_s
    extends ffi.Opaque {}

/// @brief Result of a single user SCRAM alteration.
typedef rd_kafka_AlterUserScramCredentials_result_response_t
    = rd_kafka_AlterUserScramCredentials_result_response_s;

final class rd_kafka_AclBinding_s extends ffi.Opaque {}

typedef rd_kafka_acl_result_t = rd_kafka_acl_result_s;

/// @enum rd_kafka_AclPermissionType_t
/// @brief Apache Kafka ACL permission types.
abstract class rd_kafka_AclPermissionType_t {
  /// < Unknown
  static const int RD_KAFKA_ACL_PERMISSION_TYPE_UNKNOWN = 0;
  static const int RD_KAFKA_ACL_PERMISSION_TYPE_ANY = 1;

  /// < Disallows access
  static const int RD_KAFKA_ACL_PERMISSION_TYPE_DENY = 2;

  /// < Grants access.
  static const int RD_KAFKA_ACL_PERMISSION_TYPE_ALLOW = 3;
  static const int RD_KAFKA_ACL_PERMISSION_TYPE__CNT = 4;
}

/// @brief ACL Binding is used to create access control lists.
typedef rd_kafka_AclBinding_t = rd_kafka_AclBinding_s;

/// @brief ACL Binding filter is used to filter access control lists.
typedef rd_kafka_AclBindingFilter_t = rd_kafka_AclBinding_t;

final class rd_kafka_DeleteAcls_result_response_s extends ffi.Opaque {}

/// DeleteAcls - delete access control lists.
typedef rd_kafka_DeleteAcls_result_response_t
    = rd_kafka_DeleteAcls_result_response_s;

const int __has_safe_buffers = 1;

const int __DARWIN_ONLY_64_BIT_INO_T = 1;

const int __DARWIN_ONLY_UNIX_CONFORMANCE = 1;

const int __DARWIN_ONLY_VERS_1050 = 1;

const int __DARWIN_UNIX03 = 1;

const int __DARWIN_64_BIT_INO_T = 1;

const int __DARWIN_VERS_1050 = 1;

const int __DARWIN_NON_CANCELABLE = 0;

const String __DARWIN_SUF_EXTSN = '\$DARWIN_EXTSN';

const int __DARWIN_C_ANSI = 4096;

const int __DARWIN_C_FULL = 900000;

const int __DARWIN_C_LEVEL = 900000;

const int __STDC_WANT_LIB_EXT1__ = 1;

const int __DARWIN_NO_LONG_LONG = 0;

const int _DARWIN_FEATURE_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_VERS_1050 = 1;

const int _DARWIN_FEATURE_ONLY_UNIX_CONFORMANCE = 1;

const int _DARWIN_FEATURE_UNIX_CONFORMANCE = 3;

const int __has_ptrcheck = 0;

const int __API_TO_BE_DEPRECATED = 100000;

const int __API_TO_BE_DEPRECATED_MACOS = 100000;

const int __API_TO_BE_DEPRECATED_IOS = 100000;

const int __API_TO_BE_DEPRECATED_MACCATALYST = 100000;

const int __API_TO_BE_DEPRECATED_WATCHOS = 100000;

const int __API_TO_BE_DEPRECATED_TVOS = 100000;

const int __API_TO_BE_DEPRECATED_DRIVERKIT = 100000;

const int __API_TO_BE_DEPRECATED_VISIONOS = 100000;

const int __MAC_10_0 = 1000;

const int __MAC_10_1 = 1010;

const int __MAC_10_2 = 1020;

const int __MAC_10_3 = 1030;

const int __MAC_10_4 = 1040;

const int __MAC_10_5 = 1050;

const int __MAC_10_6 = 1060;

const int __MAC_10_7 = 1070;

const int __MAC_10_8 = 1080;

const int __MAC_10_9 = 1090;

const int __MAC_10_10 = 101000;

const int __MAC_10_10_2 = 101002;

const int __MAC_10_10_3 = 101003;

const int __MAC_10_11 = 101100;

const int __MAC_10_11_2 = 101102;

const int __MAC_10_11_3 = 101103;

const int __MAC_10_11_4 = 101104;

const int __MAC_10_12 = 101200;

const int __MAC_10_12_1 = 101201;

const int __MAC_10_12_2 = 101202;

const int __MAC_10_12_4 = 101204;

const int __MAC_10_13 = 101300;

const int __MAC_10_13_1 = 101301;

const int __MAC_10_13_2 = 101302;

const int __MAC_10_13_4 = 101304;

const int __MAC_10_14 = 101400;

const int __MAC_10_14_1 = 101401;

const int __MAC_10_14_4 = 101404;

const int __MAC_10_14_5 = 101405;

const int __MAC_10_14_6 = 101406;

const int __MAC_10_15 = 101500;

const int __MAC_10_15_1 = 101501;

const int __MAC_10_15_4 = 101504;

const int __MAC_10_16 = 101600;

const int __MAC_11_0 = 110000;

const int __MAC_11_1 = 110100;

const int __MAC_11_3 = 110300;

const int __MAC_11_4 = 110400;

const int __MAC_11_5 = 110500;

const int __MAC_11_6 = 110600;

const int __MAC_12_0 = 120000;

const int __MAC_12_1 = 120100;

const int __MAC_12_2 = 120200;

const int __MAC_12_3 = 120300;

const int __MAC_12_4 = 120400;

const int __MAC_12_5 = 120500;

const int __MAC_12_6 = 120600;

const int __MAC_12_7 = 120700;

const int __MAC_13_0 = 130000;

const int __MAC_13_1 = 130100;

const int __MAC_13_2 = 130200;

const int __MAC_13_3 = 130300;

const int __MAC_13_4 = 130400;

const int __MAC_13_5 = 130500;

const int __MAC_13_6 = 130600;

const int __MAC_14_0 = 140000;

const int __MAC_14_1 = 140100;

const int __MAC_14_2 = 140200;

const int __MAC_14_3 = 140300;

const int __MAC_14_4 = 140400;

const int __MAC_14_5 = 140500;

const int __IPHONE_2_0 = 20000;

const int __IPHONE_2_1 = 20100;

const int __IPHONE_2_2 = 20200;

const int __IPHONE_3_0 = 30000;

const int __IPHONE_3_1 = 30100;

const int __IPHONE_3_2 = 30200;

const int __IPHONE_4_0 = 40000;

const int __IPHONE_4_1 = 40100;

const int __IPHONE_4_2 = 40200;

const int __IPHONE_4_3 = 40300;

const int __IPHONE_5_0 = 50000;

const int __IPHONE_5_1 = 50100;

const int __IPHONE_6_0 = 60000;

const int __IPHONE_6_1 = 60100;

const int __IPHONE_7_0 = 70000;

const int __IPHONE_7_1 = 70100;

const int __IPHONE_8_0 = 80000;

const int __IPHONE_8_1 = 80100;

const int __IPHONE_8_2 = 80200;

const int __IPHONE_8_3 = 80300;

const int __IPHONE_8_4 = 80400;

const int __IPHONE_9_0 = 90000;

const int __IPHONE_9_1 = 90100;

const int __IPHONE_9_2 = 90200;

const int __IPHONE_9_3 = 90300;

const int __IPHONE_10_0 = 100000;

const int __IPHONE_10_1 = 100100;

const int __IPHONE_10_2 = 100200;

const int __IPHONE_10_3 = 100300;

const int __IPHONE_11_0 = 110000;

const int __IPHONE_11_1 = 110100;

const int __IPHONE_11_2 = 110200;

const int __IPHONE_11_3 = 110300;

const int __IPHONE_11_4 = 110400;

const int __IPHONE_12_0 = 120000;

const int __IPHONE_12_1 = 120100;

const int __IPHONE_12_2 = 120200;

const int __IPHONE_12_3 = 120300;

const int __IPHONE_12_4 = 120400;

const int __IPHONE_13_0 = 130000;

const int __IPHONE_13_1 = 130100;

const int __IPHONE_13_2 = 130200;

const int __IPHONE_13_3 = 130300;

const int __IPHONE_13_4 = 130400;

const int __IPHONE_13_5 = 130500;

const int __IPHONE_13_6 = 130600;

const int __IPHONE_13_7 = 130700;

const int __IPHONE_14_0 = 140000;

const int __IPHONE_14_1 = 140100;

const int __IPHONE_14_2 = 140200;

const int __IPHONE_14_3 = 140300;

const int __IPHONE_14_5 = 140500;

const int __IPHONE_14_4 = 140400;

const int __IPHONE_14_6 = 140600;

const int __IPHONE_14_7 = 140700;

const int __IPHONE_14_8 = 140800;

const int __IPHONE_15_0 = 150000;

const int __IPHONE_15_1 = 150100;

const int __IPHONE_15_2 = 150200;

const int __IPHONE_15_3 = 150300;

const int __IPHONE_15_4 = 150400;

const int __IPHONE_15_5 = 150500;

const int __IPHONE_15_6 = 150600;

const int __IPHONE_15_7 = 150700;

const int __IPHONE_15_8 = 150800;

const int __IPHONE_16_0 = 160000;

const int __IPHONE_16_1 = 160100;

const int __IPHONE_16_2 = 160200;

const int __IPHONE_16_3 = 160300;

const int __IPHONE_16_4 = 160400;

const int __IPHONE_16_5 = 160500;

const int __IPHONE_16_6 = 160600;

const int __IPHONE_16_7 = 160700;

const int __IPHONE_17_0 = 170000;

const int __IPHONE_17_1 = 170100;

const int __IPHONE_17_2 = 170200;

const int __IPHONE_17_3 = 170300;

const int __IPHONE_17_4 = 170400;

const int __IPHONE_17_5 = 170500;

const int __WATCHOS_1_0 = 10000;

const int __WATCHOS_2_0 = 20000;

const int __WATCHOS_2_1 = 20100;

const int __WATCHOS_2_2 = 20200;

const int __WATCHOS_3_0 = 30000;

const int __WATCHOS_3_1 = 30100;

const int __WATCHOS_3_1_1 = 30101;

const int __WATCHOS_3_2 = 30200;

const int __WATCHOS_4_0 = 40000;

const int __WATCHOS_4_1 = 40100;

const int __WATCHOS_4_2 = 40200;

const int __WATCHOS_4_3 = 40300;

const int __WATCHOS_5_0 = 50000;

const int __WATCHOS_5_1 = 50100;

const int __WATCHOS_5_2 = 50200;

const int __WATCHOS_5_3 = 50300;

const int __WATCHOS_6_0 = 60000;

const int __WATCHOS_6_1 = 60100;

const int __WATCHOS_6_2 = 60200;

const int __WATCHOS_7_0 = 70000;

const int __WATCHOS_7_1 = 70100;

const int __WATCHOS_7_2 = 70200;

const int __WATCHOS_7_3 = 70300;

const int __WATCHOS_7_4 = 70400;

const int __WATCHOS_7_5 = 70500;

const int __WATCHOS_7_6 = 70600;

const int __WATCHOS_8_0 = 80000;

const int __WATCHOS_8_1 = 80100;

const int __WATCHOS_8_3 = 80300;

const int __WATCHOS_8_4 = 80400;

const int __WATCHOS_8_5 = 80500;

const int __WATCHOS_8_6 = 80600;

const int __WATCHOS_8_7 = 80700;

const int __WATCHOS_8_8 = 80800;

const int __WATCHOS_9_0 = 90000;

const int __WATCHOS_9_1 = 90100;

const int __WATCHOS_9_2 = 90200;

const int __WATCHOS_9_3 = 90300;

const int __WATCHOS_9_4 = 90400;

const int __WATCHOS_9_5 = 90500;

const int __WATCHOS_9_6 = 90600;

const int __WATCHOS_10_0 = 100000;

const int __WATCHOS_10_1 = 100100;

const int __WATCHOS_10_2 = 100200;

const int __WATCHOS_10_3 = 100300;

const int __WATCHOS_10_4 = 100400;

const int __WATCHOS_10_5 = 100500;

const int __TVOS_9_0 = 90000;

const int __TVOS_9_1 = 90100;

const int __TVOS_9_2 = 90200;

const int __TVOS_10_0 = 100000;

const int __TVOS_10_0_1 = 100001;

const int __TVOS_10_1 = 100100;

const int __TVOS_10_2 = 100200;

const int __TVOS_11_0 = 110000;

const int __TVOS_11_1 = 110100;

const int __TVOS_11_2 = 110200;

const int __TVOS_11_3 = 110300;

const int __TVOS_11_4 = 110400;

const int __TVOS_12_0 = 120000;

const int __TVOS_12_1 = 120100;

const int __TVOS_12_2 = 120200;

const int __TVOS_12_3 = 120300;

const int __TVOS_12_4 = 120400;

const int __TVOS_13_0 = 130000;

const int __TVOS_13_2 = 130200;

const int __TVOS_13_3 = 130300;

const int __TVOS_13_4 = 130400;

const int __TVOS_14_0 = 140000;

const int __TVOS_14_1 = 140100;

const int __TVOS_14_2 = 140200;

const int __TVOS_14_3 = 140300;

const int __TVOS_14_5 = 140500;

const int __TVOS_14_6 = 140600;

const int __TVOS_14_7 = 140700;

const int __TVOS_15_0 = 150000;

const int __TVOS_15_1 = 150100;

const int __TVOS_15_2 = 150200;

const int __TVOS_15_3 = 150300;

const int __TVOS_15_4 = 150400;

const int __TVOS_15_5 = 150500;

const int __TVOS_15_6 = 150600;

const int __TVOS_16_0 = 160000;

const int __TVOS_16_1 = 160100;

const int __TVOS_16_2 = 160200;

const int __TVOS_16_3 = 160300;

const int __TVOS_16_4 = 160400;

const int __TVOS_16_5 = 160500;

const int __TVOS_16_6 = 160600;

const int __TVOS_17_0 = 170000;

const int __TVOS_17_1 = 170100;

const int __TVOS_17_2 = 170200;

const int __TVOS_17_3 = 170300;

const int __TVOS_17_4 = 170400;

const int __TVOS_17_5 = 170500;

const int __BRIDGEOS_2_0 = 20000;

const int __BRIDGEOS_3_0 = 30000;

const int __BRIDGEOS_3_1 = 30100;

const int __BRIDGEOS_3_4 = 30400;

const int __BRIDGEOS_4_0 = 40000;

const int __BRIDGEOS_4_1 = 40100;

const int __BRIDGEOS_5_0 = 50000;

const int __BRIDGEOS_5_1 = 50100;

const int __BRIDGEOS_5_3 = 50300;

const int __BRIDGEOS_6_0 = 60000;

const int __BRIDGEOS_6_2 = 60200;

const int __BRIDGEOS_6_4 = 60400;

const int __BRIDGEOS_6_5 = 60500;

const int __BRIDGEOS_6_6 = 60600;

const int __BRIDGEOS_7_0 = 70000;

const int __BRIDGEOS_7_1 = 70100;

const int __BRIDGEOS_7_2 = 70200;

const int __BRIDGEOS_7_3 = 70300;

const int __BRIDGEOS_7_4 = 70400;

const int __BRIDGEOS_7_6 = 70600;

const int __BRIDGEOS_8_0 = 80000;

const int __BRIDGEOS_8_1 = 80100;

const int __BRIDGEOS_8_2 = 80200;

const int __BRIDGEOS_8_3 = 80300;

const int __BRIDGEOS_8_4 = 80400;

const int __BRIDGEOS_8_5 = 80500;

const int __DRIVERKIT_19_0 = 190000;

const int __DRIVERKIT_20_0 = 200000;

const int __DRIVERKIT_21_0 = 210000;

const int __DRIVERKIT_22_0 = 220000;

const int __DRIVERKIT_22_4 = 220400;

const int __DRIVERKIT_22_5 = 220500;

const int __DRIVERKIT_22_6 = 220600;

const int __DRIVERKIT_23_0 = 230000;

const int __DRIVERKIT_23_1 = 230100;

const int __DRIVERKIT_23_2 = 230200;

const int __DRIVERKIT_23_3 = 230300;

const int __DRIVERKIT_23_4 = 230400;

const int __DRIVERKIT_23_5 = 230500;

const int __VISIONOS_1_0 = 10000;

const int __VISIONOS_1_1 = 10100;

const int __VISIONOS_1_2 = 10200;

const int MAC_OS_X_VERSION_10_0 = 1000;

const int MAC_OS_X_VERSION_10_1 = 1010;

const int MAC_OS_X_VERSION_10_2 = 1020;

const int MAC_OS_X_VERSION_10_3 = 1030;

const int MAC_OS_X_VERSION_10_4 = 1040;

const int MAC_OS_X_VERSION_10_5 = 1050;

const int MAC_OS_X_VERSION_10_6 = 1060;

const int MAC_OS_X_VERSION_10_7 = 1070;

const int MAC_OS_X_VERSION_10_8 = 1080;

const int MAC_OS_X_VERSION_10_9 = 1090;

const int MAC_OS_X_VERSION_10_10 = 101000;

const int MAC_OS_X_VERSION_10_10_2 = 101002;

const int MAC_OS_X_VERSION_10_10_3 = 101003;

const int MAC_OS_X_VERSION_10_11 = 101100;

const int MAC_OS_X_VERSION_10_11_2 = 101102;

const int MAC_OS_X_VERSION_10_11_3 = 101103;

const int MAC_OS_X_VERSION_10_11_4 = 101104;

const int MAC_OS_X_VERSION_10_12 = 101200;

const int MAC_OS_X_VERSION_10_12_1 = 101201;

const int MAC_OS_X_VERSION_10_12_2 = 101202;

const int MAC_OS_X_VERSION_10_12_4 = 101204;

const int MAC_OS_X_VERSION_10_13 = 101300;

const int MAC_OS_X_VERSION_10_13_1 = 101301;

const int MAC_OS_X_VERSION_10_13_2 = 101302;

const int MAC_OS_X_VERSION_10_13_4 = 101304;

const int MAC_OS_X_VERSION_10_14 = 101400;

const int MAC_OS_X_VERSION_10_14_1 = 101401;

const int MAC_OS_X_VERSION_10_14_4 = 101404;

const int MAC_OS_X_VERSION_10_14_5 = 101405;

const int MAC_OS_X_VERSION_10_14_6 = 101406;

const int MAC_OS_X_VERSION_10_15 = 101500;

const int MAC_OS_X_VERSION_10_15_1 = 101501;

const int MAC_OS_X_VERSION_10_15_4 = 101504;

const int MAC_OS_X_VERSION_10_16 = 101600;

const int MAC_OS_VERSION_11_0 = 110000;

const int MAC_OS_VERSION_11_1 = 110100;

const int MAC_OS_VERSION_11_3 = 110300;

const int MAC_OS_VERSION_11_4 = 110400;

const int MAC_OS_VERSION_11_5 = 110500;

const int MAC_OS_VERSION_11_6 = 110600;

const int MAC_OS_VERSION_12_0 = 120000;

const int MAC_OS_VERSION_12_1 = 120100;

const int MAC_OS_VERSION_12_2 = 120200;

const int MAC_OS_VERSION_12_3 = 120300;

const int MAC_OS_VERSION_12_4 = 120400;

const int MAC_OS_VERSION_12_5 = 120500;

const int MAC_OS_VERSION_12_6 = 120600;

const int MAC_OS_VERSION_12_7 = 120700;

const int MAC_OS_VERSION_13_0 = 130000;

const int MAC_OS_VERSION_13_1 = 130100;

const int MAC_OS_VERSION_13_2 = 130200;

const int MAC_OS_VERSION_13_3 = 130300;

const int MAC_OS_VERSION_13_4 = 130400;

const int MAC_OS_VERSION_13_5 = 130500;

const int MAC_OS_VERSION_13_6 = 130600;

const int MAC_OS_VERSION_14_0 = 140000;

const int MAC_OS_VERSION_14_1 = 140100;

const int MAC_OS_VERSION_14_2 = 140200;

const int MAC_OS_VERSION_14_3 = 140300;

const int MAC_OS_VERSION_14_4 = 140400;

const int MAC_OS_VERSION_14_5 = 140500;

const int __MAC_OS_X_VERSION_MIN_REQUIRED = 140000;

const int __MAC_OS_X_VERSION_MAX_ALLOWED = 140500;

const int __ENABLE_LEGACY_MAC_AVAILABILITY = 1;

const int __DARWIN_NULL = 0;

const int __PTHREAD_SIZE__ = 8176;

const int __PTHREAD_ATTR_SIZE__ = 56;

const int __PTHREAD_MUTEXATTR_SIZE__ = 8;

const int __PTHREAD_MUTEX_SIZE__ = 56;

const int __PTHREAD_CONDATTR_SIZE__ = 8;

const int __PTHREAD_COND_SIZE__ = 40;

const int __PTHREAD_ONCE_SIZE__ = 8;

const int __PTHREAD_RWLOCK_SIZE__ = 192;

const int __PTHREAD_RWLOCKATTR_SIZE__ = 16;

const int __DARWIN_WCHAR_MAX = 2147483647;

const int __DARWIN_WCHAR_MIN = -2147483648;

const int __DARWIN_WEOF = -1;

const int _FORTIFY_SOURCE = 2;

const int USER_ADDR_NULL = 0;

const int NULL = 0;

const int RENAME_SECLUDE = 1;

const int RENAME_SWAP = 2;

const int RENAME_EXCL = 4;

const int RENAME_RESERVED1 = 8;

const int RENAME_NOFOLLOW_ANY = 16;

const int SEEK_SET = 0;

const int SEEK_CUR = 1;

const int SEEK_END = 2;

const int SEEK_HOLE = 3;

const int SEEK_DATA = 4;

const int __SLBF = 1;

const int __SNBF = 2;

const int __SRD = 4;

const int __SWR = 8;

const int __SRW = 16;

const int __SEOF = 32;

const int __SERR = 64;

const int __SMBF = 128;

const int __SAPP = 256;

const int __SSTR = 512;

const int __SOPT = 1024;

const int __SNPT = 2048;

const int __SOFF = 4096;

const int __SMOD = 8192;

const int __SALC = 16384;

const int __SIGN = 32768;

const int _IOFBF = 0;

const int _IOLBF = 1;

const int _IONBF = 2;

const int BUFSIZ = 1024;

const int EOF = -1;

const int FOPEN_MAX = 20;

const int FILENAME_MAX = 1024;

const String P_tmpdir = '/var/tmp/';

const int L_tmpnam = 1024;

const int TMP_MAX = 308915776;

const int L_ctermid = 1024;

const String __PRI_8_LENGTH_MODIFIER__ = 'hh';

const String __PRI_64_LENGTH_MODIFIER__ = 'll';

const String __SCN_64_LENGTH_MODIFIER__ = 'll';

const String __PRI_MAX_LENGTH_MODIFIER__ = 'j';

const String __SCN_MAX_LENGTH_MODIFIER__ = 'j';

const String PRId8 = 'hhd';

const String PRIi8 = 'hhi';

const String PRIo8 = 'hho';

const String PRIu8 = 'hhu';

const String PRIx8 = 'hhx';

const String PRIX8 = 'hhX';

const String PRId16 = 'hd';

const String PRIi16 = 'hi';

const String PRIo16 = 'ho';

const String PRIu16 = 'hu';

const String PRIx16 = 'hx';

const String PRIX16 = 'hX';

const String PRId32 = 'd';

const String PRIi32 = 'i';

const String PRIo32 = 'o';

const String PRIu32 = 'u';

const String PRIx32 = 'x';

const String PRIX32 = 'X';

const String PRId64 = 'lld';

const String PRIi64 = 'lli';

const String PRIo64 = 'llo';

const String PRIu64 = 'llu';

const String PRIx64 = 'llx';

const String PRIX64 = 'llX';

const String PRIdLEAST8 = 'hhd';

const String PRIiLEAST8 = 'hhi';

const String PRIoLEAST8 = 'hho';

const String PRIuLEAST8 = 'hhu';

const String PRIxLEAST8 = 'hhx';

const String PRIXLEAST8 = 'hhX';

const String PRIdLEAST16 = 'hd';

const String PRIiLEAST16 = 'hi';

const String PRIoLEAST16 = 'ho';

const String PRIuLEAST16 = 'hu';

const String PRIxLEAST16 = 'hx';

const String PRIXLEAST16 = 'hX';

const String PRIdLEAST32 = 'd';

const String PRIiLEAST32 = 'i';

const String PRIoLEAST32 = 'o';

const String PRIuLEAST32 = 'u';

const String PRIxLEAST32 = 'x';

const String PRIXLEAST32 = 'X';

const String PRIdLEAST64 = 'lld';

const String PRIiLEAST64 = 'lli';

const String PRIoLEAST64 = 'llo';

const String PRIuLEAST64 = 'llu';

const String PRIxLEAST64 = 'llx';

const String PRIXLEAST64 = 'llX';

const String PRIdFAST8 = 'hhd';

const String PRIiFAST8 = 'hhi';

const String PRIoFAST8 = 'hho';

const String PRIuFAST8 = 'hhu';

const String PRIxFAST8 = 'hhx';

const String PRIXFAST8 = 'hhX';

const String PRIdFAST16 = 'hd';

const String PRIiFAST16 = 'hi';

const String PRIoFAST16 = 'ho';

const String PRIuFAST16 = 'hu';

const String PRIxFAST16 = 'hx';

const String PRIXFAST16 = 'hX';

const String PRIdFAST32 = 'd';

const String PRIiFAST32 = 'i';

const String PRIoFAST32 = 'o';

const String PRIuFAST32 = 'u';

const String PRIxFAST32 = 'x';

const String PRIXFAST32 = 'X';

const String PRIdFAST64 = 'lld';

const String PRIiFAST64 = 'lli';

const String PRIoFAST64 = 'llo';

const String PRIuFAST64 = 'llu';

const String PRIxFAST64 = 'llx';

const String PRIXFAST64 = 'llX';

const String PRIdPTR = 'ld';

const String PRIiPTR = 'li';

const String PRIoPTR = 'lo';

const String PRIuPTR = 'lu';

const String PRIxPTR = 'lx';

const String PRIXPTR = 'lX';

const String PRIdMAX = 'jd';

const String PRIiMAX = 'ji';

const String PRIoMAX = 'jo';

const String PRIuMAX = 'ju';

const String PRIxMAX = 'jx';

const String PRIXMAX = 'jX';

const String SCNd8 = 'hhd';

const String SCNi8 = 'hhi';

const String SCNo8 = 'hho';

const String SCNu8 = 'hhu';

const String SCNx8 = 'hhx';

const String SCNd16 = 'hd';

const String SCNi16 = 'hi';

const String SCNo16 = 'ho';

const String SCNu16 = 'hu';

const String SCNx16 = 'hx';

const String SCNd32 = 'd';

const String SCNi32 = 'i';

const String SCNo32 = 'o';

const String SCNu32 = 'u';

const String SCNx32 = 'x';

const String SCNd64 = 'lld';

const String SCNi64 = 'lli';

const String SCNo64 = 'llo';

const String SCNu64 = 'llu';

const String SCNx64 = 'llx';

const String SCNdLEAST8 = 'hhd';

const String SCNiLEAST8 = 'hhi';

const String SCNoLEAST8 = 'hho';

const String SCNuLEAST8 = 'hhu';

const String SCNxLEAST8 = 'hhx';

const String SCNdLEAST16 = 'hd';

const String SCNiLEAST16 = 'hi';

const String SCNoLEAST16 = 'ho';

const String SCNuLEAST16 = 'hu';

const String SCNxLEAST16 = 'hx';

const String SCNdLEAST32 = 'd';

const String SCNiLEAST32 = 'i';

const String SCNoLEAST32 = 'o';

const String SCNuLEAST32 = 'u';

const String SCNxLEAST32 = 'x';

const String SCNdLEAST64 = 'lld';

const String SCNiLEAST64 = 'lli';

const String SCNoLEAST64 = 'llo';

const String SCNuLEAST64 = 'llu';

const String SCNxLEAST64 = 'llx';

const String SCNdFAST8 = 'hhd';

const String SCNiFAST8 = 'hhi';

const String SCNoFAST8 = 'hho';

const String SCNuFAST8 = 'hhu';

const String SCNxFAST8 = 'hhx';

const String SCNdFAST16 = 'hd';

const String SCNiFAST16 = 'hi';

const String SCNoFAST16 = 'ho';

const String SCNuFAST16 = 'hu';

const String SCNxFAST16 = 'hx';

const String SCNdFAST32 = 'd';

const String SCNiFAST32 = 'i';

const String SCNoFAST32 = 'o';

const String SCNuFAST32 = 'u';

const String SCNxFAST32 = 'x';

const String SCNdFAST64 = 'lld';

const String SCNiFAST64 = 'lli';

const String SCNoFAST64 = 'llo';

const String SCNuFAST64 = 'llu';

const String SCNxFAST64 = 'llx';

const String SCNdPTR = 'ld';

const String SCNiPTR = 'li';

const String SCNoPTR = 'lo';

const String SCNuPTR = 'lu';

const String SCNxPTR = 'lx';

const String SCNdMAX = 'jd';

const String SCNiMAX = 'ji';

const String SCNoMAX = 'jo';

const String SCNuMAX = 'ju';

const String SCNxMAX = 'jx';

const int __WORDSIZE = 64;

const int INT8_MAX = 127;

const int INT16_MAX = 32767;

const int INT32_MAX = 2147483647;

const int INT64_MAX = 9223372036854775807;

const int INT8_MIN = -128;

const int INT16_MIN = -32768;

const int INT32_MIN = -2147483648;

const int INT64_MIN = -9223372036854775808;

const int UINT8_MAX = 255;

const int UINT16_MAX = 65535;

const int UINT32_MAX = 4294967295;

const int UINT64_MAX = -1;

const int INT_LEAST8_MIN = -128;

const int INT_LEAST16_MIN = -32768;

const int INT_LEAST32_MIN = -2147483648;

const int INT_LEAST64_MIN = -9223372036854775808;

const int INT_LEAST8_MAX = 127;

const int INT_LEAST16_MAX = 32767;

const int INT_LEAST32_MAX = 2147483647;

const int INT_LEAST64_MAX = 9223372036854775807;

const int UINT_LEAST8_MAX = 255;

const int UINT_LEAST16_MAX = 65535;

const int UINT_LEAST32_MAX = 4294967295;

const int UINT_LEAST64_MAX = -1;

const int INT_FAST8_MIN = -128;

const int INT_FAST16_MIN = -32768;

const int INT_FAST32_MIN = -2147483648;

const int INT_FAST64_MIN = -9223372036854775808;

const int INT_FAST8_MAX = 127;

const int INT_FAST16_MAX = 32767;

const int INT_FAST32_MAX = 2147483647;

const int INT_FAST64_MAX = 9223372036854775807;

const int UINT_FAST8_MAX = 255;

const int UINT_FAST16_MAX = 65535;

const int UINT_FAST32_MAX = 4294967295;

const int UINT_FAST64_MAX = -1;

const int INTPTR_MAX = 9223372036854775807;

const int INTPTR_MIN = -9223372036854775808;

const int UINTPTR_MAX = -1;

const int INTMAX_MAX = 9223372036854775807;

const int UINTMAX_MAX = -1;

const int INTMAX_MIN = -9223372036854775808;

const int PTRDIFF_MIN = -9223372036854775808;

const int PTRDIFF_MAX = 9223372036854775807;

const int SIZE_MAX = -1;

const int RSIZE_MAX = 9223372036854775807;

const int WCHAR_MAX = 2147483647;

const int WCHAR_MIN = -2147483648;

const int WINT_MIN = -2147483648;

const int WINT_MAX = 2147483647;

const int SIG_ATOMIC_MIN = -2147483648;

const int SIG_ATOMIC_MAX = 2147483647;

const int _QUAD_HIGHWORD = 1;

const int _QUAD_LOWWORD = 0;

const int __DARWIN_LITTLE_ENDIAN = 1234;

const int __DARWIN_BIG_ENDIAN = 4321;

const int __DARWIN_PDP_ENDIAN = 3412;

const int __DARWIN_BYTE_ORDER = 1234;

const int LITTLE_ENDIAN = 1234;

const int BIG_ENDIAN = 4321;

const int PDP_ENDIAN = 3412;

const int BYTE_ORDER = 1234;

const int __DARWIN_FD_SETSIZE = 1024;

const int __DARWIN_NBBY = 8;

const int __DARWIN_NFDBITS = 32;

const int NBBY = 8;

const int NFDBITS = 32;

const int FD_SETSIZE = 1024;

const int __DARWIN_ALIGNBYTES = 7;

const int __DARWIN_ALIGNBYTES32 = 3;

const int KEV_INET_SUBCLASS = 1;

const int KEV_INET_NEW_ADDR = 1;

const int KEV_INET_CHANGED_ADDR = 2;

const int KEV_INET_ADDR_DELETED = 3;

const int KEV_INET_SIFDSTADDR = 4;

const int KEV_INET_SIFBRDADDR = 5;

const int KEV_INET_SIFNETMASK = 6;

const int KEV_INET_ARPCOLLISION = 7;

const int KEV_INET_PORTINUSE = 8;

const int KEV_INET_ARPRTRFAILURE = 9;

const int KEV_INET_ARPRTRALIVE = 10;

const int KEV_DL_SUBCLASS = 2;

const int KEV_DL_SIFFLAGS = 1;

const int KEV_DL_SIFMETRICS = 2;

const int KEV_DL_SIFMTU = 3;

const int KEV_DL_SIFPHYS = 4;

const int KEV_DL_SIFMEDIA = 5;

const int KEV_DL_SIFGENERIC = 6;

const int KEV_DL_ADDMULTI = 7;

const int KEV_DL_DELMULTI = 8;

const int KEV_DL_IF_ATTACHED = 9;

const int KEV_DL_IF_DETACHING = 10;

const int KEV_DL_IF_DETACHED = 11;

const int KEV_DL_LINK_OFF = 12;

const int KEV_DL_LINK_ON = 13;

const int KEV_DL_PROTO_ATTACHED = 14;

const int KEV_DL_PROTO_DETACHED = 15;

const int KEV_DL_LINK_ADDRESS_CHANGED = 16;

const int KEV_DL_WAKEFLAGS_CHANGED = 17;

const int KEV_DL_IF_IDLE_ROUTE_REFCNT = 18;

const int KEV_DL_IFCAP_CHANGED = 19;

const int KEV_DL_LINK_QUALITY_METRIC_CHANGED = 20;

const int KEV_DL_NODE_PRESENCE = 21;

const int KEV_DL_NODE_ABSENCE = 22;

const int KEV_DL_PRIMARY_ELECTED = 23;

const int KEV_DL_ISSUES = 24;

const int KEV_DL_IFDELEGATE_CHANGED = 25;

const int KEV_DL_AWDL_RESTRICTED = 26;

const int KEV_DL_AWDL_UNRESTRICTED = 27;

const int KEV_DL_RRC_STATE_CHANGED = 28;

const int KEV_DL_QOS_MODE_CHANGED = 29;

const int KEV_DL_LOW_POWER_MODE_CHANGED = 30;

const int KEV_DL_MASTER_ELECTED = 23;

const int KEV_INET6_SUBCLASS = 6;

const int KEV_INET6_NEW_USER_ADDR = 1;

const int KEV_INET6_CHANGED_ADDR = 2;

const int KEV_INET6_ADDR_DELETED = 3;

const int KEV_INET6_NEW_LL_ADDR = 4;

const int KEV_INET6_NEW_RTADV_ADDR = 5;

const int KEV_INET6_DEFROUTER = 6;

const int KEV_INET6_REQUEST_NAT64_PREFIX = 7;

const int SOCK_STREAM = 1;

const int SOCK_DGRAM = 2;

const int SOCK_RAW = 3;

const int SOCK_RDM = 4;

const int SOCK_SEQPACKET = 5;

const int SO_DEBUG = 1;

const int SO_ACCEPTCONN = 2;

const int SO_REUSEADDR = 4;

const int SO_KEEPALIVE = 8;

const int SO_DONTROUTE = 16;

const int SO_BROADCAST = 32;

const int SO_USELOOPBACK = 64;

const int SO_LINGER = 128;

const int SO_LINGER_SEC = 4224;

const int SO_OOBINLINE = 256;

const int SO_REUSEPORT = 512;

const int SO_TIMESTAMP = 1024;

const int SO_TIMESTAMP_MONOTONIC = 2048;

const int SO_DONTTRUNC = 8192;

const int SO_WANTMORE = 16384;

const int SO_WANTOOBFLAG = 32768;

const int SO_SNDBUF = 4097;

const int SO_RCVBUF = 4098;

const int SO_SNDLOWAT = 4099;

const int SO_RCVLOWAT = 4100;

const int SO_SNDTIMEO = 4101;

const int SO_RCVTIMEO = 4102;

const int SO_ERROR = 4103;

const int SO_TYPE = 4104;

const int SO_LABEL = 4112;

const int SO_PEERLABEL = 4113;

const int SO_NREAD = 4128;

const int SO_NKE = 4129;

const int SO_NOSIGPIPE = 4130;

const int SO_NOADDRERR = 4131;

const int SO_NWRITE = 4132;

const int SO_REUSESHAREUID = 4133;

const int SO_NOTIFYCONFLICT = 4134;

const int SO_UPCALLCLOSEWAIT = 4135;

const int SO_RANDOMPORT = 4226;

const int SO_NP_EXTENSIONS = 4227;

const int SO_NUMRCVPKT = 4370;

const int SO_NET_SERVICE_TYPE = 4374;

const int SO_NETSVC_MARKING_LEVEL = 4377;

const int SO_RESOLVER_SIGNATURE = 4401;

const int NET_SERVICE_TYPE_BE = 0;

const int NET_SERVICE_TYPE_BK = 1;

const int NET_SERVICE_TYPE_SIG = 2;

const int NET_SERVICE_TYPE_VI = 3;

const int NET_SERVICE_TYPE_VO = 4;

const int NET_SERVICE_TYPE_RV = 5;

const int NET_SERVICE_TYPE_AV = 6;

const int NET_SERVICE_TYPE_OAM = 7;

const int NET_SERVICE_TYPE_RD = 8;

const int NETSVC_MRKNG_UNKNOWN = 0;

const int NETSVC_MRKNG_LVL_L2 = 1;

const int NETSVC_MRKNG_LVL_L3L2_ALL = 2;

const int NETSVC_MRKNG_LVL_L3L2_BK = 3;

const int SAE_ASSOCID_ANY = 0;

const int SAE_ASSOCID_ALL = 4294967295;

const int SAE_CONNID_ANY = 0;

const int SAE_CONNID_ALL = 4294967295;

const int CONNECT_RESUME_ON_READ_WRITE = 1;

const int CONNECT_DATA_IDEMPOTENT = 2;

const int CONNECT_DATA_AUTHENTICATED = 4;

const int SONPX_SETOPTSHUT = 1;

const int SOL_SOCKET = 65535;

const int AF_UNSPEC = 0;

const int AF_UNIX = 1;

const int AF_LOCAL = 1;

const int AF_INET = 2;

const int AF_IMPLINK = 3;

const int AF_PUP = 4;

const int AF_CHAOS = 5;

const int AF_NS = 6;

const int AF_ISO = 7;

const int AF_OSI = 7;

const int AF_ECMA = 8;

const int AF_DATAKIT = 9;

const int AF_CCITT = 10;

const int AF_SNA = 11;

const int AF_DECnet = 12;

const int AF_DLI = 13;

const int AF_LAT = 14;

const int AF_HYLINK = 15;

const int AF_APPLETALK = 16;

const int AF_ROUTE = 17;

const int AF_LINK = 18;

const int pseudo_AF_XTP = 19;

const int AF_COIP = 20;

const int AF_CNT = 21;

const int pseudo_AF_RTIP = 22;

const int AF_IPX = 23;

const int AF_SIP = 24;

const int pseudo_AF_PIP = 25;

const int AF_NDRV = 27;

const int AF_ISDN = 28;

const int AF_E164 = 28;

const int pseudo_AF_KEY = 29;

const int AF_INET6 = 30;

const int AF_NATM = 31;

const int AF_SYSTEM = 32;

const int AF_NETBIOS = 33;

const int AF_PPP = 34;

const int pseudo_AF_HDRCMPLT = 35;

const int AF_RESERVED_36 = 36;

const int AF_IEEE80211 = 37;

const int AF_UTUN = 38;

const int AF_VSOCK = 40;

const int AF_MAX = 41;

const int SOCK_MAXADDRLEN = 255;

const int _SS_MAXSIZE = 128;

const int _SS_ALIGNSIZE = 8;

const int _SS_PAD1SIZE = 6;

const int _SS_PAD2SIZE = 112;

const int PF_UNSPEC = 0;

const int PF_LOCAL = 1;

const int PF_UNIX = 1;

const int PF_INET = 2;

const int PF_IMPLINK = 3;

const int PF_PUP = 4;

const int PF_CHAOS = 5;

const int PF_NS = 6;

const int PF_ISO = 7;

const int PF_OSI = 7;

const int PF_ECMA = 8;

const int PF_DATAKIT = 9;

const int PF_CCITT = 10;

const int PF_SNA = 11;

const int PF_DECnet = 12;

const int PF_DLI = 13;

const int PF_LAT = 14;

const int PF_HYLINK = 15;

const int PF_APPLETALK = 16;

const int PF_ROUTE = 17;

const int PF_LINK = 18;

const int PF_XTP = 19;

const int PF_COIP = 20;

const int PF_CNT = 21;

const int PF_SIP = 24;

const int PF_IPX = 23;

const int PF_RTIP = 22;

const int PF_PIP = 25;

const int PF_NDRV = 27;

const int PF_ISDN = 28;

const int PF_KEY = 29;

const int PF_INET6 = 30;

const int PF_NATM = 31;

const int PF_SYSTEM = 32;

const int PF_NETBIOS = 33;

const int PF_PPP = 34;

const int PF_RESERVED_36 = 36;

const int PF_UTUN = 38;

const int PF_VSOCK = 40;

const int PF_MAX = 41;

const int PF_VLAN = 1986814318;

const int PF_BOND = 1651469924;

const int NET_MAXID = 41;

const int NET_RT_DUMP = 1;

const int NET_RT_FLAGS = 2;

const int NET_RT_IFLIST = 3;

const int NET_RT_STAT = 4;

const int NET_RT_TRASH = 5;

const int NET_RT_IFLIST2 = 6;

const int NET_RT_DUMP2 = 7;

const int NET_RT_FLAGS_PRIV = 10;

const int NET_RT_MAXID = 11;

const int SOMAXCONN = 128;

const int MSG_OOB = 1;

const int MSG_PEEK = 2;

const int MSG_DONTROUTE = 4;

const int MSG_EOR = 8;

const int MSG_TRUNC = 16;

const int MSG_CTRUNC = 32;

const int MSG_WAITALL = 64;

const int MSG_DONTWAIT = 128;

const int MSG_EOF = 256;

const int MSG_WAITSTREAM = 512;

const int MSG_FLUSH = 1024;

const int MSG_HOLD = 2048;

const int MSG_SEND = 4096;

const int MSG_HAVEMORE = 8192;

const int MSG_RCVMORE = 16384;

const int MSG_NEEDSA = 65536;

const int MSG_NOSIGNAL = 524288;

const int SCM_RIGHTS = 1;

const int SCM_TIMESTAMP = 2;

const int SCM_CREDS = 3;

const int SCM_TIMESTAMP_MONOTONIC = 4;

const int SHUT_RD = 0;

const int SHUT_WR = 1;

const int SHUT_RDWR = 2;

const int LIBRDKAFKA_TYPECHECKS = 1;

const int RD_KAFKA_VERSION = 33816831;

const String RD_KAFKA_DEBUG_CONTEXTS =
    'all,generic,broker,topic,metadata,feature,queue,msg,protocol,cgrp,security,fetch,interceptor,plugin,consumer,admin,eos,mock,assignor,conf';

const int RD_KAFKA_RESP_ERR_NOT_LEADER_OR_FOLLOWER = 6;

const int RD_KAFKA_RESP_ERR_GROUP_LOAD_IN_PROGRESS = 14;

const int RD_KAFKA_RESP_ERR_GROUP_COORDINATOR_NOT_AVAILABLE = 15;

const int RD_KAFKA_RESP_ERR_NOT_COORDINATOR_FOR_GROUP = 16;

const int RD_KAFKA_V_END = 0;

const int RD_KAFKA_DESTROY_F_NO_CONSUMER_CLOSE = 8;

const int RD_KAFKA_PARTITION_UA = -1;

const int RD_KAFKA_OFFSET_BEGINNING = -2;

const int RD_KAFKA_OFFSET_END = -1;

const int RD_KAFKA_OFFSET_STORED = -1000;

const int RD_KAFKA_OFFSET_INVALID = -1001;

const int RD_KAFKA_OFFSET_TAIL_BASE = -2000;

const int RD_KAFKA_MSG_F_FREE = 1;

const int RD_KAFKA_MSG_F_COPY = 2;

const int RD_KAFKA_MSG_F_BLOCK = 4;

const int RD_KAFKA_MSG_F_PARTITION = 8;

const int RD_KAFKA_PURGE_F_QUEUE = 1;

const int RD_KAFKA_PURGE_F_INFLIGHT = 2;

const int RD_KAFKA_PURGE_F_NON_BLOCKING = 4;

const int RD_KAFKA_EVENT_NONE = 0;

const int RD_KAFKA_EVENT_DR = 1;

const int RD_KAFKA_EVENT_FETCH = 2;

const int RD_KAFKA_EVENT_LOG = 4;

const int RD_KAFKA_EVENT_ERROR = 8;

const int RD_KAFKA_EVENT_REBALANCE = 16;

const int RD_KAFKA_EVENT_OFFSET_COMMIT = 32;

const int RD_KAFKA_EVENT_STATS = 64;

const int RD_KAFKA_EVENT_CREATETOPICS_RESULT = 100;

const int RD_KAFKA_EVENT_DELETETOPICS_RESULT = 101;

const int RD_KAFKA_EVENT_CREATEPARTITIONS_RESULT = 102;

const int RD_KAFKA_EVENT_ALTERCONFIGS_RESULT = 103;

const int RD_KAFKA_EVENT_DESCRIBECONFIGS_RESULT = 104;

const int RD_KAFKA_EVENT_DELETERECORDS_RESULT = 105;

const int RD_KAFKA_EVENT_DELETEGROUPS_RESULT = 106;

const int RD_KAFKA_EVENT_DELETECONSUMERGROUPOFFSETS_RESULT = 107;

const int RD_KAFKA_EVENT_OAUTHBEARER_TOKEN_REFRESH = 256;

const int RD_KAFKA_EVENT_BACKGROUND = 512;

const int RD_KAFKA_EVENT_CREATEACLS_RESULT = 1024;

const int RD_KAFKA_EVENT_DESCRIBEACLS_RESULT = 2048;

const int RD_KAFKA_EVENT_DELETEACLS_RESULT = 4096;

const int RD_KAFKA_EVENT_LISTCONSUMERGROUPS_RESULT = 8192;

const int RD_KAFKA_EVENT_DESCRIBECONSUMERGROUPS_RESULT = 16384;

const int RD_KAFKA_EVENT_LISTCONSUMERGROUPOFFSETS_RESULT = 32768;

const int RD_KAFKA_EVENT_ALTERCONSUMERGROUPOFFSETS_RESULT = 65536;

const int RD_KAFKA_EVENT_INCREMENTALALTERCONFIGS_RESULT = 131072;

const int RD_KAFKA_EVENT_DESCRIBEUSERSCRAMCREDENTIALS_RESULT = 262144;

const int RD_KAFKA_EVENT_ALTERUSERSCRAMCREDENTIALS_RESULT = 524288;

const int RD_KAFKA_EVENT_DESCRIBETOPICS_RESULT = 1048576;

const int RD_KAFKA_EVENT_DESCRIBECLUSTER_RESULT = 2097152;

const int RD_KAFKA_EVENT_LISTOFFSETS_RESULT = 4194304;
